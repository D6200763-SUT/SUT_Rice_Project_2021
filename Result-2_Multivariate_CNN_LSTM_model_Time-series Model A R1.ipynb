{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "\n",
    "import datetime,os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name and Path\n",
    "cwd = os.getcwd()\n",
    "path_adress = \"/Import_Dataset/\"\n",
    "\n",
    "# ข้อมูล พิกัดสถานที่เเละรายชื้ออ้างอิงสถานที่ตรวจวัด\n",
    "file_name_st = 'Data_lat_long_Rice research Center'\n",
    "csv_file_st = cwd + path_adress + file_name_st + '.csv'\n",
    "\n",
    "df_st = pd.read_csv(csv_file_st)\n",
    "print(\"All low RiceCenter {} station\" .format(df_st.shape[0]))\n",
    "\n",
    "data_list_st_num = list(range(0, len(df_st)))\n",
    "data_list_st_name = []\n",
    "data_list_st_name = df_st['nameEng'].values.tolist()\n",
    "data_list_st_lat = df_st['Latitude'].values.tolist()\n",
    "data_list_st_long = df_st['Longitude'].values.tolist()\n",
    "\n",
    "#################-- Moving Averag data --#################\n",
    "def mavr_dataset(frames_sma,rolling_num,our_rate,mode):    \n",
    "    h_name = list(frames_sma)\n",
    "    if mode == 'sum':\n",
    "        frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "        frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "        frames_sma['precip'] = frames_sma['precip'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    else:\n",
    "        frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "        frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "        frames_sma['precip'] = frames_sma['precip'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "   \n",
    "    for i in range(7,12):\n",
    "        frames_sma[h_name[i]] = frames_sma[h_name[i]].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "\n",
    "    constant_subset = frames_sma[::our_rate] \n",
    "    return constant_subset\n",
    "\n",
    "#################-- creat_dataset  --#################\n",
    "def creat_dataset(st_BPH = 'ALL', y_1='2015', y_2='2019', m_avr='ALL'):\n",
    "    for i in range(len(data_list_st_num)):\n",
    "        st = i\n",
    "        file_name = df_st['nameEng'][data_list_st_num[st]]\n",
    "        name_input = file_name\n",
    "        name_locals = 'stN_' + file_name\n",
    "\n",
    "        # File name and Path\n",
    "        csv_file = cwd + path_adress + name_input + '.csv'\n",
    "        # index_col=0 , index_col=None\n",
    "        dataset = pd.read_csv(csv_file, header=0,\n",
    "                              index_col=0, encoding=\"TIS-620\")\n",
    "\n",
    "        if m_avr == '3-DAY-All-':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,1,'mean')\n",
    "        elif m_avr == '7-DAY-All':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,1,'mean')\n",
    "        elif m_avr == '14-DAY-All':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,14,1,'mean')\n",
    "        elif m_avr == '3-DAY-Sampling':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,3,'sum')\n",
    "        elif m_avr == '7-DAY-Sampling':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,7,'sum')\n",
    "        elif m_avr == '14-DAY-Sampling':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,14,14,'sum')\n",
    "        else :\n",
    "            locals()[name_locals] = dataset\n",
    "            # print(f'Dataframe name_station: {st+1 , name_input}')\n",
    "        print('wait......')\n",
    "        del dataset\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    date_start = y_1 + '-01' + '-01'\n",
    "    date_stop = y_2 + '-12' + '-31'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "    if st_BPH != 'ALL' :\n",
    "        # file_name = df_st['nameEng'][data_list_st_num[st_BPH]]\n",
    "        file_name = st_BPH\n",
    "        locals_input = 'stN_' + file_name\n",
    "        print(locals_input)\n",
    "        dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "        frames_st = dataset_st\n",
    "    else:\n",
    "        m = 0\n",
    "        for j in range(len(data_list_st_num)):\n",
    "            # for j in range(df_st.shape[0]):\n",
    "            # file_name = df_st['nameEng'][j]\n",
    "            file_name = df_st['nameEng'][data_list_st_num[j]]\n",
    "            locals_input = 'stN_' + file_name\n",
    "            print(locals_input)\n",
    "            dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "            clear_output(wait=True)\n",
    "            if m == 0:\n",
    "                frames_st = dataset_st\n",
    "                m = m+1\n",
    "                print(m)\n",
    "            else:\n",
    "                frames_st = [frames_st, dataset_st]\n",
    "                frames_st = pd.concat(frames_st)\n",
    "\n",
    "    # dataset    \n",
    "    frames = frames_st\n",
    "    return frames\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#################-- Drop Colum  --#################\n",
    "def drop_col(df_drop,drop = ['address']):\n",
    "    for j in range(len(drop)):\n",
    "        df_drop = df_drop.drop(drop[j], axis=1)\n",
    "    return df_drop\n",
    "\n",
    "#################--      Plot        --#################\n",
    "def plot_data(frames_train,plot_cols,df_name,start='2015',end='2017',st = 'ALL'):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    if st == 'ALL':\n",
    "        df_plot = frames_train[plot_cols]\n",
    "    else:\n",
    "        df_plot = frames_train[plot_cols].loc[start:end]\n",
    "    \n",
    "    plt.figure()    \n",
    "    # df_plot.plot(lw=1,grid=True,figsize=(13,30),subplots=True)\n",
    "    # df_plot.plot(lw=1,grid=True,subplots=True)\n",
    "    # df_plot.plot(marker='.',grid=True,linestyle = 'solid',subplots=True)\n",
    "    df_plot.plot(marker='.',grid=True,linestyle = 'solid')\n",
    "    plt.xlabel('Date time-'+ df_name)\n",
    "    plt.legend()\n",
    "    # plt.show()   \n",
    "\n",
    "#################--   get list of folders in directory   --#################\n",
    "dir_path = cwd + \"/Export_lstm/model/\"\n",
    "def get_list_folder():\n",
    "    folder_list = os.listdir(dir_path)\n",
    "    return folder_list\n",
    "\n",
    "def get_file_model(file_name):\n",
    "    txt = dir_path+file_name+\"/Training_model_data_discription.txt\"\n",
    "    string_data = open(txt,\"r\").read()\n",
    "    list_txt = list(string_data.split(\"\\n\"))\n",
    "    return list_txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################-- Dashboard Input Data--#########################################\n",
    "ALL = 'ALL'\n",
    "\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st = widgets.Output()\n",
    "def dropdown_station_eventhandler(change):\n",
    "    output_df_st.clear_output()\n",
    "    with output_df_st:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st_predict = widgets.Output()\n",
    "def dropdown_station_predict_eventhandler(change):\n",
    "    output_df_st_predict.clear_output()\n",
    "    with output_df_st_predict:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- load data  --#################\n",
    "\n",
    "\n",
    "output_df_train = widgets.Output()\n",
    "output_df_val = widgets.Output()\n",
    "output_df_test = widgets.Output()\n",
    "output_df_col = widgets.Output()\n",
    "def clicked_load(b):\n",
    "    global df_out_train\n",
    "    global df_out_val\n",
    "    global df_out_test\n",
    "    global selected_data \n",
    "    output_df_train.clear_output()\n",
    "    output_df_val.clear_output()\n",
    "    output_df_test.clear_output()\n",
    "    output_df_col.clear_output()\n",
    "    with output_df_train:\n",
    "        df_out_train = creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_train)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value))\n",
    "    with output_df_val:\n",
    "        df_out_val = creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_val)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value))\n",
    "    with output_df_test:\n",
    "        df_out_test = creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_test)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value))\n",
    "    with output_df_col:\n",
    "        checkbox_objects = []\n",
    "        # global selected_data\n",
    "        data = sorted(set(chek_list(df_out_train)),reverse=True)     \n",
    "        names = []\n",
    "        for key in data:\n",
    "                checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "                names.append(key)\n",
    " \n",
    "        arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "        ui = widgets.HBox(children=checkbox_objects)\n",
    "        display(ui)\n",
    "             \n",
    "        selected_data = []\n",
    "        def select_data(**kwargs):\n",
    "            selected_data.clear()\n",
    "            for key in kwargs:\n",
    "                if kwargs[key] is True:\n",
    "                    selected_data.append(key)\n",
    "            print(selected_data)\n",
    "\n",
    "        widgets.interactive_output(select_data, arg_dict)\n",
    "    \n",
    " \n",
    "#################-- Export data  --#################\n",
    "df_train = widgets.Output()\n",
    "df_val = widgets.Output()\n",
    "df_test = widgets.Output()\n",
    "def clicked_export(b):\n",
    "    df_train.clear_output()\n",
    "    df_val.clear_output()\n",
    "    df_test.clear_output()\n",
    "    global frames_train\n",
    "    global frames_val\n",
    "    global frames_test\n",
    "    with df_train:\n",
    "        frames_train = drop_col(df_out_train,selected_data) \n",
    "        display(frames_train)\n",
    "    with df_val:\n",
    "        frames_val = drop_col(df_out_val,selected_data) \n",
    "        display(frames_val)  \n",
    "    with df_test:\n",
    "        frames_test = drop_col(df_out_test,selected_data) \n",
    "        display(frames_test)  \n",
    "\n",
    "def chek_list(df_ch):\n",
    "        data_col = set(df_ch.columns)\n",
    "        return data_col      \n",
    "\n",
    "#################----------------------------- DashBoard display ----------------------------------#################\n",
    "dropdown_name_st = widgets.Dropdown(options = unique_sorted_values_plus_ALL(df_st.nameEng),description='station :')\n",
    "dropdown_sampling_data = widgets.Dropdown(options = ['All','3-DAY-All','7-DAY-All','14-DAY-All','3-DAY-Sampling','7-DAY-Sampling','14-DAY-Sampling'],valure = 'All-DAY',description='Sampling :')\n",
    "dropdown_year_train1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],description='Year-train :')\n",
    "dropdown_year_train2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2017')\n",
    "dropdown_year_val1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018',description='Year-val :')\n",
    "dropdown_year_val2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018')\n",
    "dropdown_year_test1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019',description='Year-test :')\n",
    "dropdown_year_test2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019')\n",
    "\n",
    "\n",
    "button_download = widgets.Button(description='load data',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_export = widgets.Button(description='export dataset',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "\n",
    "button_download.on_click(clicked_load)\n",
    "button_export.on_click(clicked_export)\n",
    "\n",
    "dropdown_name_st.observe(dropdown_station_eventhandler, names='value')\n",
    "\n",
    "\n",
    "item_layout = widgets.Layout(margin='0 0 15px 0')\n",
    "input_widgets_row1 = widgets.HBox([dropdown_name_st,dropdown_year_train1,dropdown_year_train2,dropdown_year_val1,dropdown_year_val2,dropdown_year_test1,dropdown_year_test2],layout = item_layout)\n",
    "input_widgets_row2 = widgets.HBox([dropdown_sampling_data,button_download,button_export],layout = item_layout)\n",
    "\n",
    "tab_dataset = widgets.Tab([output_df_st,output_df_train,output_df_val,output_df_test,output_df_col,df_train,df_val,df_test])\n",
    "tab_dataset.set_title(0, 'Dataset station')\n",
    "tab_dataset.set_title(1, 'train-data')\n",
    "tab_dataset.set_title(2, 'validation-data')\n",
    "tab_dataset.set_title(3, 'test-data')\n",
    "tab_dataset.set_title(4, 'Drop-data')\n",
    "tab_dataset.set_title(5, 'Dataset-train')\n",
    "tab_dataset.set_title(6, 'Dataset-validation')\n",
    "tab_dataset.set_title(7, 'Dataset-test')\n",
    "dashboard_dataset = widgets.VBox([input_widgets_row1,input_widgets_row2])\n",
    "display(dashboard_dataset)\n",
    "display(tab_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "def plot_data(frames_train,df_name):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    plt.figure()\n",
    "    df_plot = frames_train\n",
    "    df_plot.plot(lw=1,grid=True,figsize=(15,7),subplots=True)\n",
    "    plt.xlabel('time (day) - '+ df_name)\n",
    "    plt.legend()\n",
    "\t# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_month = frames_train['day'].values\n",
    "month_of_year = frames_train['month'].values\n",
    "\n",
    "frames_train['d_sin'] = np.sin((2*np.pi)/30*frames_train['day'].values)\n",
    "frames_train['d_cos'] = np.cos((2*np.pi)/30*frames_train['day'].values)\n",
    "frames_train['m_sin'] = np.sin((2*np.pi)/12*frames_train['month'].values)\n",
    "frames_train['m_cos'] = np.cos((2*np.pi)/12*frames_train['month'].values)\n",
    "frames_train = frames_train.drop(['day', 'month'], axis=1)\n",
    "\n",
    "frames_val['d_sin'] = np.sin((2*np.pi)/30*frames_val['day'].values)\n",
    "frames_val['d_cos'] = np.cos((2*np.pi)/30*frames_val['day'].values)\n",
    "frames_val['m_sin'] = np.sin((2*np.pi)/12*frames_val['month'].values)\n",
    "frames_val['m_cos'] = np.cos((2*np.pi)/12*frames_val['month'].values)\n",
    "frames_val = frames_val.drop(['day', 'month'], axis=1)\n",
    "\n",
    "\n",
    "frames_test['d_sin'] = np.sin((2*np.pi)/30*frames_test['day'].values)\n",
    "frames_test['d_cos'] = np.cos((2*np.pi)/30*frames_test['day'].values)\n",
    "frames_test['m_sin'] = np.sin((2*np.pi)/12*frames_test['month'].values)\n",
    "frames_test['m_cos'] = np.cos((2*np.pi)/12*frames_test['month'].values)\n",
    "frames_test = frames_test.drop(['day', 'month'], axis=1)\n",
    "\n",
    "#define function to swap columns\n",
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df\n",
    "\n",
    "#swap points and rebounds columns\n",
    "frames_train = swap_columns(frames_train, 'bph', list(frames_train.columns)[-1])\n",
    "frames_val = swap_columns(frames_val, 'bph', list(frames_val.columns)[-1])\n",
    "frames_test = swap_columns(frames_test, 'bph', list(frames_test.columns)[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(Epoc,n_input,n_output,Export_folder_name):\n",
    "\n",
    "    #Multivariate = [temp,precip,humidity,bph] 4\n",
    "    #Multivariate = [temp,precip,humidity,day,month,bph] 6\n",
    "    #Multivariate = [temp,precip,humidity,day,month,bph] + [rice] \n",
    "\n",
    "    values_train = frames_train.values    \n",
    "    n_features = frames_train.shape[1]\n",
    "    values_validation = frames_val.values\n",
    "    # plot_data(frames_train,'Data train')\n",
    "\n",
    "    # from sklearn.preprocessing import MinMaxScaler\n",
    "    # from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # In_day   Out_day  n_seq   n_steps\n",
    "    #    7      1\n",
    "    #    7      3\n",
    "    #    7      5\n",
    "    #    7      7\n",
    "    #   14      1\n",
    "    #   14      3\n",
    "    #   14      5\n",
    "    #   14      7\n",
    "    #   21      1\n",
    "    #   21      3\n",
    "    #   21      5\n",
    "    #   21      7\n",
    "\n",
    "    Epochs = int(Epoc)\n",
    "    n_day = int(n_input)\n",
    "    n_out = int(n_output)\n",
    "\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(values_train, n_day, n_out)\n",
    "    # print(reframed.shape)\n",
    "    # print(reframed.head())\n",
    "\n",
    "    # predict datasets\n",
    "    values = reframed.values\n",
    "    train = values\n",
    "\n",
    "    #input \n",
    "    n_obs = n_day * n_features\n",
    "    train_X, train_y = train[:, :n_obs], train[:, -1]\n",
    "    print(train_X.shape, train_y.shape)  \n",
    "\n",
    "    # for i in range(len(train_X)):\n",
    "    # \tprint(train_X[i], train_y[i])\n",
    "\n",
    "    subsequences = 2\n",
    "    timesteps = train_X.shape[1]//subsequences\n",
    "    train_X = train_X.reshape((train_X.shape[0], subsequences, timesteps, 1))\n",
    "    print(train_X.shape, train_y.shape)\n",
    "\n",
    "    #---------------------------------------------------------------------------------#\n",
    "\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(values_validation, n_day, n_out)\n",
    "    # print(reframed.shape)\n",
    "    # print(reframed.head())\n",
    "\n",
    "    # predict datasets\n",
    "    values = reframed.values\n",
    "    validat = values\n",
    "\n",
    "    #input \n",
    "    n_obs = n_day * n_features\n",
    "    val_X, val_y = validat[:, :n_obs], validat[:, -1]\n",
    "    print(val_X.shape, val_y.shape)  \n",
    "\n",
    "    # for i in range(len(train_X)):\n",
    "    # \tprint(val_X[i], val_y[i])\n",
    "\n",
    "    timesteps = val_X.shape[1]//subsequences\n",
    "    val_X = val_X.reshape((val_X.shape[0], subsequences, timesteps, 1))\n",
    "    print(val_X.shape, val_y.shape)\n",
    "\n",
    "\n",
    "    # # define model A\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.TimeDistributed(layers.Conv1D(filters = 64, kernel_size=2, activation='relu'), input_shape=(None, train_X.shape[2], train_X.shape[3])))\n",
    "    model.add(layers.TimeDistributed(layers.Conv1D(filters = 64, kernel_size=2, activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.MaxPooling1D(pool_size=2)))\n",
    "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "    model.add(layers.LSTM(50, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # define model A\n",
    "    # model = models.Sequential()\n",
    "    # model.add(layers.TimeDistributed(layers.Conv1D(filters = 64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features_model)))\n",
    "    # # model.add(layers.TimeDistributed(layers.Conv1D(filters = 64, kernel_size=2, activation='relu')))\n",
    "    # model.add(layers.TimeDistributed(layers.MaxPooling1D(pool_size=2)))\n",
    "    # model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "    # model.add(layers.LSTM(100, activation='relu'))\n",
    "    # model.add(layers.Dense(1))\n",
    "\n",
    "    # # define model\n",
    "    # model = models.Sequential()\n",
    "    # model.add(layers.Conv1D(filters = 64, kernel_size=2, activation='relu', input_shape=(None, n_steps, n_features_model)))\n",
    "    # # model.add(layers.Conv1D(filters = 64, kernel_size=2, activation='relu'))\n",
    "    # model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    # model.add(layers.Flatten())\n",
    "    # model.add(layers.LSTM(50, activation='relu'))\n",
    "    # model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    history = model.fit(train_X, train_y, validation_data=(val_X, val_y),epochs= Epochs, verbose=1)\n",
    "\n",
    "    # plot history\n",
    "    from matplotlib import pyplot as plt1\n",
    "    def plot_loss(history):\n",
    "        plt1.figure(figsize=(10,7))\n",
    "        plt1.plot(history.history['loss'], label='train')\n",
    "        plt1.xlabel('Epoch  '+'loss = %f'%history.history['loss'][-1])\n",
    "        plt1.ylabel('Error')\n",
    "        plt1.legend()\n",
    "        plt1.grid(True)\n",
    "    #     plt.show()\n",
    "    plot_loss(history)\n",
    "    # Export_folder_name = \"/Users/MSI-1016TH/Documents/ผลการทดลอง/\"\n",
    "    # Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง/\"\n",
    "    plot_name_T = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+str(len(list(frames_train.columns)))+'V'+'-T'+'.png'\n",
    "    plt1.savefig(Export_folder_name + plot_name_T)\n",
    "    plt1.close()\n",
    "\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    values_predict = frames_test.values\n",
    "    n_features = frames_test.shape[1]\n",
    "    df = frames_test.reset_index()\n",
    "    date_time_predict = pd.to_datetime(df.pop('date'))\n",
    "\n",
    "    \n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(values_predict, n_day, n_out)\n",
    "    # print(reframed.shape)\n",
    "    # print(reframed.head())\n",
    "        \n",
    "    # predict datasets\n",
    "    values = reframed.values\n",
    "    # n_train_day = int(values.shape[0]*0.9)\n",
    "    # train = values[:n_train_day, :]\n",
    "    test = values\n",
    "        \n",
    "    # predict into input and outputs\n",
    "    n_obs = n_day * n_features\n",
    "    # test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "    test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "    print(test_X.shape, test_y.shape)\n",
    "\n",
    "    timesteps = test_X.shape[1]//subsequences\n",
    "    test_X = test_X.reshape((test_X.shape[0], subsequences, timesteps, 1))\n",
    "    print(test_X.shape, test_y.shape)\n",
    "\n",
    "    ## make a prediction\n",
    "    yhat = model.predict(test_X,verbose=0)\n",
    "\n",
    "\n",
    "    df_out = pd.DataFrame(list(date_time_predict[n_day+n_out-1:]),columns=['date'])\n",
    "    df_out['actual'] = pd.DataFrame(list(test_y))\n",
    "    df_out['predict'] = pd.DataFrame(list(yhat))\n",
    "\n",
    "    # calculate RMSE\n",
    "    m = tf.keras.metrics.RootMeanSquaredError()\n",
    "    m.update_state([df_out['actual']], [df_out['predict']])\n",
    "    rmse_all = m.result().numpy()\n",
    "    print('RMSE-all: %.3f' % rmse_all)\n",
    "\n",
    "\n",
    "    d_range = 365-n_day-n_out-1\n",
    "    pre_start = 0 \n",
    "\n",
    "    pre_stop = pre_start+d_range\n",
    "\n",
    "    # calculate RMSE\n",
    "    m = tf.keras.metrics.RootMeanSquaredError()\n",
    "    m.update_state(df_out['actual'][pre_start:pre_stop], df_out['predict'][pre_start:pre_stop])\n",
    "    rmse = m.result().numpy()\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "\n",
    "    strings = list(frames_test.columns)\n",
    "    textstr = '\\n'.join(strings[:18])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(6)\n",
    "    fig.set_figwidth(10)\n",
    "\n",
    "    ax.plot(df_out['date'][pre_start:pre_stop],df_out['actual'][pre_start:pre_stop],label='actual')\n",
    "    ax.plot(df_out['date'][pre_start:pre_stop],df_out['predict'][pre_start:pre_stop],label='predict')\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title('Multivariate-CNN_LSTM model-A' +'  RMSE: %.2f' % rmse)\n",
    "    ax.set_xlabel('time (day) '+'(%d-'%n_day+'%d-'%n_out+'Epoch %d)'%Epochs)\n",
    "    ax.set_ylabel('BPH Volume')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', alpha=0.5)\n",
    "\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    \n",
    "    file_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+str(len(strings))+'V'\n",
    "    # plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+str(len(strings))+'V'+'.png'\n",
    "    plot_name = file_name +'.png'\n",
    "    plt.savefig(Export_folder_name + plot_name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    #Output : file name and Path Save file\n",
    "    # file_name_save = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+str(len(strings))+'V'+'.csv'\n",
    "    file_name_save = file_name +'.csv'\n",
    "    dataset_path_save = Export_folder_name + file_name_save\n",
    "    df_out.to_csv(dataset_path_save, index=False, encoding=\"TIS-620\")\n",
    "    print(\"{} {}\" .format(dataset_path_save,len(df_out)))\n",
    "    del df_out,model\n",
    "    return  str(file_name),str(rmse),str(rmse_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37239, 168) (37239,)\n",
      "(37239, 2, 84, 1) (37239,)\n",
      "(12385, 168) (12385,)\n",
      "(12385, 2, 84, 1) (12385,)\n",
      "Epoch 1/500\n",
      "1164/1164 [==============================] - 15s 12ms/step - loss: 20.9516 - accuracy: 0.3384 - val_loss: 15.1852 - val_accuracy: 0.4753\n",
      "Epoch 2/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 14.4641 - accuracy: 0.3946 - val_loss: 13.9639 - val_accuracy: 0.3358\n",
      "Epoch 3/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 12.7988 - accuracy: 0.3989 - val_loss: 13.4355 - val_accuracy: 0.4839\n",
      "Epoch 4/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 13.6310 - accuracy: 0.4011 - val_loss: 14.1456 - val_accuracy: 0.4831\n",
      "Epoch 5/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 13.5520 - accuracy: 0.4056 - val_loss: 13.9909 - val_accuracy: 0.4835\n",
      "Epoch 6/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 12.3547 - accuracy: 0.4048 - val_loss: 12.0523 - val_accuracy: 0.4578\n",
      "Epoch 7/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.5608 - accuracy: 0.4039 - val_loss: 11.5643 - val_accuracy: 0.4780\n",
      "Epoch 8/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 13.7233 - accuracy: 0.4053 - val_loss: 12.8418 - val_accuracy: 0.4836\n",
      "Epoch 9/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.8027 - accuracy: 0.4014 - val_loss: 10.6633 - val_accuracy: 0.4844\n",
      "Epoch 10/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.6761 - accuracy: 0.4019 - val_loss: 10.8102 - val_accuracy: 0.4841\n",
      "Epoch 11/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 12.7918 - accuracy: 0.4002 - val_loss: 10.1792 - val_accuracy: 0.4827\n",
      "Epoch 12/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.6879 - accuracy: 0.4079 - val_loss: 10.3115 - val_accuracy: 0.4836\n",
      "Epoch 13/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.3924 - accuracy: 0.4075 - val_loss: 11.0461 - val_accuracy: 0.4845\n",
      "Epoch 14/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 13.1831 - accuracy: 0.4046 - val_loss: 10.4795 - val_accuracy: 0.4821\n",
      "Epoch 15/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 12.8243 - accuracy: 0.4040 - val_loss: 10.7077 - val_accuracy: 0.4834\n",
      "Epoch 16/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.2487 - accuracy: 0.4072 - val_loss: 10.3979 - val_accuracy: 0.4845\n",
      "Epoch 17/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 11.4505 - accuracy: 0.4070 - val_loss: 11.3392 - val_accuracy: 0.4832\n",
      "Epoch 18/500\n",
      "1164/1164 [==============================] - 15s 12ms/step - loss: 12.0649 - accuracy: 0.4075 - val_loss: 10.1926 - val_accuracy: 0.4844\n",
      "Epoch 19/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 11.5623 - accuracy: 0.4058 - val_loss: 11.0416 - val_accuracy: 0.4845\n",
      "Epoch 20/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.7676 - accuracy: 0.4038 - val_loss: 10.0744 - val_accuracy: 0.4848\n",
      "Epoch 21/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.6872 - accuracy: 0.4071 - val_loss: 10.0017 - val_accuracy: 0.4846\n",
      "Epoch 22/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.6113 - accuracy: 0.4053 - val_loss: 10.2723 - val_accuracy: 0.4849\n",
      "Epoch 23/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.8877 - accuracy: 0.4031 - val_loss: 11.6307 - val_accuracy: 0.4857\n",
      "Epoch 24/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.7770 - accuracy: 0.4044 - val_loss: 11.0674 - val_accuracy: 0.4734\n",
      "Epoch 25/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.3959 - accuracy: 0.3996 - val_loss: 10.7506 - val_accuracy: 0.4843\n",
      "Epoch 26/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.4618 - accuracy: 0.4035 - val_loss: 12.1844 - val_accuracy: 0.4849\n",
      "Epoch 27/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.1142 - accuracy: 0.4065 - val_loss: 9.8149 - val_accuracy: 0.4810\n",
      "Epoch 28/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.5942 - accuracy: 0.4019 - val_loss: 9.5041 - val_accuracy: 0.4852\n",
      "Epoch 29/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.4570 - accuracy: 0.4043 - val_loss: 10.3106 - val_accuracy: 0.4837\n",
      "Epoch 30/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.5979 - accuracy: 0.4069 - val_loss: 10.1811 - val_accuracy: 0.4851\n",
      "Epoch 31/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.9324 - accuracy: 0.4059 - val_loss: 10.4048 - val_accuracy: 0.4844\n",
      "Epoch 32/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.9133 - accuracy: 0.4067 - val_loss: 10.6547 - val_accuracy: 0.4845\n",
      "Epoch 33/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.4536 - accuracy: 0.4021 - val_loss: 10.4130 - val_accuracy: 0.4851\n",
      "Epoch 34/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 12.0635 - accuracy: 0.4019 - val_loss: 11.7438 - val_accuracy: 0.4846\n",
      "Epoch 35/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.0464 - accuracy: 0.4016 - val_loss: 10.2968 - val_accuracy: 0.4846\n",
      "Epoch 36/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.2243 - accuracy: 0.4043 - val_loss: 9.8966 - val_accuracy: 0.4831\n",
      "Epoch 37/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.1771 - accuracy: 0.4092 - val_loss: 10.8619 - val_accuracy: 0.4846\n",
      "Epoch 38/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.7265 - accuracy: 0.4041 - val_loss: 10.5006 - val_accuracy: 0.4850\n",
      "Epoch 39/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 12.4911 - accuracy: 0.4007 - val_loss: 10.5642 - val_accuracy: 0.4849\n",
      "Epoch 40/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.6364 - accuracy: 0.4037 - val_loss: 10.4800 - val_accuracy: 0.4848\n",
      "Epoch 41/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.8168 - accuracy: 0.4086 - val_loss: 11.4603 - val_accuracy: 0.4845\n",
      "Epoch 42/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.0046 - accuracy: 0.4055 - val_loss: 11.1515 - val_accuracy: 0.4846\n",
      "Epoch 43/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.4126 - accuracy: 0.4008 - val_loss: 9.7280 - val_accuracy: 0.4843\n",
      "Epoch 44/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.6749 - accuracy: 0.4068 - val_loss: 9.8730 - val_accuracy: 0.4820\n",
      "Epoch 45/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.0538 - accuracy: 0.4087 - val_loss: 9.9371 - val_accuracy: 0.4854\n",
      "Epoch 46/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.5148 - accuracy: 0.4069 - val_loss: 11.0793 - val_accuracy: 0.4849\n",
      "Epoch 47/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.2478 - accuracy: 0.4063 - val_loss: 10.0163 - val_accuracy: 0.4824\n",
      "Epoch 48/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.3002 - accuracy: 0.4034 - val_loss: 10.5182 - val_accuracy: 0.4852\n",
      "Epoch 49/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.7816 - accuracy: 0.4021 - val_loss: 10.5311 - val_accuracy: 0.4853\n",
      "Epoch 50/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.7983 - accuracy: 0.4029 - val_loss: 11.4696 - val_accuracy: 0.4854\n",
      "Epoch 51/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.6261 - accuracy: 0.4022 - val_loss: 11.1178 - val_accuracy: 0.4852\n",
      "Epoch 52/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 10.6546 - accuracy: 0.4012 - val_loss: 10.5335 - val_accuracy: 0.4853\n",
      "Epoch 53/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 11.0466 - accuracy: 0.4043 - val_loss: 10.3326 - val_accuracy: 0.4851\n",
      "Epoch 54/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.1802 - accuracy: 0.4083 - val_loss: 10.2147 - val_accuracy: 0.4853\n",
      "Epoch 55/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.1093 - accuracy: 0.4067 - val_loss: 10.2281 - val_accuracy: 0.4852\n",
      "Epoch 56/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.7807 - accuracy: 0.4060 - val_loss: 10.1064 - val_accuracy: 0.4855\n",
      "Epoch 57/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.8475 - accuracy: 0.4051 - val_loss: 10.5932 - val_accuracy: 0.4857\n",
      "Epoch 58/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.8841 - accuracy: 0.4011 - val_loss: 10.4150 - val_accuracy: 0.4853\n",
      "Epoch 59/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 11.3353 - accuracy: 0.4121 - val_loss: 10.1733 - val_accuracy: 0.4862\n",
      "Epoch 60/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.5702 - accuracy: 0.4046 - val_loss: 10.4931 - val_accuracy: 0.4841\n",
      "Epoch 61/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 10.0833 - accuracy: 0.4039 - val_loss: 10.2240 - val_accuracy: 0.4848\n",
      "Epoch 62/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.7072 - accuracy: 0.4041 - val_loss: 10.2018 - val_accuracy: 0.4849\n",
      "Epoch 63/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.4122 - accuracy: 0.4073 - val_loss: 10.1618 - val_accuracy: 0.4854\n",
      "Epoch 64/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.7656 - accuracy: 0.4092 - val_loss: 10.7580 - val_accuracy: 0.4862\n",
      "Epoch 65/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.7844 - accuracy: 0.4080 - val_loss: 10.5966 - val_accuracy: 0.4851\n",
      "Epoch 66/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.1985 - accuracy: 0.4077 - val_loss: 10.9680 - val_accuracy: 0.4853\n",
      "Epoch 67/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.2712 - accuracy: 0.4055 - val_loss: 10.4377 - val_accuracy: 0.4862\n",
      "Epoch 68/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 9.9679 - accuracy: 0.4070 - val_loss: 10.9141 - val_accuracy: 0.4860\n",
      "Epoch 69/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.2259 - accuracy: 0.4077 - val_loss: 10.3068 - val_accuracy: 0.4853\n",
      "Epoch 70/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.7362 - accuracy: 0.4079 - val_loss: 9.9398 - val_accuracy: 0.4858\n",
      "Epoch 71/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.3722 - accuracy: 0.4052 - val_loss: 10.1025 - val_accuracy: 0.4853\n",
      "Epoch 72/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.6799 - accuracy: 0.4061 - val_loss: 10.3378 - val_accuracy: 0.4865\n",
      "Epoch 73/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.2961 - accuracy: 0.4032 - val_loss: 10.4925 - val_accuracy: 0.4861\n",
      "Epoch 74/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.8034 - accuracy: 0.4049 - val_loss: 10.1030 - val_accuracy: 0.4853\n",
      "Epoch 75/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0718 - accuracy: 0.4019 - val_loss: 10.2219 - val_accuracy: 0.4866\n",
      "Epoch 76/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.2717 - accuracy: 0.4038 - val_loss: 10.3507 - val_accuracy: 0.4864\n",
      "Epoch 77/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.3144 - accuracy: 0.4059 - val_loss: 10.2827 - val_accuracy: 0.4852\n",
      "Epoch 78/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.1659 - accuracy: 0.4085 - val_loss: 12.1551 - val_accuracy: 0.4862\n",
      "Epoch 79/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 10.0680 - accuracy: 0.4033 - val_loss: 10.1503 - val_accuracy: 0.4857\n",
      "Epoch 80/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0856 - accuracy: 0.4104 - val_loss: 10.1737 - val_accuracy: 0.4850\n",
      "Epoch 81/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.3410 - accuracy: 0.4121 - val_loss: 11.3869 - val_accuracy: 0.4862\n",
      "Epoch 82/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0482 - accuracy: 0.4009 - val_loss: 10.9993 - val_accuracy: 0.4848\n",
      "Epoch 83/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.6012 - accuracy: 0.4017 - val_loss: 10.5742 - val_accuracy: 0.4852\n",
      "Epoch 84/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.6607 - accuracy: 0.4046 - val_loss: 10.5165 - val_accuracy: 0.4859\n",
      "Epoch 85/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0637 - accuracy: 0.4075 - val_loss: 10.5339 - val_accuracy: 0.4869\n",
      "Epoch 86/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0567 - accuracy: 0.4067 - val_loss: 10.6706 - val_accuracy: 0.4853\n",
      "Epoch 87/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.1830 - accuracy: 0.4098 - val_loss: 10.2834 - val_accuracy: 0.4858\n",
      "Epoch 88/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 10.3790 - accuracy: 0.4070 - val_loss: 12.6887 - val_accuracy: 0.4859\n",
      "Epoch 89/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 9.7553 - accuracy: 0.4075 - val_loss: 11.1356 - val_accuracy: 0.4850\n",
      "Epoch 90/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.1819 - accuracy: 0.4040 - val_loss: 11.1955 - val_accuracy: 0.4849\n",
      "Epoch 91/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.5290 - accuracy: 0.4056 - val_loss: 11.7277 - val_accuracy: 0.4850\n",
      "Epoch 92/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.0744 - accuracy: 0.4111 - val_loss: 10.3711 - val_accuracy: 0.4862\n",
      "Epoch 93/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.8675 - accuracy: 0.4030 - val_loss: 11.0180 - val_accuracy: 0.4862\n",
      "Epoch 94/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.8284 - accuracy: 0.4036 - val_loss: 11.0571 - val_accuracy: 0.4853\n",
      "Epoch 95/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 10.4637 - accuracy: 0.4010 - val_loss: 10.6979 - val_accuracy: 0.4854\n",
      "Epoch 96/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.8130 - accuracy: 0.4077 - val_loss: 9.9254 - val_accuracy: 0.4862\n",
      "Epoch 97/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 9.1620 - accuracy: 0.4041 - val_loss: 10.9705 - val_accuracy: 0.4862\n",
      "Epoch 98/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.7066 - accuracy: 0.4055 - val_loss: 10.0520 - val_accuracy: 0.4865\n",
      "Epoch 99/500\n",
      "1164/1164 [==============================] - 12s 11ms/step - loss: 9.0348 - accuracy: 0.4020 - val_loss: 11.0973 - val_accuracy: 0.4860\n",
      "Epoch 100/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0922 - accuracy: 0.4039 - val_loss: 10.9397 - val_accuracy: 0.4856\n",
      "Epoch 101/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 9.4241 - accuracy: 0.4066 - val_loss: 10.1552 - val_accuracy: 0.4857\n",
      "Epoch 102/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.6851 - accuracy: 0.4023 - val_loss: 10.5044 - val_accuracy: 0.4857\n",
      "Epoch 103/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.7362 - accuracy: 0.4060 - val_loss: 10.4005 - val_accuracy: 0.4853\n",
      "Epoch 104/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.7932 - accuracy: 0.4079 - val_loss: 11.4464 - val_accuracy: 0.4853\n",
      "Epoch 105/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.1963 - accuracy: 0.4033 - val_loss: 10.6067 - val_accuracy: 0.4861\n",
      "Epoch 106/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.5572 - accuracy: 0.4086 - val_loss: 11.3624 - val_accuracy: 0.4857\n",
      "Epoch 107/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.0440 - accuracy: 0.4068 - val_loss: 10.1102 - val_accuracy: 0.4861\n",
      "Epoch 108/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.6471 - accuracy: 0.4041 - val_loss: 10.5836 - val_accuracy: 0.4857\n",
      "Epoch 109/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.2778 - accuracy: 0.4055 - val_loss: 10.9822 - val_accuracy: 0.4859\n",
      "Epoch 110/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.0187 - accuracy: 0.4053 - val_loss: 10.7485 - val_accuracy: 0.4860\n",
      "Epoch 111/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.4532 - accuracy: 0.4087 - val_loss: 11.4251 - val_accuracy: 0.4861\n",
      "Epoch 112/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.4329 - accuracy: 0.4059 - val_loss: 11.1850 - val_accuracy: 0.4857\n",
      "Epoch 113/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.1376 - accuracy: 0.4058 - val_loss: 11.5373 - val_accuracy: 0.4849\n",
      "Epoch 114/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 11.2112 - accuracy: 0.4080 - val_loss: 10.3975 - val_accuracy: 0.4850\n",
      "Epoch 115/500\n",
      "1164/1164 [==============================] - 15s 12ms/step - loss: 9.3607 - accuracy: 0.4000 - val_loss: 11.0049 - val_accuracy: 0.4855\n",
      "Epoch 116/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.3422 - accuracy: 0.4069 - val_loss: 10.7538 - val_accuracy: 0.4860\n",
      "Epoch 117/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8257 - accuracy: 0.4072 - val_loss: 11.4889 - val_accuracy: 0.4848\n",
      "Epoch 118/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.3004 - accuracy: 0.4124 - val_loss: 10.5960 - val_accuracy: 0.4853\n",
      "Epoch 119/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.1425 - accuracy: 0.4060 - val_loss: 10.9331 - val_accuracy: 0.4851\n",
      "Epoch 120/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2116 - accuracy: 0.4064 - val_loss: 11.4748 - val_accuracy: 0.4857\n",
      "Epoch 121/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.5392 - accuracy: 0.4080 - val_loss: 10.6804 - val_accuracy: 0.4858\n",
      "Epoch 122/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.9792 - accuracy: 0.4044 - val_loss: 11.0159 - val_accuracy: 0.4857\n",
      "Epoch 123/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2061 - accuracy: 0.4055 - val_loss: 10.9437 - val_accuracy: 0.4849\n",
      "Epoch 124/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.3440 - accuracy: 0.4103 - val_loss: 10.5519 - val_accuracy: 0.4850\n",
      "Epoch 125/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.7340 - accuracy: 0.4074 - val_loss: 10.3836 - val_accuracy: 0.4851\n",
      "Epoch 126/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9229 - accuracy: 0.4071 - val_loss: 10.2647 - val_accuracy: 0.4857\n",
      "Epoch 127/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.8014 - accuracy: 0.4052 - val_loss: 11.0107 - val_accuracy: 0.4856\n",
      "Epoch 128/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.6200 - accuracy: 0.4043 - val_loss: 10.5572 - val_accuracy: 0.4860\n",
      "Epoch 129/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.0999 - accuracy: 0.4073 - val_loss: 11.1103 - val_accuracy: 0.4851\n",
      "Epoch 130/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.6445 - accuracy: 0.4048 - val_loss: 11.1715 - val_accuracy: 0.4861\n",
      "Epoch 131/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.6282 - accuracy: 0.4105 - val_loss: 10.2519 - val_accuracy: 0.4861\n",
      "Epoch 132/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.9712 - accuracy: 0.4023 - val_loss: 10.3974 - val_accuracy: 0.4851\n",
      "Epoch 133/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.9335 - accuracy: 0.3988 - val_loss: 10.6295 - val_accuracy: 0.4856\n",
      "Epoch 134/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.0801 - accuracy: 0.4082 - val_loss: 11.0908 - val_accuracy: 0.4863\n",
      "Epoch 135/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2356 - accuracy: 0.4090 - val_loss: 10.5322 - val_accuracy: 0.4861\n",
      "Epoch 136/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.0683 - accuracy: 0.4039 - val_loss: 10.8539 - val_accuracy: 0.4855\n",
      "Epoch 137/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.3246 - accuracy: 0.4074 - val_loss: 10.8121 - val_accuracy: 0.4859\n",
      "Epoch 138/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 9.0329 - accuracy: 0.4061 - val_loss: 10.7500 - val_accuracy: 0.4860\n",
      "Epoch 139/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.3987 - accuracy: 0.4026 - val_loss: 10.7659 - val_accuracy: 0.4857\n",
      "Epoch 140/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.4967 - accuracy: 0.4035 - val_loss: 10.4642 - val_accuracy: 0.4860\n",
      "Epoch 141/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5777 - accuracy: 0.4072 - val_loss: 10.8518 - val_accuracy: 0.4853\n",
      "Epoch 142/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.7291 - accuracy: 0.4032 - val_loss: 10.6432 - val_accuracy: 0.4854\n",
      "Epoch 143/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8284 - accuracy: 0.4045 - val_loss: 11.2698 - val_accuracy: 0.4853\n",
      "Epoch 144/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.6947 - accuracy: 0.4059 - val_loss: 10.8712 - val_accuracy: 0.4861\n",
      "Epoch 145/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8106 - accuracy: 0.4073 - val_loss: 11.5902 - val_accuracy: 0.4855\n",
      "Epoch 146/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2529 - accuracy: 0.4053 - val_loss: 12.0963 - val_accuracy: 0.4860\n",
      "Epoch 147/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.4661 - accuracy: 0.4081 - val_loss: 10.4408 - val_accuracy: 0.4848\n",
      "Epoch 148/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.9196 - accuracy: 0.4051 - val_loss: 10.2909 - val_accuracy: 0.4859\n",
      "Epoch 149/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.8419 - accuracy: 0.4070 - val_loss: 11.4212 - val_accuracy: 0.4858\n",
      "Epoch 150/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.5618 - accuracy: 0.4049 - val_loss: 10.5742 - val_accuracy: 0.4857\n",
      "Epoch 151/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.0383 - accuracy: 0.4081 - val_loss: 10.9903 - val_accuracy: 0.4851\n",
      "Epoch 152/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.1899 - accuracy: 0.4045 - val_loss: 11.0549 - val_accuracy: 0.4860\n",
      "Epoch 153/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.7795 - accuracy: 0.4049 - val_loss: 10.7063 - val_accuracy: 0.4857\n",
      "Epoch 154/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2537 - accuracy: 0.4008 - val_loss: 11.0692 - val_accuracy: 0.4858\n",
      "Epoch 155/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.0613 - accuracy: 0.4039 - val_loss: 10.4362 - val_accuracy: 0.4859\n",
      "Epoch 156/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5518 - accuracy: 0.4073 - val_loss: 10.4121 - val_accuracy: 0.4857\n",
      "Epoch 157/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3775 - accuracy: 0.4055 - val_loss: 11.6999 - val_accuracy: 0.4865\n",
      "Epoch 158/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.6062 - accuracy: 0.4066 - val_loss: 12.0624 - val_accuracy: 0.4855\n",
      "Epoch 159/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.9488 - accuracy: 0.4019 - val_loss: 11.7985 - val_accuracy: 0.4794\n",
      "Epoch 160/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.7983 - accuracy: 0.4050 - val_loss: 10.9810 - val_accuracy: 0.4852\n",
      "Epoch 161/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.4486 - accuracy: 0.4026 - val_loss: 10.6643 - val_accuracy: 0.4861\n",
      "Epoch 162/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.7328 - accuracy: 0.4065 - val_loss: 10.4202 - val_accuracy: 0.4858\n",
      "Epoch 163/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5846 - accuracy: 0.4072 - val_loss: 11.4158 - val_accuracy: 0.4856\n",
      "Epoch 164/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.3790 - accuracy: 0.4046 - val_loss: 11.1024 - val_accuracy: 0.4857\n",
      "Epoch 165/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.8127 - accuracy: 0.4042 - val_loss: 11.4136 - val_accuracy: 0.4852\n",
      "Epoch 166/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 10.5446 - accuracy: 0.4041 - val_loss: 10.8963 - val_accuracy: 0.4859\n",
      "Epoch 167/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.9832 - accuracy: 0.4077 - val_loss: 11.5733 - val_accuracy: 0.4853\n",
      "Epoch 168/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.7866 - accuracy: 0.4054 - val_loss: 11.2549 - val_accuracy: 0.4862\n",
      "Epoch 169/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5054 - accuracy: 0.4091 - val_loss: 11.3647 - val_accuracy: 0.4853\n",
      "Epoch 170/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.2973 - accuracy: 0.4039 - val_loss: 11.3292 - val_accuracy: 0.4845\n",
      "Epoch 171/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2544 - accuracy: 0.4040 - val_loss: 10.9218 - val_accuracy: 0.4853\n",
      "Epoch 172/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8995 - accuracy: 0.4114 - val_loss: 10.7298 - val_accuracy: 0.4856\n",
      "Epoch 173/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8608 - accuracy: 0.4082 - val_loss: 11.0141 - val_accuracy: 0.4806\n",
      "Epoch 174/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7027 - accuracy: 0.4079 - val_loss: 10.9358 - val_accuracy: 0.4860\n",
      "Epoch 175/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9716 - accuracy: 0.4029 - val_loss: 10.8798 - val_accuracy: 0.4852\n",
      "Epoch 176/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1045 - accuracy: 0.4051 - val_loss: 11.2503 - val_accuracy: 0.4851\n",
      "Epoch 177/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3126 - accuracy: 0.4032 - val_loss: 10.9018 - val_accuracy: 0.4860\n",
      "Epoch 178/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8784 - accuracy: 0.4046 - val_loss: 11.7509 - val_accuracy: 0.4859\n",
      "Epoch 179/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.6216 - accuracy: 0.4028 - val_loss: 10.7453 - val_accuracy: 0.4863\n",
      "Epoch 180/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.7063 - accuracy: 0.4069 - val_loss: 10.9736 - val_accuracy: 0.4849\n",
      "Epoch 181/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.1412 - accuracy: 0.4088 - val_loss: 10.9235 - val_accuracy: 0.4854\n",
      "Epoch 182/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5120 - accuracy: 0.4064 - val_loss: 11.2388 - val_accuracy: 0.4856\n",
      "Epoch 183/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1969 - accuracy: 0.4062 - val_loss: 11.0782 - val_accuracy: 0.4854\n",
      "Epoch 184/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1019 - accuracy: 0.4057 - val_loss: 11.2617 - val_accuracy: 0.4846\n",
      "Epoch 185/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8554 - accuracy: 0.4116 - val_loss: 10.7166 - val_accuracy: 0.4862\n",
      "Epoch 186/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1776 - accuracy: 0.4102 - val_loss: 11.3331 - val_accuracy: 0.4859\n",
      "Epoch 187/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.8778 - accuracy: 0.4034 - val_loss: 10.7964 - val_accuracy: 0.4862\n",
      "Epoch 188/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7306 - accuracy: 0.4076 - val_loss: 11.2274 - val_accuracy: 0.4852\n",
      "Epoch 189/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.2764 - accuracy: 0.4045 - val_loss: 10.9925 - val_accuracy: 0.4853\n",
      "Epoch 190/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5805 - accuracy: 0.4090 - val_loss: 11.6704 - val_accuracy: 0.4851\n",
      "Epoch 191/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3651 - accuracy: 0.4040 - val_loss: 11.1525 - val_accuracy: 0.4853\n",
      "Epoch 192/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1464 - accuracy: 0.4030 - val_loss: 11.0405 - val_accuracy: 0.4849\n",
      "Epoch 193/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8817 - accuracy: 0.4049 - val_loss: 10.9027 - val_accuracy: 0.4849\n",
      "Epoch 194/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.1043 - accuracy: 0.4070 - val_loss: 11.7308 - val_accuracy: 0.4857\n",
      "Epoch 195/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.8749 - accuracy: 0.4013 - val_loss: 11.1605 - val_accuracy: 0.4862\n",
      "Epoch 196/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.6631 - accuracy: 0.4035 - val_loss: 11.5191 - val_accuracy: 0.4859\n",
      "Epoch 197/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.9294 - accuracy: 0.4072 - val_loss: 10.8360 - val_accuracy: 0.4855\n",
      "Epoch 198/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.2148 - accuracy: 0.4033 - val_loss: 11.0711 - val_accuracy: 0.4861\n",
      "Epoch 199/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1118 - accuracy: 0.4075 - val_loss: 11.4418 - val_accuracy: 0.4857\n",
      "Epoch 200/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8672 - accuracy: 0.4067 - val_loss: 11.5452 - val_accuracy: 0.4857\n",
      "Epoch 201/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.6439 - accuracy: 0.4035 - val_loss: 11.1250 - val_accuracy: 0.4766\n",
      "Epoch 202/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1160 - accuracy: 0.4053 - val_loss: 11.7969 - val_accuracy: 0.4846\n",
      "Epoch 203/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0689 - accuracy: 0.4057 - val_loss: 11.5312 - val_accuracy: 0.4859\n",
      "Epoch 204/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5943 - accuracy: 0.4055 - val_loss: 10.5611 - val_accuracy: 0.4857\n",
      "Epoch 205/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.5710 - accuracy: 0.4038 - val_loss: 11.1784 - val_accuracy: 0.4857\n",
      "Epoch 206/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.4526 - accuracy: 0.4044 - val_loss: 11.0890 - val_accuracy: 0.4849\n",
      "Epoch 207/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0533 - accuracy: 0.4031 - val_loss: 10.3855 - val_accuracy: 0.4855\n",
      "Epoch 208/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6484 - accuracy: 0.4036 - val_loss: 10.6323 - val_accuracy: 0.4848\n",
      "Epoch 209/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0524 - accuracy: 0.4048 - val_loss: 10.6773 - val_accuracy: 0.4825\n",
      "Epoch 210/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5812 - accuracy: 0.4044 - val_loss: 11.2197 - val_accuracy: 0.4856\n",
      "Epoch 211/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.2953 - accuracy: 0.4092 - val_loss: 10.9586 - val_accuracy: 0.4854\n",
      "Epoch 212/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7804 - accuracy: 0.4033 - val_loss: 11.3144 - val_accuracy: 0.4857\n",
      "Epoch 213/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0437 - accuracy: 0.4090 - val_loss: 10.5426 - val_accuracy: 0.4855\n",
      "Epoch 214/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6841 - accuracy: 0.4120 - val_loss: 10.5906 - val_accuracy: 0.4861\n",
      "Epoch 215/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5393 - accuracy: 0.4080 - val_loss: 10.7900 - val_accuracy: 0.4860\n",
      "Epoch 216/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1808 - accuracy: 0.4042 - val_loss: 12.2079 - val_accuracy: 0.4857\n",
      "Epoch 217/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.7465 - accuracy: 0.4042 - val_loss: 11.4202 - val_accuracy: 0.4854\n",
      "Epoch 218/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9926 - accuracy: 0.4010 - val_loss: 11.4789 - val_accuracy: 0.4859\n",
      "Epoch 219/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.2168 - accuracy: 0.4082 - val_loss: 10.6102 - val_accuracy: 0.4849\n",
      "Epoch 220/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0985 - accuracy: 0.4037 - val_loss: 11.3335 - val_accuracy: 0.4856\n",
      "Epoch 221/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8359 - accuracy: 0.4078 - val_loss: 11.0463 - val_accuracy: 0.4854\n",
      "Epoch 222/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9766 - accuracy: 0.4039 - val_loss: 11.5036 - val_accuracy: 0.4851\n",
      "Epoch 223/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9524 - accuracy: 0.3984 - val_loss: 11.3135 - val_accuracy: 0.4855\n",
      "Epoch 224/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7068 - accuracy: 0.4047 - val_loss: 11.7779 - val_accuracy: 0.4855\n",
      "Epoch 225/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1683 - accuracy: 0.4021 - val_loss: 11.7922 - val_accuracy: 0.4857\n",
      "Epoch 226/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7131 - accuracy: 0.4093 - val_loss: 10.7711 - val_accuracy: 0.4843\n",
      "Epoch 227/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6159 - accuracy: 0.4109 - val_loss: 11.9716 - val_accuracy: 0.4861\n",
      "Epoch 228/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.7822 - accuracy: 0.4075 - val_loss: 11.5353 - val_accuracy: 0.4857\n",
      "Epoch 229/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3551 - accuracy: 0.4043 - val_loss: 10.7524 - val_accuracy: 0.4857\n",
      "Epoch 230/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.4724 - accuracy: 0.4046 - val_loss: 11.2926 - val_accuracy: 0.4861\n",
      "Epoch 231/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.9167 - accuracy: 0.4025 - val_loss: 11.3044 - val_accuracy: 0.4858\n",
      "Epoch 232/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.9712 - accuracy: 0.4037 - val_loss: 12.6210 - val_accuracy: 0.4857\n",
      "Epoch 233/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.4802 - accuracy: 0.4056 - val_loss: 11.6980 - val_accuracy: 0.4857\n",
      "Epoch 234/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6629 - accuracy: 0.4043 - val_loss: 11.1735 - val_accuracy: 0.4858\n",
      "Epoch 235/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5308 - accuracy: 0.4046 - val_loss: 11.3376 - val_accuracy: 0.4858\n",
      "Epoch 236/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5485 - accuracy: 0.3999 - val_loss: 11.2378 - val_accuracy: 0.4858\n",
      "Epoch 237/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.5765 - accuracy: 0.4069 - val_loss: 11.3417 - val_accuracy: 0.4852\n",
      "Epoch 238/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5315 - accuracy: 0.4058 - val_loss: 10.8136 - val_accuracy: 0.4853\n",
      "Epoch 239/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5693 - accuracy: 0.4002 - val_loss: 10.8614 - val_accuracy: 0.4863\n",
      "Epoch 240/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.9500 - accuracy: 0.3991 - val_loss: 11.3820 - val_accuracy: 0.4853\n",
      "Epoch 241/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.0970 - accuracy: 0.4067 - val_loss: 12.0890 - val_accuracy: 0.4854\n",
      "Epoch 242/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 9.5378 - accuracy: 0.4100 - val_loss: 12.0289 - val_accuracy: 0.4857\n",
      "Epoch 243/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.7434 - accuracy: 0.4044 - val_loss: 11.1873 - val_accuracy: 0.4853\n",
      "Epoch 244/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.8053 - accuracy: 0.4052 - val_loss: 11.8489 - val_accuracy: 0.4860\n",
      "Epoch 245/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0308 - accuracy: 0.4063 - val_loss: 11.6123 - val_accuracy: 0.4862\n",
      "Epoch 246/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.6400 - accuracy: 0.4049 - val_loss: 11.7251 - val_accuracy: 0.4853\n",
      "Epoch 247/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7308 - accuracy: 0.4064 - val_loss: 11.1549 - val_accuracy: 0.4860\n",
      "Epoch 248/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.7521 - accuracy: 0.4100 - val_loss: 11.4740 - val_accuracy: 0.4852\n",
      "Epoch 249/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5343 - accuracy: 0.4049 - val_loss: 11.7969 - val_accuracy: 0.4845\n",
      "Epoch 250/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.0978 - accuracy: 0.4087 - val_loss: 12.2044 - val_accuracy: 0.4853\n",
      "Epoch 251/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.3881 - accuracy: 0.4052 - val_loss: 11.7879 - val_accuracy: 0.4857\n",
      "Epoch 252/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9037 - accuracy: 0.4051 - val_loss: 11.0549 - val_accuracy: 0.4859\n",
      "Epoch 253/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9963 - accuracy: 0.4070 - val_loss: 11.0623 - val_accuracy: 0.4861\n",
      "Epoch 254/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 9.0643 - accuracy: 0.4051 - val_loss: 11.0098 - val_accuracy: 0.4854\n",
      "Epoch 255/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.5768 - accuracy: 0.4064 - val_loss: 11.0746 - val_accuracy: 0.4859\n",
      "Epoch 256/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8414 - accuracy: 0.4027 - val_loss: 11.5327 - val_accuracy: 0.4847\n",
      "Epoch 257/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.5039 - accuracy: 0.4063 - val_loss: 11.1539 - val_accuracy: 0.4857\n",
      "Epoch 258/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8472 - accuracy: 0.4104 - val_loss: 10.9676 - val_accuracy: 0.4862\n",
      "Epoch 259/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8005 - accuracy: 0.4041 - val_loss: 11.4583 - val_accuracy: 0.4857\n",
      "Epoch 260/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9496 - accuracy: 0.4089 - val_loss: 11.2381 - val_accuracy: 0.4862\n",
      "Epoch 261/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1162 - accuracy: 0.4005 - val_loss: 10.9663 - val_accuracy: 0.4854\n",
      "Epoch 262/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3539 - accuracy: 0.4065 - val_loss: 11.3148 - val_accuracy: 0.4853\n",
      "Epoch 263/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7443 - accuracy: 0.4021 - val_loss: 11.6914 - val_accuracy: 0.4862\n",
      "Epoch 264/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0063 - accuracy: 0.4132 - val_loss: 11.5570 - val_accuracy: 0.4858\n",
      "Epoch 265/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4117 - accuracy: 0.4030 - val_loss: 11.7008 - val_accuracy: 0.4855\n",
      "Epoch 266/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0831 - accuracy: 0.4081 - val_loss: 12.1820 - val_accuracy: 0.4859\n",
      "Epoch 267/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7271 - accuracy: 0.4087 - val_loss: 11.0478 - val_accuracy: 0.4853\n",
      "Epoch 268/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.2816 - accuracy: 0.4088 - val_loss: 11.9340 - val_accuracy: 0.4857\n",
      "Epoch 269/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.5896 - accuracy: 0.4066 - val_loss: 11.5489 - val_accuracy: 0.4856\n",
      "Epoch 270/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3926 - accuracy: 0.4091 - val_loss: 11.8771 - val_accuracy: 0.4858\n",
      "Epoch 271/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9604 - accuracy: 0.4080 - val_loss: 11.9974 - val_accuracy: 0.4858\n",
      "Epoch 272/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8681 - accuracy: 0.4044 - val_loss: 10.7618 - val_accuracy: 0.4858\n",
      "Epoch 273/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.8960 - accuracy: 0.4038 - val_loss: 11.2796 - val_accuracy: 0.4862\n",
      "Epoch 274/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1244 - accuracy: 0.4061 - val_loss: 11.0290 - val_accuracy: 0.4857\n",
      "Epoch 275/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7664 - accuracy: 0.4028 - val_loss: 11.3247 - val_accuracy: 0.4860\n",
      "Epoch 276/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8406 - accuracy: 0.4054 - val_loss: 11.9998 - val_accuracy: 0.4841\n",
      "Epoch 277/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4898 - accuracy: 0.4041 - val_loss: 11.7909 - val_accuracy: 0.4850\n",
      "Epoch 278/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 8.6096 - accuracy: 0.4043 - val_loss: 11.8438 - val_accuracy: 0.4859\n",
      "Epoch 279/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.2560 - accuracy: 0.4024 - val_loss: 11.8307 - val_accuracy: 0.4855\n",
      "Epoch 280/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8269 - accuracy: 0.4035 - val_loss: 11.1373 - val_accuracy: 0.4857\n",
      "Epoch 281/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3989 - accuracy: 0.4088 - val_loss: 11.0293 - val_accuracy: 0.4853\n",
      "Epoch 282/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.0138 - accuracy: 0.4125 - val_loss: 11.4638 - val_accuracy: 0.4858\n",
      "Epoch 283/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.2506 - accuracy: 0.4063 - val_loss: 12.4515 - val_accuracy: 0.4851\n",
      "Epoch 284/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3315 - accuracy: 0.4073 - val_loss: 11.3378 - val_accuracy: 0.4853\n",
      "Epoch 285/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.2736 - accuracy: 0.4020 - val_loss: 10.8487 - val_accuracy: 0.4853\n",
      "Epoch 286/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.3804 - accuracy: 0.4070 - val_loss: 11.7712 - val_accuracy: 0.4858\n",
      "Epoch 287/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.0748 - accuracy: 0.4082 - val_loss: 12.0597 - val_accuracy: 0.4857\n",
      "Epoch 288/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0128 - accuracy: 0.4034 - val_loss: 10.9582 - val_accuracy: 0.4860\n",
      "Epoch 289/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3299 - accuracy: 0.4011 - val_loss: 11.1898 - val_accuracy: 0.4853\n",
      "Epoch 290/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5978 - accuracy: 0.4064 - val_loss: 11.0408 - val_accuracy: 0.4852\n",
      "Epoch 291/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.6398 - accuracy: 0.4003 - val_loss: 11.4718 - val_accuracy: 0.4862\n",
      "Epoch 292/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.9116 - accuracy: 0.4044 - val_loss: 10.9899 - val_accuracy: 0.4849\n",
      "Epoch 293/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7634 - accuracy: 0.4006 - val_loss: 11.3077 - val_accuracy: 0.4856\n",
      "Epoch 294/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8413 - accuracy: 0.4062 - val_loss: 11.8016 - val_accuracy: 0.4848\n",
      "Epoch 295/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6136 - accuracy: 0.4041 - val_loss: 11.2418 - val_accuracy: 0.4858\n",
      "Epoch 296/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.9058 - accuracy: 0.4029 - val_loss: 11.9309 - val_accuracy: 0.4847\n",
      "Epoch 297/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8816 - accuracy: 0.4058 - val_loss: 11.6007 - val_accuracy: 0.4853\n",
      "Epoch 298/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5862 - accuracy: 0.4052 - val_loss: 11.5014 - val_accuracy: 0.4854\n",
      "Epoch 299/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8536 - accuracy: 0.4031 - val_loss: 11.7153 - val_accuracy: 0.4856\n",
      "Epoch 300/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2477 - accuracy: 0.4057 - val_loss: 11.6374 - val_accuracy: 0.4859\n",
      "Epoch 301/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3521 - accuracy: 0.4070 - val_loss: 11.7373 - val_accuracy: 0.4852\n",
      "Epoch 302/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1746 - accuracy: 0.4088 - val_loss: 12.4498 - val_accuracy: 0.4812\n",
      "Epoch 303/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.3445 - accuracy: 0.4041 - val_loss: 11.7313 - val_accuracy: 0.4858\n",
      "Epoch 304/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.5851 - accuracy: 0.4037 - val_loss: 12.1267 - val_accuracy: 0.4855\n",
      "Epoch 305/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2740 - accuracy: 0.4007 - val_loss: 11.8277 - val_accuracy: 0.4855\n",
      "Epoch 306/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.6185 - accuracy: 0.4105 - val_loss: 11.4402 - val_accuracy: 0.4854\n",
      "Epoch 307/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.0802 - accuracy: 0.4026 - val_loss: 11.1256 - val_accuracy: 0.4853\n",
      "Epoch 308/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7335 - accuracy: 0.4064 - val_loss: 11.5413 - val_accuracy: 0.4858\n",
      "Epoch 309/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.1638 - accuracy: 0.4050 - val_loss: 11.8582 - val_accuracy: 0.4853\n",
      "Epoch 310/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1617 - accuracy: 0.4044 - val_loss: 11.9114 - val_accuracy: 0.4862\n",
      "Epoch 311/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6202 - accuracy: 0.4067 - val_loss: 12.3930 - val_accuracy: 0.4857\n",
      "Epoch 312/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6107 - accuracy: 0.4033 - val_loss: 11.4635 - val_accuracy: 0.4859\n",
      "Epoch 313/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1153 - accuracy: 0.4052 - val_loss: 12.0920 - val_accuracy: 0.4851\n",
      "Epoch 314/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3509 - accuracy: 0.4041 - val_loss: 11.2391 - val_accuracy: 0.4858\n",
      "Epoch 315/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4205 - accuracy: 0.4074 - val_loss: 11.3778 - val_accuracy: 0.4856\n",
      "Epoch 316/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.4383 - accuracy: 0.4018 - val_loss: 12.4123 - val_accuracy: 0.4857\n",
      "Epoch 317/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4568 - accuracy: 0.4102 - val_loss: 11.6659 - val_accuracy: 0.4860\n",
      "Epoch 318/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.8674 - accuracy: 0.4021 - val_loss: 11.4283 - val_accuracy: 0.4860\n",
      "Epoch 319/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1453 - accuracy: 0.4045 - val_loss: 11.4473 - val_accuracy: 0.4865\n",
      "Epoch 320/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1445 - accuracy: 0.4051 - val_loss: 11.7247 - val_accuracy: 0.4859\n",
      "Epoch 321/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2928 - accuracy: 0.4077 - val_loss: 11.5410 - val_accuracy: 0.4856\n",
      "Epoch 322/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.0368 - accuracy: 0.4074 - val_loss: 11.7991 - val_accuracy: 0.4856\n",
      "Epoch 323/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.7941 - accuracy: 0.4040 - val_loss: 12.0558 - val_accuracy: 0.4854\n",
      "Epoch 324/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.4263 - accuracy: 0.4051 - val_loss: 11.3116 - val_accuracy: 0.4858\n",
      "Epoch 325/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.4104 - accuracy: 0.4038 - val_loss: 11.4085 - val_accuracy: 0.4852\n",
      "Epoch 326/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.0038 - accuracy: 0.4038 - val_loss: 11.5943 - val_accuracy: 0.4857\n",
      "Epoch 327/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.3988 - accuracy: 0.4039 - val_loss: 11.5914 - val_accuracy: 0.4856\n",
      "Epoch 328/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2789 - accuracy: 0.4074 - val_loss: 11.2222 - val_accuracy: 0.4854\n",
      "Epoch 329/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.4762 - accuracy: 0.4082 - val_loss: 11.4439 - val_accuracy: 0.4857\n",
      "Epoch 330/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.5155 - accuracy: 0.4046 - val_loss: 12.2427 - val_accuracy: 0.4865\n",
      "Epoch 331/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.6044 - accuracy: 0.4052 - val_loss: 11.1732 - val_accuracy: 0.4862\n",
      "Epoch 332/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.4284 - accuracy: 0.4089 - val_loss: 11.4991 - val_accuracy: 0.4859\n",
      "Epoch 333/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3532 - accuracy: 0.4091 - val_loss: 13.2236 - val_accuracy: 0.4859\n",
      "Epoch 334/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4529 - accuracy: 0.4057 - val_loss: 11.7841 - val_accuracy: 0.4860\n",
      "Epoch 335/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.3130 - accuracy: 0.4027 - val_loss: 12.3962 - val_accuracy: 0.4855\n",
      "Epoch 336/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.6190 - accuracy: 0.4042 - val_loss: 11.6611 - val_accuracy: 0.4859\n",
      "Epoch 337/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0170 - accuracy: 0.4061 - val_loss: 12.5590 - val_accuracy: 0.4857\n",
      "Epoch 338/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2023 - accuracy: 0.4011 - val_loss: 11.9236 - val_accuracy: 0.4851\n",
      "Epoch 339/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7310 - accuracy: 0.4088 - val_loss: 11.9752 - val_accuracy: 0.4857\n",
      "Epoch 340/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4170 - accuracy: 0.4082 - val_loss: 11.7554 - val_accuracy: 0.4857\n",
      "Epoch 341/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1199 - accuracy: 0.4058 - val_loss: 11.9905 - val_accuracy: 0.4857\n",
      "Epoch 342/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3000 - accuracy: 0.4112 - val_loss: 12.3759 - val_accuracy: 0.4841\n",
      "Epoch 343/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8406 - accuracy: 0.4053 - val_loss: 11.6000 - val_accuracy: 0.4857\n",
      "Epoch 344/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.8837 - accuracy: 0.4072 - val_loss: 11.3576 - val_accuracy: 0.4862\n",
      "Epoch 345/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.7010 - accuracy: 0.4055 - val_loss: 11.6205 - val_accuracy: 0.4860\n",
      "Epoch 346/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8612 - accuracy: 0.4014 - val_loss: 11.4545 - val_accuracy: 0.4860\n",
      "Epoch 347/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2572 - accuracy: 0.4062 - val_loss: 11.3917 - val_accuracy: 0.4852\n",
      "Epoch 348/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1637 - accuracy: 0.4062 - val_loss: 11.3230 - val_accuracy: 0.4862\n",
      "Epoch 349/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.8221 - accuracy: 0.4041 - val_loss: 12.9095 - val_accuracy: 0.4859\n",
      "Epoch 350/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.5981 - accuracy: 0.4035 - val_loss: 11.5964 - val_accuracy: 0.4853\n",
      "Epoch 351/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3208 - accuracy: 0.4008 - val_loss: 11.9137 - val_accuracy: 0.4857\n",
      "Epoch 352/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9382 - accuracy: 0.4069 - val_loss: 11.7290 - val_accuracy: 0.4855\n",
      "Epoch 353/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1472 - accuracy: 0.4076 - val_loss: 11.4895 - val_accuracy: 0.4855\n",
      "Epoch 354/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.9279 - accuracy: 0.4095 - val_loss: 11.7820 - val_accuracy: 0.4852\n",
      "Epoch 355/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3981 - accuracy: 0.4072 - val_loss: 11.4622 - val_accuracy: 0.4866\n",
      "Epoch 356/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8772 - accuracy: 0.4131 - val_loss: 11.3223 - val_accuracy: 0.4857\n",
      "Epoch 357/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2613 - accuracy: 0.4067 - val_loss: 11.7288 - val_accuracy: 0.4857\n",
      "Epoch 358/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.9534 - accuracy: 0.4078 - val_loss: 11.2929 - val_accuracy: 0.4858\n",
      "Epoch 359/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6020 - accuracy: 0.4057 - val_loss: 12.0048 - val_accuracy: 0.4857\n",
      "Epoch 360/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7229 - accuracy: 0.4040 - val_loss: 11.5656 - val_accuracy: 0.4859\n",
      "Epoch 361/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0934 - accuracy: 0.4120 - val_loss: 11.3247 - val_accuracy: 0.4848\n",
      "Epoch 362/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9934 - accuracy: 0.4012 - val_loss: 11.4176 - val_accuracy: 0.4852\n",
      "Epoch 363/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.5477 - accuracy: 0.4012 - val_loss: 11.1784 - val_accuracy: 0.4854\n",
      "Epoch 364/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1254 - accuracy: 0.4041 - val_loss: 11.1813 - val_accuracy: 0.4857\n",
      "Epoch 365/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7841 - accuracy: 0.4047 - val_loss: 11.4304 - val_accuracy: 0.4853\n",
      "Epoch 366/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6537 - accuracy: 0.4098 - val_loss: 12.1791 - val_accuracy: 0.4864\n",
      "Epoch 367/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.1950 - accuracy: 0.4063 - val_loss: 11.6516 - val_accuracy: 0.4860\n",
      "Epoch 368/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4069 - accuracy: 0.4052 - val_loss: 11.8369 - val_accuracy: 0.4847\n",
      "Epoch 369/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3102 - accuracy: 0.4031 - val_loss: 11.9789 - val_accuracy: 0.4852\n",
      "Epoch 370/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3726 - accuracy: 0.4073 - val_loss: 11.2515 - val_accuracy: 0.4853\n",
      "Epoch 371/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.4738 - accuracy: 0.4082 - val_loss: 11.7955 - val_accuracy: 0.4854\n",
      "Epoch 372/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.3154 - accuracy: 0.4047 - val_loss: 11.2250 - val_accuracy: 0.4860\n",
      "Epoch 373/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.5895 - accuracy: 0.4064 - val_loss: 11.5908 - val_accuracy: 0.4859\n",
      "Epoch 374/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.0576 - accuracy: 0.4049 - val_loss: 11.9877 - val_accuracy: 0.4857\n",
      "Epoch 375/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.4502 - accuracy: 0.4066 - val_loss: 11.7930 - val_accuracy: 0.4857\n",
      "Epoch 376/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.9268 - accuracy: 0.4042 - val_loss: 11.8493 - val_accuracy: 0.4861\n",
      "Epoch 377/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.8346 - accuracy: 0.4047 - val_loss: 11.8357 - val_accuracy: 0.4860\n",
      "Epoch 378/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8229 - accuracy: 0.4078 - val_loss: 11.4662 - val_accuracy: 0.4856\n",
      "Epoch 379/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1102 - accuracy: 0.4085 - val_loss: 11.9702 - val_accuracy: 0.4857\n",
      "Epoch 380/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0849 - accuracy: 0.4057 - val_loss: 11.5492 - val_accuracy: 0.4860\n",
      "Epoch 381/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.9054 - accuracy: 0.4108 - val_loss: 12.4076 - val_accuracy: 0.4853\n",
      "Epoch 382/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9479 - accuracy: 0.4071 - val_loss: 11.8269 - val_accuracy: 0.4857\n",
      "Epoch 383/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.7481 - accuracy: 0.4010 - val_loss: 11.7512 - val_accuracy: 0.4859\n",
      "Epoch 384/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6439 - accuracy: 0.4093 - val_loss: 11.8195 - val_accuracy: 0.4859\n",
      "Epoch 385/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0534 - accuracy: 0.4045 - val_loss: 11.8928 - val_accuracy: 0.4861\n",
      "Epoch 386/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.3962 - accuracy: 0.4035 - val_loss: 11.7124 - val_accuracy: 0.4857\n",
      "Epoch 387/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5377 - accuracy: 0.4082 - val_loss: 12.4841 - val_accuracy: 0.4855\n",
      "Epoch 388/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0917 - accuracy: 0.4060 - val_loss: 13.3966 - val_accuracy: 0.4841\n",
      "Epoch 389/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 8.1833 - accuracy: 0.4079 - val_loss: 11.4878 - val_accuracy: 0.4857\n",
      "Epoch 390/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.2810 - accuracy: 0.4079 - val_loss: 11.3173 - val_accuracy: 0.4854\n",
      "Epoch 391/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1421 - accuracy: 0.4053 - val_loss: 11.9544 - val_accuracy: 0.4861\n",
      "Epoch 392/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2714 - accuracy: 0.4054 - val_loss: 11.8634 - val_accuracy: 0.4856\n",
      "Epoch 393/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3745 - accuracy: 0.4066 - val_loss: 11.6661 - val_accuracy: 0.4860\n",
      "Epoch 394/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8263 - accuracy: 0.4055 - val_loss: 12.0346 - val_accuracy: 0.4861\n",
      "Epoch 395/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.5581 - accuracy: 0.4040 - val_loss: 11.2317 - val_accuracy: 0.4863\n",
      "Epoch 396/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5327 - accuracy: 0.4084 - val_loss: 11.4732 - val_accuracy: 0.4857\n",
      "Epoch 397/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6941 - accuracy: 0.4053 - val_loss: 12.2070 - val_accuracy: 0.4857\n",
      "Epoch 398/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1585 - accuracy: 0.4093 - val_loss: 12.2272 - val_accuracy: 0.4858\n",
      "Epoch 399/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4294 - accuracy: 0.4056 - val_loss: 12.4098 - val_accuracy: 0.4855\n",
      "Epoch 400/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6421 - accuracy: 0.4081 - val_loss: 11.6249 - val_accuracy: 0.4861\n",
      "Epoch 401/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6986 - accuracy: 0.4043 - val_loss: 11.2879 - val_accuracy: 0.4855\n",
      "Epoch 402/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4327 - accuracy: 0.4031 - val_loss: 11.3317 - val_accuracy: 0.4859\n",
      "Epoch 403/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8052 - accuracy: 0.4064 - val_loss: 11.4969 - val_accuracy: 0.4848\n",
      "Epoch 404/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6169 - accuracy: 0.4097 - val_loss: 11.3914 - val_accuracy: 0.4857\n",
      "Epoch 405/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.5028 - accuracy: 0.4059 - val_loss: 11.1614 - val_accuracy: 0.4857\n",
      "Epoch 406/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9727 - accuracy: 0.4065 - val_loss: 11.2852 - val_accuracy: 0.4853\n",
      "Epoch 407/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4879 - accuracy: 0.4058 - val_loss: 11.3211 - val_accuracy: 0.4853\n",
      "Epoch 408/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6617 - accuracy: 0.4045 - val_loss: 11.2372 - val_accuracy: 0.4856\n",
      "Epoch 409/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.0275 - accuracy: 0.4045 - val_loss: 11.5757 - val_accuracy: 0.4858\n",
      "Epoch 410/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1001 - accuracy: 0.4083 - val_loss: 11.5306 - val_accuracy: 0.4857\n",
      "Epoch 411/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3230 - accuracy: 0.4049 - val_loss: 11.5900 - val_accuracy: 0.4865\n",
      "Epoch 412/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 8.1282 - accuracy: 0.4030 - val_loss: 11.4772 - val_accuracy: 0.4851\n",
      "Epoch 413/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.7157 - accuracy: 0.4079 - val_loss: 11.7382 - val_accuracy: 0.4861\n",
      "Epoch 414/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0456 - accuracy: 0.4079 - val_loss: 11.9957 - val_accuracy: 0.4858\n",
      "Epoch 415/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4605 - accuracy: 0.4073 - val_loss: 11.7697 - val_accuracy: 0.4854\n",
      "Epoch 416/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0456 - accuracy: 0.4027 - val_loss: 11.9807 - val_accuracy: 0.4862\n",
      "Epoch 417/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.2746 - accuracy: 0.4035 - val_loss: 11.6521 - val_accuracy: 0.4856\n",
      "Epoch 418/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.5683 - accuracy: 0.4048 - val_loss: 11.9054 - val_accuracy: 0.4860\n",
      "Epoch 419/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7155 - accuracy: 0.4027 - val_loss: 11.6594 - val_accuracy: 0.4857\n",
      "Epoch 420/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.8634 - accuracy: 0.4079 - val_loss: 12.6019 - val_accuracy: 0.4858\n",
      "Epoch 421/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.2483 - accuracy: 0.4057 - val_loss: 11.7578 - val_accuracy: 0.4856\n",
      "Epoch 422/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.6953 - accuracy: 0.4090 - val_loss: 11.6429 - val_accuracy: 0.4861\n",
      "Epoch 423/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6824 - accuracy: 0.4066 - val_loss: 11.8109 - val_accuracy: 0.4864\n",
      "Epoch 424/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.5976 - accuracy: 0.4072 - val_loss: 12.6067 - val_accuracy: 0.4856\n",
      "Epoch 425/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8162 - accuracy: 0.4068 - val_loss: 11.7833 - val_accuracy: 0.4862\n",
      "Epoch 426/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.8723 - accuracy: 0.4054 - val_loss: 12.2336 - val_accuracy: 0.4851\n",
      "Epoch 427/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.6279 - accuracy: 0.4039 - val_loss: 11.0873 - val_accuracy: 0.4856\n",
      "Epoch 428/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2433 - accuracy: 0.4042 - val_loss: 12.2377 - val_accuracy: 0.4856\n",
      "Epoch 429/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6027 - accuracy: 0.4066 - val_loss: 11.4517 - val_accuracy: 0.4863\n",
      "Epoch 430/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7474 - accuracy: 0.4035 - val_loss: 11.3720 - val_accuracy: 0.4858\n",
      "Epoch 431/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.4589 - accuracy: 0.4050 - val_loss: 11.3374 - val_accuracy: 0.4862\n",
      "Epoch 432/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7061 - accuracy: 0.4040 - val_loss: 12.2004 - val_accuracy: 0.4860\n",
      "Epoch 433/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9195 - accuracy: 0.4051 - val_loss: 11.5388 - val_accuracy: 0.4859\n",
      "Epoch 434/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8746 - accuracy: 0.4034 - val_loss: 11.7383 - val_accuracy: 0.4861\n",
      "Epoch 435/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.8100 - accuracy: 0.4042 - val_loss: 11.2498 - val_accuracy: 0.4848\n",
      "Epoch 436/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.3498 - accuracy: 0.4062 - val_loss: 11.5798 - val_accuracy: 0.4858\n",
      "Epoch 437/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7714 - accuracy: 0.4082 - val_loss: 12.1932 - val_accuracy: 0.4862\n",
      "Epoch 438/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0543 - accuracy: 0.4068 - val_loss: 12.1171 - val_accuracy: 0.4854\n",
      "Epoch 439/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9084 - accuracy: 0.4081 - val_loss: 11.7007 - val_accuracy: 0.4857\n",
      "Epoch 440/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.1231 - accuracy: 0.4046 - val_loss: 12.6817 - val_accuracy: 0.4854\n",
      "Epoch 441/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.5904 - accuracy: 0.4115 - val_loss: 11.8633 - val_accuracy: 0.4856\n",
      "Epoch 442/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4736 - accuracy: 0.4071 - val_loss: 11.9733 - val_accuracy: 0.4859\n",
      "Epoch 443/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7678 - accuracy: 0.4045 - val_loss: 11.9543 - val_accuracy: 0.4861\n",
      "Epoch 444/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.4249 - accuracy: 0.4085 - val_loss: 11.7021 - val_accuracy: 0.4860\n",
      "Epoch 445/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.7378 - accuracy: 0.4079 - val_loss: 11.6621 - val_accuracy: 0.4863\n",
      "Epoch 446/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2341 - accuracy: 0.4083 - val_loss: 11.8752 - val_accuracy: 0.4858\n",
      "Epoch 447/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4807 - accuracy: 0.4033 - val_loss: 12.0330 - val_accuracy: 0.4857\n",
      "Epoch 448/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.8688 - accuracy: 0.4055 - val_loss: 11.8571 - val_accuracy: 0.4862\n",
      "Epoch 449/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.4295 - accuracy: 0.4074 - val_loss: 12.7794 - val_accuracy: 0.4856\n",
      "Epoch 450/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.3434 - accuracy: 0.4044 - val_loss: 11.5124 - val_accuracy: 0.4860\n",
      "Epoch 451/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.3891 - accuracy: 0.4078 - val_loss: 11.4066 - val_accuracy: 0.4854\n",
      "Epoch 452/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6926 - accuracy: 0.4027 - val_loss: 11.6644 - val_accuracy: 0.4857\n",
      "Epoch 453/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.9512 - accuracy: 0.4049 - val_loss: 11.7625 - val_accuracy: 0.4857\n",
      "Epoch 454/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.1980 - accuracy: 0.4056 - val_loss: 11.5059 - val_accuracy: 0.4855\n",
      "Epoch 455/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8840 - accuracy: 0.4032 - val_loss: 11.6109 - val_accuracy: 0.4857\n",
      "Epoch 456/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8784 - accuracy: 0.4063 - val_loss: 11.8893 - val_accuracy: 0.4863\n",
      "Epoch 457/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.6628 - accuracy: 0.4071 - val_loss: 11.4125 - val_accuracy: 0.4858\n",
      "Epoch 458/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.4236 - accuracy: 0.4040 - val_loss: 11.5123 - val_accuracy: 0.4865\n",
      "Epoch 459/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.7171 - accuracy: 0.4016 - val_loss: 11.5962 - val_accuracy: 0.4861\n",
      "Epoch 460/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.5897 - accuracy: 0.4081 - val_loss: 11.6380 - val_accuracy: 0.4859\n",
      "Epoch 461/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.7213 - accuracy: 0.4033 - val_loss: 11.6820 - val_accuracy: 0.4861\n",
      "Epoch 462/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.2669 - accuracy: 0.4087 - val_loss: 12.0860 - val_accuracy: 0.4861\n",
      "Epoch 463/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8191 - accuracy: 0.4077 - val_loss: 11.6618 - val_accuracy: 0.4862\n",
      "Epoch 464/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.3436 - accuracy: 0.4080 - val_loss: 11.8780 - val_accuracy: 0.4858\n",
      "Epoch 465/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.4393 - accuracy: 0.4074 - val_loss: 11.6960 - val_accuracy: 0.4861\n",
      "Epoch 466/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.7002 - accuracy: 0.4036 - val_loss: 11.9586 - val_accuracy: 0.4862\n",
      "Epoch 467/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.7244 - accuracy: 0.4034 - val_loss: 11.6433 - val_accuracy: 0.4857\n",
      "Epoch 468/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.6614 - accuracy: 0.4074 - val_loss: 11.6429 - val_accuracy: 0.4862\n",
      "Epoch 469/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8313 - accuracy: 0.4081 - val_loss: 11.2316 - val_accuracy: 0.4855\n",
      "Epoch 470/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.0431 - accuracy: 0.4067 - val_loss: 11.9042 - val_accuracy: 0.4865\n",
      "Epoch 471/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.0540 - accuracy: 0.4041 - val_loss: 12.1025 - val_accuracy: 0.4861\n",
      "Epoch 472/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.4028 - accuracy: 0.4035 - val_loss: 11.6490 - val_accuracy: 0.4865\n",
      "Epoch 473/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1662 - accuracy: 0.4069 - val_loss: 11.3218 - val_accuracy: 0.4853\n",
      "Epoch 474/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2440 - accuracy: 0.4040 - val_loss: 11.5170 - val_accuracy: 0.4862\n",
      "Epoch 475/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.5195 - accuracy: 0.4082 - val_loss: 11.5155 - val_accuracy: 0.4865\n",
      "Epoch 476/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.6415 - accuracy: 0.4040 - val_loss: 11.3197 - val_accuracy: 0.4859\n",
      "Epoch 477/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.9509 - accuracy: 0.4077 - val_loss: 11.2117 - val_accuracy: 0.4858\n",
      "Epoch 478/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 6.8299 - accuracy: 0.4091 - val_loss: 11.7218 - val_accuracy: 0.4864\n",
      "Epoch 479/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1644 - accuracy: 0.4057 - val_loss: 11.6122 - val_accuracy: 0.4858\n",
      "Epoch 480/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.8080 - accuracy: 0.4049 - val_loss: 11.7379 - val_accuracy: 0.4864\n",
      "Epoch 481/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.1894 - accuracy: 0.4053 - val_loss: 12.4909 - val_accuracy: 0.4857\n",
      "Epoch 482/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.2127 - accuracy: 0.4050 - val_loss: 11.9427 - val_accuracy: 0.4857\n",
      "Epoch 483/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.0084 - accuracy: 0.4048 - val_loss: 11.6832 - val_accuracy: 0.4865\n",
      "Epoch 484/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.4942 - accuracy: 0.4071 - val_loss: 11.5362 - val_accuracy: 0.4863\n",
      "Epoch 485/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.1634 - accuracy: 0.4047 - val_loss: 11.3821 - val_accuracy: 0.4842\n",
      "Epoch 486/500\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 7.5936 - accuracy: 0.3999 - val_loss: 11.5174 - val_accuracy: 0.4862\n",
      "Epoch 487/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.1053 - accuracy: 0.4063 - val_loss: 11.4047 - val_accuracy: 0.4864\n",
      "Epoch 488/500\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 6.9891 - accuracy: 0.4076 - val_loss: 11.1973 - val_accuracy: 0.4858\n",
      "Epoch 489/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 7.4562 - accuracy: 0.4097 - val_loss: 11.4536 - val_accuracy: 0.4861\n",
      "Epoch 490/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.1643 - accuracy: 0.4085 - val_loss: 12.0643 - val_accuracy: 0.4863\n",
      "Epoch 491/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.0186 - accuracy: 0.4093 - val_loss: 11.2693 - val_accuracy: 0.4859\n",
      "Epoch 492/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.7814 - accuracy: 0.4055 - val_loss: 11.3501 - val_accuracy: 0.4865\n",
      "Epoch 493/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.6953 - accuracy: 0.4062 - val_loss: 11.7847 - val_accuracy: 0.4862\n",
      "Epoch 494/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.7545 - accuracy: 0.4066 - val_loss: 11.8411 - val_accuracy: 0.4862\n",
      "Epoch 495/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.3053 - accuracy: 0.4083 - val_loss: 11.9875 - val_accuracy: 0.4861\n",
      "Epoch 496/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.2687 - accuracy: 0.4044 - val_loss: 11.5534 - val_accuracy: 0.4860\n",
      "Epoch 497/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.4099 - accuracy: 0.4064 - val_loss: 11.9391 - val_accuracy: 0.4864\n",
      "Epoch 498/500\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 6.5441 - accuracy: 0.4083 - val_loss: 11.6150 - val_accuracy: 0.4862\n",
      "Epoch 499/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 7.0366 - accuracy: 0.4055 - val_loss: 11.7714 - val_accuracy: 0.4857\n",
      "Epoch 500/500\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 6.5013 - accuracy: 0.4072 - val_loss: 12.1984 - val_accuracy: 0.4861\n",
      "(12385, 168) (12385,)\n",
      "(12385, 2, 84, 1) (12385,)\n",
      "RMSE-all: 55.773\n",
      "RMSE: 31.062\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGDCAYAAACFuAwbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAACPOElEQVR4nOzdd3hcxdXA4d9skVbVsixZ7pZ7L9jGYAzGVNM7obck8CWhhIQSICGNkBBCgEBoDr2H3kK3EaYb915xk4tkW1aXts73x9yVVquVLMlbVM77PHp29967d2ev2tkzZ2aU1hohhBBCCJE4tkQ3QAghhBCiq5OATAghhBAiwSQgE0IIIYRIMAnIhBBCCCESTAIyIYQQQogEk4BMCCGEECLBJCATQgghhEgwCciEaCOllFZKDW1m/0ql1MwYvXbMzi0SRyn1R6XU8y08tkAp9dNYt0kIER8SkIkuRym1WSnlUUrlhG1fYgVZ+W0459NKqb+EbtNaj9FaFxxYayNrzbn3Fzi28BzDlVKvKqX2KKXKlFLLlFK/VkrZlVL51mv8L+w5zyul/mjdn2kd81DYMV8qpS7fz2tfrpT6sol9Y5RSHyul9imlSpVSC5VSJymlLlJKVVpfNUqpQMjjSuu5Uf85aG+UUoOs9/5wK583M+SaVSil1iqlrgg7RiulipRSjpBtDqVUsVJKh2yL+D2K8DqhX9Na2M7nlVI7lVLlSql1oQGqUipJKfWa9X3W+/sAo5TKVkq9qZSqUkptUUpdGLY/VSn1cMjvwLyWtFGIlpKATHRVm4ALgg+UUuOAlMQ1p2VC//nF8TWHAN8B24BxWutuwLnAFCAj5NBDlVLTmzlVFXBplAOdd4FPgDygJ3AdUK61fkFrna61TgdOBHYEH1vbgjrkz0ErXArsA85XSiW38rk7rGuVCfwK+I9SakTYMaWY6xt0kvV6oSJ+j8JfJ+zrmxa28W9AvtY6EzgN+ItSanLI/i+Bi4FdLTjXQ4DHaudFwCNKqTEh+2cD2cAo6/ZXLWyjEC0iAZnoqp7D/LMKugx4NvSA8C6hpjI1SqmrMH/Ab7Y+3b9rbd+slDpWKdXHytJkhzznIOuTtlMpNUQpNVcptdfa9oJSKivk2M1Kqd8opZYBVVYWYrNS6lhr/1Sl1DdW9mGnUurfSqkka1/wU/xSq23nWdtPsTJBpUqpr5VS45u5Vn8CvtZa/1prvRNAa71Wa32h1ro05Li7gb9EOoGlFHga+EMzx7SYldkaBPxHa+2xvr7SWkfMpjVhvz8HEV63QCn1F+u6VSql3lVK9bC+b+VKqe9Dg06l1GHWtjLr9rCQfYOUUp9bWahPgPBs3aHW65QqpZbuL8sTwaXA7wAvcGornwuANt4HSoDwn5Pw63cpIdcvSt+j5tq2UmvtDj60voZY+zxa6/ut1/I3dx6lVBpwNnC71rrSes47wCXW/hGYgO8qrfVurbVfa70wGu9BiCAJyERX9S2QqZQapZSyA+cBLardCae1ng28ANxtfbo/NWz/DuAbzB/8oAuB17TWXkBhPun3wXz67g/8MexlLgBOBrK01r6wfX7Mp/UcYBpwDPAL67VnWMdMsNr2X6XUJOBJ4P+AHsBjwDvNZFCOBV7b33XAZBiGBwPFJtwJnB0h09IWe4ENwPNKqTOUUnltOEdbfw7Ox/yz7osJAL4BnsJkTlZjBZ1WEP4/4AHMtb4X+J9Sqod1nheBhZjv3R2YgBDruX2t5/7FOu+NwOtKqdyWvDGl1BFAP+Bl4BUaBk4tppSyKaVOs9q4IWz3W8AMpVSW9SHiCODtkP0H9D1SSt2ilHpvP8c8rJSqBtYAO4H3W/MaluGAX2u9LmTbUiCYITsE2AL8yfrQtFwpdXb4SYQ4EBKQia4s+On+OMwf8+0xfK0XsbrGlFIK8w/9RQCt9Qat9Sdaa7fWejfmn/aRYc9/QGu9TWtdE35irfVCrfW3Wmuf1nozJsAKf36oK4HHtNbfWZ/0nwHcwKFNHN8D849uf2oxAVeTWTKt9S7gUeDPLThfs7TWGjgK2Az8E9iplJqnlBrWylO15efgKa31Rq11GfABsFFr/akVLL8KHGQddzKwXmv9nPX9ecl6jVOVUgOAgzFZGbfWeh6mey/oYuB9rfX7WuuA1voTYAGmW7AlLgM+0Frvw/ysnaiU6tnC5wL0UUqVAjXAm8CvtdaLw46ptdp8HuZn+h1rG9Di71EfKwMY+pVmPf8urfUpzTVSa/0LTNf5EcAbmJ/l1koHysK2lVHfJd8PGGtt6wNcAzyjlBrVhtcSIiIJyERX9hwmU3U5++mmioLXgGlKqT7ADEzXyhcASqmeSqmXlVLblVLlmAxNTtjztzV1YmUK7t9TSu2ynv/XCM8PNRC4IfQfICYr10c1LIb/wDp+L9C7he/zP0CeUqq57rG/A7OUUhNaeM4maa0LtdbXaK2HYN5XFa3/Xrbl56Ao5H5NhMfBOrU+mMxKqC2YzFofYJ/WuipsX9BA4Nyw79PhRPheKDPqNvh9O0IplYKp83sBwKrJ2mq9z5baobXOwtSQPQAc3cRxz2IC2gbdlUEt+B7t0FpnhX1VhZ+nOdYHiy8xgdPPW/NcSyXmfYbKBCqs+zWYbt+/WF2hnwOfAce34bWEiEgCMtFlaa23YIq6T8J8sg5XBaSGPO7V3On281qlwMfAjzD/FF+ysgdguis1MN4qTr4Y043Z0vM/gsm6DLOef1uE54faBtwZ9g8wVWv9UmgxvNY6WKz9KQ27W5t7n15MzdkdTbVBa70XuN86Jmq01tsw3aZjW/m8/f0cHIgdmCAk1ABMFm4n0D2YDQrZF7QNeC7s+5Smtb4r/EW0GXUb/L59AZyJCSgetgL1XZggsNXdllaN1m+AcUqpMyIc8gUmSMzDFNE3d642fY9awYFVQ9ZK6wBHWOZuArDSur/sQBsmxP5IQCa6up8ARzfxiXwJcJYyw92HWsc2pQgYvJ/XehHzD/Fs635QBuYTeqlVN3RTC9se+vxyoFIpNZLGGYLwtv0H+JlS6hBlpCmlTlZKZRDZH4DDlFL/UEr1AlBKDVVmyoGsCMc/ByQDJzTT5nuBwzA1cy2hlFKusK/uSqk/WW2xWQXkP8bUhbVWcz8HB+J9TF3dhcoMxjgPGA28ZwWCCzB1SUlKqcNpWHj/PKZrc5Yy04u4lJkmol8LXvcyTJ3gOGCi9TUdmKjMSNJW0Vp7MF2Ov4+wT1vtPi3kQwYAUf4eNWBlls9XSqVb12cWpixgbsgxyUopl/UwybqGjT4oWN/3N4A/W78P04HTMT/LAPMwGcZbre/jdGAm8NGBvg8hgiQgE12aVQe0oInd92GGwRcBz2B1/zThCWC01bX0VhPHvAMMA4q01ktDtv8JmISpT/kfrc/S3IjJulVggq3/hu3/I6bepVQp9SPr/V4J/BszRcEGTHddRFrrjZjBAvnASqVUGfA6JpioiHC8HxPEZYfvCzmmHDMqs8ljwhyG6TYK/QpYbfoUE5CuwNQPNflemmlPcz8HbWZlA08BbsB0/d4MnKK13mMdciGmYLwEc82eDXnuNkxQcBuwG5Mxu4n9/N22gvpjgPu11rtCvhYCHxIycKCVngQGROqO1ma048oIz/Gw/+9RH9V4HrKzrfdyW0jXeaOXxXz4KMT8HN8DXK+1Dh1UsBbzs9IXEzzVYGUsI5z7F5gpT4qBl4CfB9+Tlfk9HZNFLcP8nl2qtV7TRNuEaDUV9oFGCCGEEELEmWTIhBBCCCESTAIyIUTCKaUejdBtVamUejTRbRNCiHiQLkshhBBCiASTDJkQQgghRILFfaHiaMrJydH5+fmJbkaHUlVVRVpa2v4PFFEh1zu+5HrHn1zz+JLrHT+xuNYLFy7co7WOuPxZhw7I8vPzWbAg6iPVO7WCggJmzpyZ6GZ0GXK940uud/zJNY8vud7xE4trrZQKX7mjjnRZCiGEEEIkmARkQgghhBAJJgGZEEIIIUSCdegaMiGEEEIkjtfrpbCwkNra2kQ3Jeq6devG6tWr2/Rcl8tFv379cDqdLX6OBGRCCCGEaJPCwkIyMjLIz88nwrrtHVpFRQUZGRmtfp7Wmr1791JYWMigQYNa/DzpshRCCCFEm9TW1tKjR49OF4wdCKUUPXr0aHXWUAIyIYQQQrSZBGONteWaSEAmhBBCiC6hoKCAr7/++oDOkZ6eHqXWNCQBmRBCCCG6hGgEZLEiAZkQQgghOrQzzjiDyZMnM2bMGGbPng3Ahx9+yKRJk5gwYQLHHHMMmzdv5tFHH+W+++5j4sSJfPHFF1x++eW89tprdecJZr8qKys59dRTmTRpEuPGjePtt9+O+XuQUZYtUFxczPr169lXVg7oRDenxRw2Oz16ZDNu3DhcLleimyOEEKIT+9O7K1m1ozyq5xzdJ5M/nDpmv8c9+eSTZGdnU1NTw8EHH8zpp5/OlVdeybx58xg0aBAlJSVkZ2fzs5/9jPT0dG688UYAnnjiiYjnc7lcvPDCC/Tt25c9e/Zw6KGHctppp8W0Xk4Csv0oLCzkHw8/gTezHw5XKtBxihd1IIC7fA3Dvp7PNVf9mJSUlEQ3SQiRSJ5qKNsGuSMS3RIhouqBBx7gzTffBGDbtm3Mnj2bGTNm1E07kZ2d3arzaa3505/+xLfffovNZmP79u0UFRXRq1evqLc9SAKyZtTW1nLvI0+SNnwauX3zE92cNtFas3HJVzz/8mtcecUliW6OECJRqkvg+bOgaBXcug0cyYlukehkWpLJioWCggI+/fRTvvnmG1JTU5k5cyYTJkxg7dq1+32uw+EgEAgA5v+lx+MB4IUXXmDv3r0sXLgQp9NJfn5+zCe/lRqyZuzZs4daldxhgzEwQ2/7jZjIqg2bEt0UIUQivXAu7FgMfjdU7Ex0a4SImrKyMrp3705qaipr1qzh22+/xe128/nnn7Npk/nfV1JSAkBGRgYVFRV1z83Pz2fhwoUAvP3223i93rpz5uTk4HQ6+eyzz9iyZUvM34cEZM1wu90oZ8f/FJmUnEJ1Tedb1kII0UJaw/YF0Gu8eVwuAZnoPE444QR8Ph/jx4/n9ttv59BDDyU3N5fZs2dz1llnMWHCBM477zwATj31VN588826ov4rr7ySzz//nKlTp/Ldd9+RlpYGwEUXXcTixYuZMmUKL7zwAiNHjoz5+5AuywP04bMPkpySylHn/iTRTRFCiMi06ZKhxxDYtQwqdiS2PUJEUXJyMh988EHEfSeeeGKDx8OHD2fZsmUNtn377bd19//2t78BkJOTw5w5cyIunVRZWXmgTY5IMmRCCNHZBfzmtls/cysZMiHaHcmQtcEnLz7Cgk/fIiu3N+ndsuk3bAzfvP8K377/X3w+Lzl9BnLRzXcTCPi55/9O49anPsLucFJbVck/fnYat1mPhRAiLrQVkKVkgyNFasiEaIckQ9ZK29atYHHB+9zw8Ftc8ft/s3XdcgDGH34cv/r369z06Dvk9R/Mdx++his1nSETDmHVd58DsLjgf4w//HgJxoQQ8RXMkNnskNFLAjIh2iHJkLXSDysWMG76sSS5zJxeYw89GoCdm9fzwdP3U1NZgaemihFTDgfg0BPPYe4rjzNu+rHM//gNfnT9HQlruxCiiwpmyJQdMvtIl6UQ7ZBkyNog0ky9L//jFs66+vfcPPtdjr/kGnzWXCaDxkympGg7G5bNJxDw03vQ8Hg3VwjR1TXIkPWWon4h2iEJyFppyLiDWf7VJ3jctdRWV7Ly288AcNdUkZmdi9/nZdGcdxs85+Bjz+D5v/6aqceflYgmCyG6uuAoS2WHzN4mQ6Y7zjJwQnQFEpC1Ur9hY5h45En88+en8/Sfr2PwuMkAnHDZL/nXdefy6C0/pueAwQ2eM+noU6muLGfSUackoslCiK6uLkNmg4w+ZnLYmn2JbZMQ7VBBQQGnnGL+V7///vvcddddTR5bWlrKww8/HLXXlhqyNjjuwp9z3IU/b7R9+qkXRjx+04qFTDhiFinpmbFumhBCNNaghqy3uV++A1Jbt76fEB2V3+/Hbre36jknnXRSxHnIgoIB2S9+8YsDbR4gGbKYe+OhO3jvyX9y3EXR+YYJIUSrNagh62Puy0hL0Uls3ryZkSNHctlllzF+/HjOOeccqquryc/P589//jOHH344r776Kh9//DHTpk1j0qRJnHvuuXUTvH744YeMHDmSww8/nDfeeKPuvC+88ALXXHMNAEVFRZx55plMmDCBCRMm8PXXX3PLLbewceNGJk6cyE033XTA70MyZDF21tW3J7oJQoiuLpghszkaZsiEiKYPboFdy6N7zl7j4MSmuw2D1q5dyxNPPMH06dP58Y9/XNeV6HK5+PLLL9mzZw9nnXUWn376KWlpafz973/n3nvv5eabb+bKK69k7ty5DB06tG6JpXDXXXcdRx55JG+++SZ+v5/KykruuusuVqxYwZIlS6LyViVD1g7UVJbz1Tsv1D3esPQ7Hr/9/xLYIiFEpxII6bJM72XuS0AmOpH+/fszffp0AC6++GK+/PJLgLoA69tvv2XVqlVMnz6diRMn8swzz7BlyxbWrFnDoEGDGDZsGEopLr744ojnnzt3Lj//uSlVstvtdOvWLervQTJk7UBNZTlfvfsS00+7KNFNEUJ0RqFdlo4kyB4MxSsT2ybR+bQgkxUr4dNRBR8HFwvXWnPcccfx0ksvNThuyZIlEaeySgQJyFqpZFchs2/7KYPGTmbL6qX0GTyCqbPO5sNnH6CytISLbrmHnD4D+O8/b2Pvrm04k1P40fV/ps/gkXz47IOU7t7B3p2F7CvewYwzL2PGmZfy3hP/ZM/Ordzzs9MZPukwRh8yE3dNNU//+Tp2bV5Hv2FjuOiWe9rND40Qon17bWEhryzYxn+vOtT83agr6rc6RfocBNvmJ66BQkTZ1q1b+eabb5g2bRovvfQShx9+OIsXL67bf+ihh3L11VezYcMGhg4dSnV1NYWFhYwcOZJNmzaxceNGhgwZ0ihgCzrmmGN45JFHuP766/H7/VRVVZGRkUFFRUXU3oN0WbbBnh1bOeLMS7nxsXco3raJRZ+9y7X3vcRpV93MnJce5aPnHqTv0NHc9Ni7nHzFr3jx7t/UPbd42yb+769PcP2Dr/Lx8w/h93k55Sc3kNN7ADc++janXWWO3b5hFWf8/DZufvx99u4qZNPKhYl6u0KIDqS81sud/1vF/E0llFSZCaobZMjABGRl26Byd2IaKUSUjRo1imeeeYbx48dTUlJS170YlJuby9NPP80FF1zA+PHjOfTQQ1mzZg0ul4vZs2dz8sknc/jhhzNw4MCI5//Xv/7FZ599xrhx45g8eTIrV66kR48eTJ8+nbFjx0pRf6Jk9+pHn0EjAOiVP5RhE6ehlKL3oBGUFG1nX/EOLv/9gwAMO2ga1eWl1FSZKHrU1CNxJCWRnpRNelY2Ffv2RnyNASPGk5Vraj36DhlJya7tDB47JQ7vTgjRkf1n3g/sq/YCsKO0lh7pyQ2nvQATkAHsXALDjot/I4WIMpvNxqOPPtpg2+bNmxs8Pvroo/n+++8bPfeEE05gzZo1jbZfdNFFddNe5OXl8fbbbzc65sUXXzyAVjckGbI2cDiT6u4rZat7rJQi4PejI8yArVCNnmuz2Qn4fZFfIynkNWx2AsFPuEII0QSfP8ATX25iWM90ALaX1pgd4RmyXuMBBTuWxL2NQojIJCCLgcHjDmbhnHcAM2IyrVt3XGnpTR6fnJqGu6YqXs0TQnRSe6s8VHv8nDbBzDVWF5CFLp0E4MqEnGGwY3GEswjRseTn57NixYpEN+OASZdlDMy65Bpe/uet/OP/TsWZnMIFNzU/8iQtszv5YyZx95WnMPLgIxh9yMz4NFQI0akUl7sBGN4rgxSnnR2NMmQhn8F7T4TNX8a3gUKIJklA1krZvfpx83/eq3scGmyF7vvJnx5p9NwTLr22wePQ81xy6z8b7Bs64ZC6+2df8/sDa7QQoksorqgFoGdGMn2yXPUBWXgNGUCvsbD8FagtA1f051QSXYfWWmYBCBOpdGl/pMtSCCE6id0VJkPWM9NFn6yUCBmykIAss6+5LZcllETbuVwu9u7d26YApLPSWrN3715cLlernicZMiGE6CSKrYAsNz2ZvlkprN5pzZEUKUOWYS2hVLETeo6MYytFZ9KvXz8KCwvZvbvzTaFSW1vb6qAqyOVy0a9fv1Y9RwIyIYToJIoraume6iTJYaNvVgp7Kt3Uev24ImXIMqwllGSRcXEAnE4ngwYNSnQzYqKgoICDDjoobq8X8y5LpZRdKbVYKfWe9ThbKfWJUmq9dds95NhblVIblFJrlVKzYt221gpfc1IIIdqT4nI3PTPMJ/o+WSkA7CyrbTzKEiDTjMSUNS2FaB/iUUP2S2B1yONbgDla62HAHOsxSqnRwPnAGOAE4GGlQv96JF5wzUkhhGiPiivc9MxMBuoDsh2lNZFHWTpTwJUFFbvi3EohRCQx7bJUSvUDTgbuBH5tbT4dmGndfwYoAH5jbX9Za+0GNimlNgBTgW9i2cbWCF9zMj2rB0vnfYDP62Hc9OM44dLrWrTW5cCR4/nw2QfZu3MrZXuKKN29i6N+9FOmnfSjRL9FIUQHtrvCzeAcs5hyXysg215aA+kmIFu/u5pXlqzi1hNHYbMpU0cmXZZCtAuxzpDdD9wMBEK25WmtdwJYtz2t7X2BbSHHFVrb2o3QNSdHTJrOnu1buP7B17jhkbcpXL+SjcvMkgz7W+syaMemtfz0L7O57l8v88nzD1G2tyhRb00I0cFprdld4SbXypD16ubCaVd8tqYYHTArgry9rJj/fLGJb3+wlmzL7C1dlkK0EzHLkCmlTgGKtdYLlVIzW/KUCNsajaNVSl0FXAVmbamCgoIDaGXztm/fzs6dO3FY62GV79mFx+th8+bNzP/sfTYs+pINPzkJAK+7hjXLFtJ/5EQycvLwqGS2bt1Kek4vsvoNY8uWLfidaezatonNmzdTWlpK/1GT2bHTdBf0GjqGBfPmMOSgw6L+PgIBPzt37qSgoIDKysqYXjPRkFzv+OrK17vSo/H4A5QXFVJQYD7cnTrYwRsrdvHfsiWcD8z/YQ/Qj/veW4BnoosRVYrski18cwDXrCtf80SQ6x0/8b7WseyynA6cppQ6CXABmUqp54EipVRvrfVOpVRvoNg6vhDoH/L8fkCjj25a69nAbIApU6bomTNnxuwNbNy4ka837CY/Px+AEpeDJGcS+fn5LM3MZNZFv+CwU85v8JySXYWkpKTVPScjI5PevfuQn59PicuBw24nPz+fNVlZgK47Lj09nby8nnWPoyng9+Pp3ZuZM2dSUFBALK+ZaEiud3x15eu9dlcFzJ3HYQeNYaa1dNKMGZqyZxfw3QYv5ztgr1uRk57M4mIPYyZPIzfwJXxRwMwZRzQcgdkKXfmaJ4Jc7/iJ97WOWZel1vpWrXU/rXU+plh/rtb6YuAd4DLrsMuA4PLp7wDnK6WSlVKDgGHA/Fi1ry1C15wcOflw5n/0et3j0j1FVOzb26rzrfh6Dl6Pm6ryfWxYOp/+I8ZFvc1CiK4hdJb+IJtN8duTR6Gton4/Nv58+hh8Ac2Dc9ej03uZOcoqiyOeUwgRP4mYh+wu4BWl1E+ArcC5AFrrlUqpV4BVgA+4WuvgbIbtQ/iak5OOPoV//dJkyJJTUrnoN//AZmt5jDtgxHge/91V7CveyXEX/YJuPfJi1XQhRCcXXMeyZ2bDiSwH56YzulcalEBGiosTxvTi8sPyefrrzRwyWXEyQMUOU08mhEiYuARkWusCzGhKtNZ7gWOaOO5OzIjMdit8zckZZ17W6JiWrHUJkNsvnx/96o4YtFII0dUEZ+kPzZAFHTG0O8yH8f27Y7Mpfn/KaHaW1TB7ySZOdiJTXwjRDshalkII0QlU1Hpx2BRpyY0/Z4/oaabCOG2SKdO12RTTh+aww59lDpCRlkIknCydlCAnXHptopsghOhE/FqbucUisFnVH4cM7lm3LS3JwV66oZUdFSlDtv4TyB0BWQNi0l4hREOSIWulkl2F3H3lKVE/7wfP/It1i75utH3D0u94/Pb/A2DFN3OY8/JsAJZ/9Sm7tmyIejuEEB2T369xNBGQRVo6KS3ZQQAbAUcqeKoaHu+ugJfOh/mzY9RaIUQ4yZC1Eyde9sv9HjN22jGMnWbK71Z8/SmjD5lJr4FDY900IUQH4Ncau2oiIIuwuHi61bXptydj99U0PH7LNxDwgd8bi6YKISKQgKwNAgE//73vd2xetZhuPfL48Z8e5j+/vZLTrrqZ/sPHUVlWwn3XnMPtz81l/sdvsOKrTwkEAuzavI4jz/kxfq+XhXPexu5M4sq/zCYtM4uX/nELow+ZyYQZJ7D6+3m8/chfSevWnb5Dx9S97vyP32DbuhVMOuoUVnw7l43L5vPJi49w+e8f5Jm//JIbHn4TgN3bN/Pcnb/m1w+/kahLJISIs0Cg6S5LggPWVX2nSFqyCc78dhd4axsev3meddJ2NdBdiE5NuizbYM/2LRx+2kX85j//IyU9g2VffNTs8Tu3rOfiW+/h+gdf44On7iPJ5eKGR94if9REFnz6VoNjvR43r953Oz+541GuufdFKvbtbnS+QWMmMfbQozn1ypu58dG3yekzAFdaOts3mjXc53/0Bgcff2bU3q8Qov3za429qYCsmQyZz5YM4RmyTV+Y2/Y185AQnZoEZG2Q3asffYeMAqDfsDHsK9re7PFDJxyCKzWd9KxsXGkZjD70aAB6DxpOSdhzi7f9QHavfuT2zUcpxeRjTmtRmw494Vzmf/Q6Ab+fJZ+/z6Sjo1/nJoRov/wBsDXVZVmXIWtYQwbgVUkNM2Q1pbBrmfW80GWIhRCxJAFZGzicSXX3bTY7fr8fm91OIGCW3vR5PE0er2w2HE5n3f2AP8In0Kb+qDZj/BGzWPP9F6z67jP6DRtDWmb3Vp9DCNFx+QOBpov6I2TIggGZR4VlyLZ8XR+ISZelEHEjAVmUZOf1pXD9CgCWfvFhm8/Ts/9gSnYVsmfHVgAWf/a/iMeFLuME4ExKZsSUw3ntgT8y9fiz2vz6QoiOyR+g6S7LSKMsk8x9T3iGbPcac5uSLRkyIeJIArIomXnOj/n6vZd44PrzqSrb1+bzOJOSOff6P/P4767iwV9dQPe8PhGPO2jmSXz26hP88+dn1AVvk44+FZRixOTD2/z6QoiOKaA1Ta7cFiFD5rDbcDlt1JLUMEPmrgCbE5LTJUMmRBzJKMtWCl/+6Khzf1J3/6bH3q27f9IVvwJg6vFnNchY3f7c3Lr7oftCl1gadfAMRh08o9Frhx4/aMxkfvP4+w32b1qxkENmnY3Nbm/0XCFE5+YPNDPthfYDqlE5RHqyg1qdBD53/UZ3BSRnmGyaZMiEiBsJyDqJJ/94NXt3buXndz+T6KYIIRKguZn6CfgbZMeC0pId1Ghnwy7LYEBms8soSyHiSAKyTuLHf3wo0U0QQiRQszP1B3wN6seC0pIc1HidoMO6LJMzwe+WLksh4khqyIQQohPwa93MtBcBsDX+/J2e7KCqUYasPKTLUgIyIeJFArJ25I5LjqayrCTRzRBCdECBwH4mho3YZWmnKuBoXNRf12WpY9RaIUQ4CciEEKITaHamfu1vsGxSUFqyg0q/01q30mc2uivMCEtlky5LIeJIashaae4r/8HhTGbGmZfy1iN/ZccPa/jFP55l3eJv+O6DV3E4k9i2bgUoxSGzzubIsy/noRsvoc+QkWxbu5zaqkrOu+GvDBw5nqryfTz31xuoKiuh/4jx8mlUCNFm/kAzXZZNZMjSkx1U+Kx/A74asGeEjLK0SZelEHEkGbJWGjzuYDatWADAtvUrcNdW4/d52bRiIX2GjKRsTxE3/+c9bp79LlNn1U934amt4br7X+bsa//Af/95GwAfPfcQg8ZO4oZH3mLstKPZV7wjIe9JCNHx+QPNFPVrf8Si/vRkB+XBgCxYRxbaZSkZMiHiRgKyVuo/bAzb1q+ktroShzOJ/FET2bZuBT+sWMDgsZPZu2sbbzx0B6u/n0dyanrd8ybNPBmAIeMPpra6kprKcn5Y/j1TjjkdgNGHzCQlo1tC3pMQouPzB9o27UW5PyRD5veZ2+RMmYdMiDiTgKyV7A4n2Xl9mf/RG+SPPojBY6ewYel37N2xlfzRk7jx0bcZMn4qX73zIq/c99v6J4Z3JbRhvUohhGhKQDc3MWygyQyZW1tr7XprwVNh7kuXpRBxJwFZGwwedzAFrz3JkHEHM3jcFL5+72X6DBlFVfk+dEAz4YhZnHj5Lylcv6ruOUs+N7Pq/7BiAa60DFLSMhg87mAWzTWz+6+e/zk1FWUJeT9CiI7Pv99RlpGL+mtxmge+GtNdCSFdlpIhEyJepKi/DQaPm8KnLz3KwFETSU5JxZmUzOCxUyjbU8zL/7wVbf0RO/nHv657Tkp6Nx64/vy6on6AWZdczXN/vYFlvziTIeMOpnvPyOtWCiHE/vg1TXdZNlFDlpZsN2tZgsmQ2cIyZFJDJkTcSEDWBsMPmsY9H6yse3zrUx/V3b/h4TcjPmfCEcdzyk9uaLAtLbM7P7vrybrHZ/z8tii3VAjRVfgDAexNVUI0M8qyNthl6asBrJHewQyZ3xOTtgohGpOATAghOgF/AOwRuiWBZjJkjoYZMr/X3E/OlAyZEHEmAVkcXH3Pc4lughCikzMz9Te1s5kMGSEZsuCoSlk6SYi4k4BMCCE6geZn6o88yrJxhsxt7ielW0snSVG/EPEioyxjaP7Hb/D6v/8MwNfvvcT3n7yV2AYJITqtwH5n6o80ytLesIYsdJSlklGWQsSTZMji5LBTLoi43e/3YbfLt0EIcWB8zU170cxM/XXTXnhr6wOypHQzV6J0WQoRNxIJtFJza1nO/+h1hh80jTkvzyYjO5fcfvk4nObT54fPPkhySipHnfsTHrrxEvJHH8SmlYsYO+1oZp7z4wS/KyFER7f/ecgaB2QpTjseFZYhS8ow2TRZOkmIuJIuy1Zqbi3L3L75fPjsg1x730v87K4nKdqyocnz1FSWc80/n5dgTAgRFc3O1B/wRcyQKaVwJqegUVaGrNx0V4IsnSREnElA1krNrWVpdzgYOmEq6VnZOJxJTDzypCbPM3Fm0/uEEKK1ms2Q6QDYIneIZLqS8Kqk+gxZXUAmSycJEU8SkLVSc2tZ9uw/BGjZGpXJrpTYNlQI0aUE9P4WF4/85z492WG6LYM1ZMGATLoshYgrCcjaoKm1LPNHTWDjsvlUle/D7/Oy9IsPE91UIUQX4Q80t7h45KJ+gAyXA49KBl8tuCuly1KIBJGi/jZoai3LzB49mXXJNTzwy/PJyM6l39DRBGTYuBAiDpodZdlEUT9AustaPslnZcgyepkdNpsEZELEkQRkbdDcWpZTZ53N1FlnN3rOCZdeW3dfZu4XQkRboA3TXgBkuJzU4ARvsIYs0+yQpZOEiCvpshRCiE6g2Zn6A4GmM2TJDmoDTitDVg7J6WaHLJ0kRFxJQCaEEJ1AIEDTM/Vrv8l4RZDpclCtnVC+wwRk3fqZHbJ0khBxJQFZO7Bt3XLeeOgviW6GEKIDMxmyJnY2V0OW7KA64ETvXmM29BxlbpWMshQinqSGLAYCfj82e+Q/fpH0Hz6O/sPHxbBFQojOTGttzUPWRES2n1GWtSShgtmwnqPNrZKifiHiSQKyVirZVcjs237KgJET2L5xFbl9B3HhzX/n71eezNRZZ7Fu4VccftrFpGZ048PnHsTn9ZDTuz/n3/g3klPS2Lp2GW898lfctdU4nEn8/O9PU7h+JQWvPclP73iMD599kL07t1K2p4jS3bs46kc/ZdpJP0r02xZCtGMBbW6bnqm/uVGWTmqxlk9ydYOM3ua+zEMmRFxJQNYGxYWbOO+GOxk0ZjIv//NWvnr3RQCcSclce99LVJaV8PSfruVndz1Fckoqc/47m4LXn+KY867i2Tt/xaW/vY8BI8ZTW1WJM9nV6Pw7Nq3ll/96BU9tNff+/ExGH3Ik3XrkxfttCiE6CL8VkTXZZbmfDFmptgKy3FFmUXGQDJkQcSYBWRtk5fZm0JjJAEw++jS+eMtMYxFcKmnL6qUUbd3Ag7+6AAC/z8vAURMpLtxEZnYuA0aMB8CVlh7x/GOnHUNSsoukZBdDJx7C1jXLGTddAjIhRGQBbQKypmfqb3qUZUayg104zYNg/RhYRf2SIRMiXiQgawMV3i1gPU4KLoekNcMnTeeS2+5tcNiOH9Y0fm4Lzt+CpwghurC6DFkbRlmmWzVkQH39GMg8ZELEmYyybIN9xTvYvGoxAIsK/sfgsZMb7B84aiKbVi5i9/YtAHhqaygu3ETP/oMp21vM1rXLAKitrsTv9zU6/4qv5+D1uKkq38eGpfPpP0IK/oUQTfPVdVm2voYsI7SGLDRDJvOQCRFXkiFrg7wBQ/j+kzd59V+/J6dvPoedcgFfvP183f70rGwuuPFvPP+3X+PzegA48fLr6dlvEJf+9j7eeOgveD21OJNc/PzvTzU6/4AR43n8d1exr3gnx130C6kfE0I0K7C/gKyZGrL0ZAcVOhWNQoV3WQJoLWl6IeJAArI2UMrGub/8c4Nttz83t8HjYQdN41f/fr3RcweMGM/1D7zSYNvQCYcwdMIhdY9z++Xzo1/dEcUWCyE6M78+kAyZg1f9RzJu0mGcnpZTvyPYxRnwg13+VQgRa9JlKYQQHVwwQ9bkTP2BpjNkyQ4b1fYM1qRNabgjGJBJt6UQcSEfe1opu1c/bv7PezE7f+gi5EII0RL7zZDppjNkSikyXE4qar0NdwSPl8J+IeJCMmRCCNHB+fxt77IEU0dWWRs2wCiYUZO5yISICwnIWqlkVyF3X3lKi49/6R+3sHTehzFskRCiqwvOQ9b8tBdNB2QZLgcVjQIy6bIUIp4kIBNCiA7OfwDTXoA10tIdFpBJl6UQcSU1ZG0Q8Pt48e7fNFrLcuKRJ7Jh6XcAXHzLP8ntOxCAjcsX8PkbT1NesptTf3oTE2ackMjmCyE6mUYz9W/9Fla8ASfdbaatQO8nQ+Zke2lNw40qZNoLIUTMSYasDYoLNzHt5B9x02Pv4kpLq1vL0pWazq8efI3DT7uYtx/9a93xFSXFXHPvi/z0jsd478l/JqrZQohOym+VedV1Wa56G+Y/Bt7a+gxXMxmyDJeDSnd4Ub90WQoRTxKQtUH4WpabViwEYNJRp1i3J7N51ZK648cediw2m41eA4dSuW9P3NsrhOjcfAETkdV1WVbsMre1pfUBVRNLJ8F+asiky1KIuJCArA2aWsuyqU0OZ1Ldfcn+CyGiLRDMkAUDsspic1tT2qIMWXCUpQ79A1XXZSkBmRDxIAFZGzS1luWSzz8AYHHB+wwcdVDC2ieE6Frq5yGzNlQGM2RlIRmypgOy7LQkfAFNcYW7fqNNpr0QIp4kIGuD4FqW//i/U6muKOOwUy4AwOf1cP+15/LFW89y+s9uTXArhRBdhT98pv5ghqy2tEUZsiOH5wLw/vKd9Ruly1KIuJJRlq2U3asfv3n8/Yj7pp92IbMuuabBtgtuuqvB47veWRyztgkhuqZA6Ez9nmpwl5sdtWX1Ga5mMmTD8jIY2SuDd5bu4IrpgxoeLxkyIeIiZhkypZRLKTVfKbVUKbVSKfUna3u2UuoTpdR667Z7yHNuVUptUEqtVUrNilXbWsrpdKL93v0f2M55PW5cyUn7P1AI0SE1mKm/sqh+RwtryABOm9iHxVtL2VZS3fB4yZAJERex7LJ0A0drrScAE4ETlFKHArcAc7TWw4A51mOUUqOB84ExwAnAw0o185EuDnJycrC7KyjdvWu/x97+3FzSu2XHoVWtt3PjKoYO7JfoZgghYqTBTP2hAVmDGrLm/9yfOr4PAG8u3t7weMmQCREXMeuy1Ga4TqX10Gl9aeB0YKa1/RmgAPiNtf1lrbUb2KSU2gBMBb6JVRv3JzU1let+egn3/ud5SnqNwJWWHnFEZXulAwEq9xbRy1bOZT+5KtHNEULESIOZ+hsEZKUtzpD1z05l5ohcnvpqEz8+fBDpsnSSEHEV0xoyK8O1EBgKPKS1/k4plae13gmgtd6plOppHd4X+Dbk6YXWtoQaNmwYt17zE5atWElJaXmHmrbCbrfRe9hQpk49mIyMjEQ3RwgRI/7QmfqDBf32ZNNl2YJRlkG/Pm44p/37K576chPX9pEuSyHiKaYBmdbaD0xUSmUBbyqlxjZzeKTUU6PwRyl1FXAVQF5eHgUFBVFo6f6lp6aQnpoSl9eKtoULF9bdr6ysjNs1E3K9462rXu+lxWZS1yWLF9Fj73cMwEZ1ci7VhRvY+M3XHAqsXreeovKC/Z7roJ527v1kHeuci3nQDgsWfE9lRkmTx3fVa54ocr3jJ97XOi6jLLXWpUqpAkxtWJFSqreVHesNWB/nKAT6hzytH7AjwrlmA7MBpkyZomfOnBnLpnc6BQUFyDWLH7ne8dVVr7d75S5YtJCpU6YwcMGbsC+PtO79SbM5yD14CnwHo0aNYdSEmfs915jJbp75ejPrvlgCwJRJE6Hv5CaP76rXPFHkesdPvK91LEdZ5lqZMZRSKcCxwBrgHeAy67DLgLet++8A5yulkpVSg4BhwPxYtU8IITqLQHgNWXpPcHVruHTSfmrIgnIzkrlx1gicTkfw5DFosRAiXCwzZL2BZ6w6Mhvwitb6PaXUN8ArSqmfAFuBcwG01iuVUq8AqwAfcLXV5SmEEKIZfh0ekOWBKwuKVrW4qL8RZTNFI/JnWIi4iOUoy2VAo/WDtNZ7gWOaeM6dwJ2xapMQQnRGDWbqryiCXuMhKS1scfHWBWRaJoYVIq5kpn4hhOjg6uch01C123RZ2hxmxn6/xxzUygyZstnAj4yyFCJOJCATQogOLjhTv8PvNhmx5Awz7QWYqS/gADJkEpAJEQ8SkAkhRAcXzJA5tNtscKaaoAyg2pqyotUZMpmHTIh4iuXSSUIIIeLAb5V52f1WQOZwmVGWADVWQLafpZMaqcuQdaDZsIXowCQgE0KIDq5ulKW/xmxwpphRlgDVe81tW2rIQLoshYgTCciEEKKDq5uHzF9rNjhckJJl7gcDslbWkNUdL12WQsSFBGRCCNHB1S0uHgjWkKXUd1keaA2ZZMiEiAsJyIQQooPzR8qQhXdZtjZDZpN5yISIJwnIhBCigwvWkNn8IRmypDSwOaFqj9nW1hoy6bIUIi4kIBNCiA6ubqb+0AyZUpCWa5ZSggMYZSkZMiHiQQIyIYTo4IJF/TafFZA5U8xtWg5UtzVDJgGZEPEkAZkQQnRwjbosHS5zm5Zbf1Ara8hkYlgh4ksCMiGE6OD8AY1SkTJkIQGZzEMmRLsmAZkQQnRw/oDGrhT4rIlh6zJkOfUHSYZMiHZNAjIhhOjg/FpjsynwNhOQSQ2ZEO2aBGRCCNHBBYIZMm+NCcaC3Y0H0mWpZGJYIeJJAjIhhOjg/AGw2xT4auuzY3BARf02e7DLUjJkQsSDBGRCCNHB+QMBE5B5a+oL+uGAuiyRpZOEiKsWB2RKqbRYNkQIIUTb+LWOfoZMasiEiKv9BmRKqcOUUquA1dbjCUqph2PeMiGEEC3iD4BNRciQpUahqF9GWQoRFy3JkN0HzAL2AmitlwIzYtkoIYRImLLtYE202lEEAhq7jcYZsqRUcFqdG61cOqmuhky6LIWIixb9hmqtt4Vtkt9QIUTnU/ID3D8WNs1LdEtaxa+DoyxrG2bIoL6OTDJkQrRrLQnItimlDgO0UipJKXUjVvelEEJ0KiU/mJqp0q2Jbkmr+AMau92aGDY0Qwb1dWRtHWXZwbKFQnRULQnIfgZcDfQFCoGJ1mMhhOhcKovNbW1ZYtvRSnUz9UfMkFkBWSszZDaZh0yIuHLs7wCt9R7goji0RQghEquyyNx2tIAsOFN/xAyZ1WXZ6gyZ9e8hvMty6cuQNxZ6jW1ja4UQkew3IFNKDQKuBfJDj9danxa7ZgkhRAJ00AxZg5n6nWEBWXpPQLU6Q2a3gU/bcIRPe/H+zTDubDjlvgNrtBCigf0GZMBbwBPAu4BMSCOE6LzqMmSlCW1Ga/kD1jxktTXgTG24c8pPIG9MGwIyGwFU4y5LXy14qg+wxUKIcC0JyGq11g/EvCVCCJFoHTRDVheQhU97AdCtL3Q7u9XntNsggK1hl6XW4HeDVwIyIaKtJQHZv5RSfwA+BtzBjVrrRTFrlRBCJEIHriGzK0xAFl7U30Z2mw0/NnTAjwpu9Fn/AiQgEyLqWhKQjQMuAY6mvstSW4+FEKLz6KgBWUDjUl7zIDxD1kZ2pUxApgMhAVmtuZUuSyGiriUB2ZnAYK21J9aNEUKIhPHW1gdiHSwgC2hNSjAgi1KGzGFXaBSBgL9+fiS/9W/AWxWV1xBC1GvJPGRLgawYt0MIIRKryqofS+7W4QIyf0DjwgqWopQhs1kZMvwhNWTBDJm3JiqvIYSo15IMWR6wRin1PQ1ryGTaCyFE5xEs6M8ZBtsXgN8H9pb8iUw8f0CToqyALFoZMluwyzI0ILP+BUiXpRBR15K/Nn+IeSuEECLRgvVjOcNNQOYuh9TsxLaphWJRQ2azKQLY0P4IAZl0WQoRdS2Zqf/zeDRECCESqi4gG2Zua/Z1nIBMgysGGbJAUxky6bIUIupaMlN/BWZUJUAS4ASqtNaZsWyYEELEVbDLssdQc9uB6sgCAY3LZgVLUcyQ+bERCESoIfPVmvnJWjnZrBCiaS3JkGWEPlZKnQFMjVWDhBAiISqLILVH/dqPHSgga1DUH615yJQioFXkon4wc5ElZzR+ohCiTVoyyrIBrfVbyBxkQojOpmo3pOWCq5t53FEDsihlyCIW9ftDZj+SbkshoqolXZZnhTy0AVOo78IUQojOwec2wUxHDMi0JjnKGbK6ov5AyBLGoRkyjxT2CxFNLRlleWrIfR+wGTg9Jq0RQohE8XvAngSuLPO4AwVkgYAmKcoBWV1Rf8BXv9Hnrr8vyycJEVUtqSG7Ih4NEUKIhPL7wO6EpDRQ9g4VkPm1Jjm4mIojehkyPzbQTWXIJCATIpqaDMiUUg/STNek1vq6mLRICCESwe+BpFRQynRbdqSALKBJDs7b7YxeDZlGoRuMsgytIZOATIhoai5DtiBurRBCiEQLeMHmNPdd3aC2NKHNaQ1/IAYZsuDSSZGmvQAJyISIsiYDMq31M6GPlVIZZrOujHmrhBAi3vxeU0MGHTJD5sRjAkpbqwfPR1Q3yjIQYWJYkKJ+IaJsv7+5SqmxSqnFwApglVJqoVJqTOybJoQQceT3mhoy6HABWUBrnNobtYJ+ALtV1N9kDZlMeyFEVLXko9Rs4Nda64Fa6wHADcB/YtssIYSIM7+nYUBWU5rQ5rSGP6BJ0h5wJEftnCYgUw27LP0yylKIWGlJQJamtf4s+EBrXQCkxaxFQgiRCKFdlindO1wNmVN7ojYpLJiAzEwMG5ohc9fXqEmXpRBR1ZKA7Ael1O1KqXzr63fAplg3TAgh4irgBZtVVpvS3SwurjvGHNgBjemyjHqGLEJRv6sboCRDJkSUNRmQKaXyrLs/BnKBN4A3gRxA5iYTQnQuwYlhwQRkfk+HCTp8gYAp6o92hkyH15BZ3aLOVKkhEyLKmpv2YqlSajnwEnC71rrjVLgKIURrBSeGBROQgcmSJbX/Co1AAByBGNWQ6bAMmcNl5muTLkshoqq5Lsu+wD3AEcBapdRbSqnzlFLRG8YjhBDtRWhRf2hA1gH4tcap3dHNkKlIXZZucCRZGbKOkT0UoqNoMiDTWvu11h9ZSycNAJ4CzgA2KaVeiFP7hBAiPkInhq0LyEoT1pzW8Ad0TDJkZumkSBmyNAnIhIiyFs0gqLX2AKuA1UA5MDqWjRJCiLgK+E2tVF0NWZa57QAZskDADDxwxGCUpemyDBnY4Ldew5kia1kKEWXNBmRKqQFKqZuUUouA9wA7cLrW+qC4tE4IIeLB7zW39pBRltAhArK3l24HsKa9iF6GzNHUKMu6on4JyISIpuYWF/8aU0f2KnCV1lrWthRCdE5+ax3I0FGW0O4DslcWbOPm15ZxyKBsMqsDUc2Q2awuS6XDasjsyWZ6kIqdUXstIUTzoyxvBeZp3UEm4hFCiLYK+MxtsIbMmWqCs3YekL00fysje2Xw/E8PwX6fO+oZMn+kpZOCryFdlkJEVXNF/Z9LMCaE6BLqMmRWQKZU/eSw7VRReS2Lt5ZyyvjeOO22+oL7KLEphUZFmIfMJV2WQsRAcxkyIYToGupqyJz129p5QPbxyl0AzBrTy2zwRTlDZo/UZWllyOxOmYdMiChr0SjLtlBK9VdKfaaUWq2UWqmU+qW1PVsp9YlSar112z3kObcqpTYopdYqpWbFqm1CCNFAeA0ZtPuA7KOVRQzOTWNoz3QzEjLKGTK7aqKGTGbqFyImmivq/3VzT9Ra37ufc/uAG7TWi5RSGcBCpdQnwOXAHK31XUqpW4BbgN8opUYD5wNjgD7Ap0qp4VqH/jUQQogYCNaQhWfISrclpj37UeX28c0Pe7nyiMEopUygBNGfqV/bGk57EcyQJaWB391wBKYQ4oA0lyHLCPm6Mexxxv5OrLXeqbVeZN2vwMxh1hc4HXjGOuwZzGSzWNtf1lq7tdabgA3A1Fa+HyGEaL1ghswWEpC5sqC2tO5hrdfPtS8t5ufPL4xr0yJZVliGP6A5ZHC22eCrNbdRn4csJEOmtQnCgvOQgXRbChFFTWbItNZ/Ct5XSp0R+ri1lFL5wEHAd0Ce1nqn9Ro7lVI9rcP6At+GPK3Q2hZ+rquAqwDy8vIoKChoa7O6pMrKSrlmcSTXO77aer0zytczGVi+ai17i83zh+ytpHflbr4sKKDGp3lgUS2rSwJku1TCv6f/+8EEkJVbVlKwcxVOTynTgXU/bGWHOzptq/Fp/Cj8Pg8FBQWogJcjgR+2bsfnSGM48NW8uVR6HAm/Hl2J/E2Jn3hf65YW9bd5tKVSKh14Hbhea12ulGry0Ja8rtZ6NjAbYMqUKXrmzJltbVqXVFBQgFyz+JHrHV9tvt5bU2ARjJt4EAy1nq++h8J3GD9pClc8t5R1pTUMz0tnZ1ltwr+nL21bwMAeFZx6/FFmQ+lW+BqGjx7H8INmRuU1qj0+3ih4EKdNmfdbWwbzYPCwUZCcDuth+qFTKVi0LuHXoyuRvynxE+9rHbOifgCllBMTjL2gtX7D2lyklOpt7e8NFFvbC4H+IU/vB+yIZfuEEAJoVNRfXutl4W6z6ZS732X1znIevXgys8b0osrtI9EzAi3ZVsrE/ln1G+pqyKLfZVk37YXPukYOa2JYqK+9E0IcsOaK+pdjMlQKGKKUWhbcBWit9fjmTqxMKuwJYHXYAIB3gMuAu6zbt0O2v6iUuhdT1D8MmN/qdySEEK0VsKa9sDnRWvPTZxaQt6WUyUlw/tgMjjtyOqN6Z7JxdyUBDTVeP6lJiZk1aGdZDUXl7rCALFhDFsWi/uAoS4IBWUidWrDWLjhdiBDigDX3F+WUAzz3dOASYLlSaom17TZMIPaKUuonwFbgXACt9Uql1CuYRcx9wNUywlIIERd185AlUbB2N/M3lfDIoaNhCVx3WA70zgQgLdn8yays9SUsIFuytRQgbhkyVZchCxnJabOb+5IhEyJqmivq36KUOgMYCizXWn/UmhNrrb8kcl0YwDFNPOdO4M7WvI4QQhwwKyALKDv/+GgtA7JTOXZSL1gCVJfUHZYRDMjcPnpGOE08rNxRjt2mGN0ns35jDDJkSoUHZBFeQwIyIaKmyRoypdTDwK+AHsAdSqnb49YqIYSIJ6uG7JstFazaWc71xw7D2d0a5F2+ve6wYIasyp245H1pjYdMl4Nkh71+YwymvQBAhQRk/pAsnHRZChF1zeXcZwATtNZ+pVQq8AVwR3yaJYQQcWRlel5auJN+3XM4bUIfsClISoe9G+oOS7cCsgp34gKRare/LjCsE4OJYQG0smHD3/A17EmgrMyYZMiEiJrmRll6gjVcWutqmu5+FEKIjs3KkC3ZUc1PDx+Ew24zC4xnD44YkCUyQ1bp9tW1o06MMmRa2SN0WbqkhkyIGGguQzYybGRlcKRli0ZZCiFEh2F1vaW6kvnRwSGz7/QYCjsW1z1MSzaBSJU7cYFItcdPapK94caYZsgiFPUHAzHpshQiapoLyEbFrRVCCJFANe5aUoBjx/ZvOHqyx1BY9ZaZg8uRRLor2GWZuICs0u0jwxWfDBnKZiY/CgQajuQMztsW8BLj6SyF6DKaHWUZvk0plQPs1YmeFVEIIaJo3fYSJgDHj+vXcEePoWZi1H2bIXd4SJdlIjNkPnplhgVeMcuQ2U1Apv0NX8Nr/evw+4CkqL6mEF1Vc6MsD1VKFSil3lBKHaSUWgGswMy0f0L8miiEELG1ZsdeACbk5zbc0WOoubXqyFI2fcpF9jkJDciqIhb1x6qGzPoXEfA3nPZCZuoXIuqayzX/G/gr8BIwF/ip1roXZvTl3+LQNiGEiLmSKg/b95QDoOxhGaYeg83t3g2gNerj33GD8xUqahMYkHl8dbVsdepGQMYgQwYmSxj6GnZr2ouA1JAJES3NBWQOrfXHWutXgV1a628BtNZr4tM0IYSIvfVFFdixAixbWKCT0h1Sc6BkI+xaDnvXk00F/up98W+opcrti5whsyeBLcr1XMoaXK/94Ksx950pMg+ZEDHQ3G9vIOR+Tdg+qSETQnQKRRVunPgJ2JLqA5BQPYZC0SpY+UbdprTKRiW2ceHxBfD6NWmRRllGu6AfCKiQwMtTbe47U0OmvZDV7YSIluZGWU5QSpVjprlIse5jPY7+b74QQiRAcXktTnyoYDdcuKHHwGd3mukvsgZA6VYyq7fGt5GWYO1axAxZlAv6ATzKOqenCrzV1hxkNumyFCIGmsyQaa3tWutMrXWG1tph3Q8+buIvlxBCdCxF5bW4bIH6ICPcjJvgiBtM8HHEjQRQZLu3xbeRliqPFZCFL2weowyZx5Zi7nirzZcz1TyWLkshok4mkBFCdGlF5W4yk3TTGTKl4Jjfw/XLYdKl7HPkkuspjG8jLcEVAuKVIXMHAzJPFXhrQgIyGWUpRLRJQCaE6NKKymvJcAZMUXxzsgaAUuxN7k8v3474NC5MMEOWGmmUZQwyZF67dU5vjQnKkqyAzC4BmRDRJgGZEKJLK65wk+6gPuuzH2UpA+inExSQWTVkEdeyjEUNWaMuS+uxdFkKEXUSkAkhurTi8lrSHC3IkFkq0wbQjSp01d4Yt6yxYJdlxLUsY5Ah89msc9Z1WaaZx9JlKUTUSUAmhOiyKt0+qjx+Uu3NFPWHqcnIB8Cze30MWxZZvDNk3tAMWYMuy+AoSwnIhIgWCciEEF1WUblZDiilFQGZt1s+AO7iH2LVrCZVB2vIGo2yrI1NhsweXtQf7LK0A0q6LIWIIgnIhBBdVjAgS7YF6uui9sOengOAtzL+XZaVVpdl4wyZOzYZMntoDVlVfZclmG5LmYdMiKiRgEwI0WUVl5v1GV02X4tryJLTuwPgq4r/8knVHh82BS5n2J/uGGXI/MFRlp7qhhkyMBlF6bIUImokIBNCdFnBDJlTBeqnctiPtJQUqnQygQSsZ1np9pGW5ECFL/EUowyZzW6nlmSTHfNUQ1JohswJfgnIhIgWCciEEF1WUbmb1CQ79oC3xRmytGQHZaSha0pj27gIqt3+xpPCQswyZHabolYlWxmy6oYZMptduiyFiCIJyIQQXda2fdX0zEhGtTYg02kod1mMW9dYpcfXeFJYiFmGzK4UtbigpgTQ9TP1g3RZChFlEpAJIbqkFdvLmLO6iKNG9jSjBVs4MWxKkp1y0rAnICCrdvsaF/RrHbsMmd3KkFXtMRuky1KImJGATAjR5Xh8Af74zkq6pyZx/bHDTUDWwgyZy2GjXKfh8JTHuJWNVbn9jSeFLbdWDUjpHvXXsytFDS6o2m02SJelEDHTso+EQgjRSby+sJC/f7iG4go3d58znm4pTisga9m0F8lOO2WkkeTdHuOWNlbl8dG7W1gmbOMcczvoyKi/nsOmqCUJqorMBumyFCJmJCATQnQZry8s5IZXlzJ5YHfuOXcCM4bnmh2BlgdkLoeNMp1Gki8RGTJf40lhN3wKGX2g56iov57NpqghGaqtOddCAzKbUyaGFSKKJCATQnQJ20qqufn1ZUwf2oMnLjsYlzOk68/vafHEsA67jQrSSPJXtyqzFg1VnrBRln4fbCyA0adB+FQYUeCwKapJBrTZkBSaIXNIhkyIKJIaMiFEl7C1pBp/QHPt0cMaBmNgApsW1pABVNnSzZ3a+Bb2V7l9pIXWkG1fAO4yGHpsTF7PZlNU65Au0gYZModkyISIIgnIhBBdQnmNCR66pUTIaPk9LZ4YFqDWnmHdiV9AFghoqsMzZKveAWWHwdGvHwMrQ6ZDAtXwLkvJkAkRNRKQCSG6hIpaEzxkuCIEXn5PqzJktQ4rIIvj5LA1XrOOZVpwHrLK3bDwKRh7dkxGWALYVLDL0pIkRf1CxIoEZEKILqG81mTIMsMzZIEAaH+La8gAah2Z1p34LZ9U7TEBWUqwqP+r+838Y0f+Jmav6bApqgMhAVmDDJlduiyFiCIJyIQQXUJ5jRelID18lGJwLq1WFOd7nFZAFs8MWTAgc9rB54Hvn4BxP4KcoTF7TbtNUambCsgkQyZENElAJoToEsprzSz3NlvYaER/6wMybzAgqy2NTuNaINhlmZpkh8pd4KuBgYfF9DXtNkU1TdSQ2Z0yMawQUSQBmRCiSyiv9ZLpaqKgH1pVQ+ZNin+GrNpjslEpTjtU7DIbM3rH9DXtNkVlsMvSntRw4IPNIUsnCRFFEpAJIbqE8hpf4/oxqO92a+FalgD2pBQ8OOM6yjKYIUtJCg3I8mL6mnaboirYZRm6bBKY6yVdlkJEjQRkQoguwWTImhhhCa3KkLkcdipUeny7LENryCqtpYzSe8X0Nc1alsGALC1sp3RZChFNEpAJIbqEilofGRG7LIM1ZK0IyJxmtv5ETHuRGsyQKRuk5cT0Ne12RXUwQxY65QVIl6UQUSYBmRCiSyiv8ZKZEilD1vqi/mSHWWA8nhmy+mkvrKL+tJ5m6okYMhkya6Z+Zwo+f4Dnv93C8sIyq8tSMmRCRIusZSmE6BKaLOpvw7QXLqdZYDxh015UFMW8fgwg2WGrmxjWa0/hvMe+YdHWUjJcDuaN1nSXGjIhokYyZEKITi8Q0FS6myjq97nNbSsmhnU57ZQGUhNS1J+a5DAZshiPsATok5VS12W5q9rGoq2l/PHU0aQm2flkzV78Pk/M2yBEVyEBmRCi06v0+NCa5ov6na7G+5qQ7LBRFnCh3RVRauH+Bbsskx02U0OWHvsMWd/uKXVF/eV+JznpSVw+fRDP/vgQvNipdbvZVOaPeTuE6AokIBNCdHrBhcUjdln6as2toxUBmdNOJSngqYxG81qk1usnxWnHpv1QtQcyYjvCEqBf99S6LstSr4MB2aawf0SvDE49aCB2/Hy8RerIhIgGCciEEJ1eeY2pdYpY1B/ssnQkN97XBJfTToVOQfk99c+PsWqPzxT0VxUDOi4Zsm4pTlJcLvzY2eupD8gAMlNdOPFTVKVj3g4hugIJyIQQnV5wYfGI0160JUPmsFGFNVFqeLfl2g/hi3vb0sxm1XgCYbP0xz5DBiZLttuRxzp39wYBGTYndgLsqvKjtQRlQhwoCciEEJ1eRa2VIYsYkFkZLnvrMmSVuomAbNnLMH92W5rZrBqvlSGL06SwQf26p3Ca504e9Z1C/9CAzFpGyePzU1Ilxf1CHCgJyIQQnV5dDVnELstghqw1AZnN1JBB44CspjQm3Zg1Hn/9pLAQxwxZCsWeZHw4GNgjZLZ+a1SqAz+b9lTx0cpdrCuK3yAHITobCciEEJ1esMuy2QxZq7os7VQ0FZDVlsYkIKv2+EOWTVKQ3jPqrxFJ36z6NSwbdlma4NaJn+Xby7jmxUXc89HauLRJiM5IAjIhRKcXLOpPjzTtRZuK+m1UaSuAa5Qh2wf+GGTIvH7TZVmyycxB1oqJbA9Ev+4mCEty2OiZEXKNrNdPVj6e/3YLXr9mwZZ9Uk8mRBtJQCaE6PQqar2kJtlx2iP8yWtDUb8rOO0FNJ76oqYUAj4IRHd+rrouyz1rIXd4VM/dnH7dzfsckJ2Kzabqd1gZsp4pmo27qwAoqfLU3RdCtI4EZEKITq/JZZPAypCpVq5laaNCW9137vL6HYFA/ez9Ue62rPb4cTlssGc95IyI6rmb09/KkDXoroS6gKxPSgCAMX0yAfh+c0nc2iZEZyIBmRCi0yuv8ZERqbsSTIbMkQxKRd4fQYMMWWiXpbsMsLrsotxtWev100uVmIxcHDNkmSkO8jKTGdkro+EOK4DtZQVkV0wfRE56Et9vkoBMiLaQxcWFEJ1epdsXuX4MTCarFfVjAC6HnWqS0SiUO6TLsmZfw/NGUbXHTz/fdvMgJ34BmVKK9649onFAa42yzM+EjGQHR43I5dNVRXy/RQIyIdpCMmRCiE7P7fPjctgj7/S7W1U/BpDstAEKryOtYYasprT+fhQDMq01NV4/vb1bzYY4dlkC5GYk43KGXT+beTwuW7Po98fRIz2ZqYOy2VZSw47Smri2T4jOQAIyIUSnV+sN4HI28eeujRkyAI89LCCrLW143iip9ZpuwVz3VnB1i9uUF82yuizt2l83WGLakB4AfL1xb8KaJURHJQGZEKLTq/X6SW4qQ+arbWOGLBiQhRT1h3ZZRrGGrNpjpu3oUbPJdFe2ot4tZqwuS6XrR5OOyMugR1oSX2/Y0/Lz+H3RbpkQHZIEZEKITs/ti26GLNlhzuW2pTac9iJGXZY1XhP0ZFVvint3ZZOsUZahAZnNppg2pAdfbtjTsvnIvrgX/j4QqiSjJoQEZEKITq/W629cAxXUhgyZUopkh41aW2pYDVlsivprPH5SqSXFvRd6DI7aeQ+IvXFABjB9aA7FFW427q6M9Kx68/8Dc/5kAtqyrbFqpRAdRswCMqXUk0qpYqXUipBt2UqpT5RS663b7iH7blVKbVBKrVVKzYpVu4QQXY/psmwmQ9aKhcWDXE471eEBWWgNWRS7LGu8frphTbia2iNq5z0gEbosAaYPyQHgqw37yXp9cS+kWbVwoZlFIbqoWGbIngZOCNt2CzBHaz0MmGM9Rik1GjgfGGM952GlVBMfZ4UQonVqfYFmMmSt77IE021ZTSq4Y99lWe3xk6msgMyVFbXzHpC6LsuGNWADeqQyKCeN95fvbPq5Pg9U7IQBh5rHoYGsEF1UzAIyrfU8IHxCmtOBZ6z7zwBnhGx/WWvt1lpvAjYAU2PVNiFE16G1xuMLkNxsQNa6LkuwMmQqpXGXpbLVnzdKarx+Mqm2Xrhb1M57QKwuS1uEJaIeT3mQYVv/y4biikb7ABOMoSFvrHksGTIh4j4xbJ7WeieA1nqnUio4drsv8G3IcYXWtkaUUlcBVwHk5eVRUFAQu9Z2QpWVlXLN4kiud3xFut4evyku37FtMwUFOxo9Z2p5CZWBbqxq5ffJ76mh2K/R7nI+/+wzUIoJuzaT6uxGsmcfq5cvoWh3VhvfSUMLdvnqMmQLV26gYlviR1mmV/zAFMBdE3bNtZ8Zez7jUNvB/P31r7loVOPsY7fSlRwErNitGQtsXLWIbZWD4tTyjk3+psRPvK91e5mpP9Jfl4hDdLTWs4HZAFOmTNEzZ86MYbM6n4KCAuSaxY9c7/iKdL1Lqz3wySeMGj6MmYdH+Ke/2E5qnwH0bOX3qceKLwn4eqDcmpmHHQzJ6bAacPWHXfsYNXwwoya17pxN2bOwkB3LPgVg8vSjoceQqJz3gBT1hIWQkpzElNBrV74DPvczNMPHt7vg7CNGcNzoXthDFyZfthuWwNiZZ8KafzKkdzZD5PekReRvSvzE+1rHe5RlkVKqN4B1W2xtLwT6hxzXD2j8UVYIIVrJ7TOTqjY97UVtm2vIKrS1nmVw6ouaUkjPs84b5aL+9lZDZg8W9YfNI1a6DYD8NC/Z6Un87PlFHHfv57zy/Tb8Aetzdpk5hsy+5v2Ejk4VoouKd0D2DnCZdf8y4O2Q7ecrpZKVUoOAYcD8OLdNCNEJ1VpzeDW/dFLbRlmWa+t5wTqymn2QEYOAzOMLqSHLjNp5D0iEeciAumDL5Stn7g0z+feFB5GabOfm15dx5sNf8cPuSijfbmrhktMhJUuK+oUghl2WSqmXgJlAjlKqEPgDcBfwilLqJ8BW4FwArfVKpdQrwCrAB1ytdfhvuRBCtF5w2aHkKE4MC5DssFPmtzJk2+bDrmXgrYL0XmZbNKe98ATIVFXopHSUlZlKOHvkaS8oteYUq9mH3aY4ZXwfTh7Xm3eX7eS3byzn3k/W8W+2Q2Y/c5wrS4r6hSCGAZnW+oImdh3TxPF3AnfGqj1CiK7J7WsmQ6Z1myaGBRPglQWs571zLQQDk+A6k9Gc9sLro6+tBtVeRlhCXYbMFgjrsgx2R9aWQSAANhtKKU6b0Id3lmxnQ3EluAqhmzVuKyULKovi124h2imZqV8I0akFM2QR5yHze8xtGzJk6UkO9niTzAOl4OjfQd/JMPAwM9FsFAOyHaW15Dpr2s+UF9DkxLDBGjLQ4C5rsGtIbjo/7KlCl2039WMgGTIhLO1llKUQQsREXQ1ZpC5LX625bUOGLMPlYIs7Axw2OPI3MOMm8wUmwItiQLZ5TxW5Dnf7CsiaWDqpLkMGJtBKqVuQhSG56dh8NaiaEuhmdVlKDZkQgARkQohOLhiQJUfqsgwGTW3IkGWmONnmzcD76+U4s8KmTbQnRa2GTGvNpj1VdE+tAlevqJwzKiIV9WsNZYWQNRBKt1ijJ+unGhnSM40+ylpSqVtIDVlteV33phBdlfz0CyE6tWanvagLyNqWIQOoSOppuixDOVxRy5DtqfRQ6faRrqvaV4bMFmHai5p9ZgqQ3uPN47DM15DcdHoHA7LMkBqyCN2bQnQ1EpAJITq1+i7LZjJkbVhcPNNlApKKWm/jnY6kqAVkm/aY+cdc/sr2MwcZhBT1h2TIgt2VvayALGx+sazUJKa6Cs2D7gPNbfA9SR2Z6OIkIBNCdGq1VoYs2dFcDVnrA7Jghqy8xtd4p8MVtS7LzXuqUARweCvaWYbMBsrWsMuyNDwgK234nICf89SnrHKOgawBZltKlnWsTA4rujYJyIQQnZo7WEPWXIasDV2WmSnNZMjs0cuQ/bCniiy7G4VuXwEZgM0ZFpBZc5D1Gmduw4Os9R/Ty7+TJ72z0NqatT+YIZPCftHFSUAmhOjUmq8hi0KGLGKXZfRqyDbvqWJklnkP7S4gszsb1pDt2wTJmZDZBxwpjYOs7x6jKrknb9VOpKjcuj7BUZjSZSm6OAnIhBCdWq3Xj1KQZI/utBfBGrLy2khdltGtIRvZzcpCtbeAzGZvmCEr2QTd880gh5SshhmymlLYNA/3mPPw4eC/31vdm8EuS8mQiS5OAjIhRKfm9gVIdpjZ4hs5gIlhg12W5TVNZMiiUEMWCGg2761icHo7DcgcLmwBT/3jfZsg25rmIqV7w6zXps9B+8mecDJHjcjluW83mwEXUtQvBCABmRCik6v1+iOPsIQD6rJMT7amvYiUIYtSDdnibftw+wIMy7ICsmA2qb1wdcPhM6NACfhh3xbobgVk4TPwb/gUkrtBv4O58ojB7Kn08Nbi7eBMMddLMmSii5OATAjRqdV6/ZHXsYQDmhjWblNkJDuaqCGLzkz97y7dSbLDxoQcK7vX3jJkriyc3kpzv3w7BLwNM2TBIEtrWP8pDD4S7A6mDelB/+wU5q3fbbo3ZfkkISQgE0J0brXeAMmRCvrhgGrIwBT2R8yQOVz13aFt5PMHeG/ZTo4e2ZMUvxX0tLeALKV7fYasZJO5DWbIQmvIildDxQ4YeiwASin6ZaVSHCzszxoAu5bFr91CtEMSkAkhOjW3ryUZsrYFZJkpzsg1ZPak+mCvjb79oYQ9lW5OndAHaq1Z7JMzD+icUZeShcNnBYv7rIAsUg3Z9gXmNv/wuqf2zEymqMK6RmPOhB2LYc+G2LdZiHZKAjIhRKdW6w1EnvICDqiGDPaTIfMdWIbsf8t3kpZk5+iRPcFdDknpYGsisEwUV0hAVrLJLKcUXBLJlQXeKnMdgpmy9J51T+2ZkUxxudvMRzb2bEDB8lfi2nwh2hMJyIQQnVqt1x95YXGoD5rasHQSmKkvIteQHViGTGtNwdpiDh+WYwYkeKrAmdrm88VMShYOX7VZGHzfJrMcUjBoDJ2Bv6bULLWUlF731LxMF25fwEwbktkbBs2AZa+YejMhuiAJyIQQnZrbt58aMpsD7I42nbv5GjJ3m4OLdUWV7Cyr5agRVkbJWwNJ7TAgc2WZFQTcZdYcZIPq99VN+LrPfLmyGizCnpthguDicitwHXuWCer2rItT44VoXyQgE0J0avud9qKN2TGwasiaWjoJ2lzY/9naYgBm1gVk1e02QwaYDFjplvoFwwFSs619JWa0ZdiUHT0zTN1ecYVVxxdcbmnvxli1VrQ3JZvgkz9EbRLljk4CMiFEp+b2BZoJyNxtrh+D+gyZDs+EBQcJtPEfzWdrihnVO5Ne3azzeGvMfF3tTXBS14pdZuBBZp/6fSlWQFZdYgK24LGWvEwrQxYs7M8ebG5LfohZc0U7s+4j+Op+KLgr0S1pFyQgE0J0aqaGrJkuyzaOsARTQ+YPaKo9/oY7gkFeGzJkVW4fC7fsY+aI3PqN7T1Dtnu1uc3oXb8vmCGr3hs5Q5ZprnuDNS1TuktA1pX4asztV/dD4YKENqU9kIBMCNGpmQxZUwHZgWbIzPJJjerIgudsQ2H/qp3l+AKaKQO7129srwFZMOtVHCkg62FuayJnyNKTHaQm2evnIgOTJZOArOvwWgGZMw0WP5/YtrQDEpAJITq1Zmfq97sPLEOWYgYDNKojC9altaHLcuV2M+fY2L4hk8C21y7LYNYrUkDmTDXXoTpyDRmYkZZ1XZZgBWRSQ9ZleGvAkQJpOeCpTHRrEk4CMiFEp6W1Nl2WTWXIvLVRypCFBWQOq6i/LQHZjnJy0pPomRHSLk81JKW1tZmxE54hywwJyJQy3ZbVJaa+LCxDBmakZaMMWVmhFHl3Fd4acLrMz3YwW9aFSUAmhOi0fAFNQNN0hsxTdUCBTqbLypDVhHdZWlk3f+sDixU7yhndpxsqZIoI02XZDjNkzhQCygHVe0xGLHwlgZRsM/pSByJmyHpmJDfOkOkAlG6NbbvbgVqvn29/2IvHF2jV89IrfoBlr8aoVXHmszJkzlTzu9jFtW3yHSGE6ABqvabYvslRlt4qSM1p8/m7pZgM2Vcb9jBzRG59EGVvW4bM7fOzvqiiYUE/tN8uS6XwOdJJ8pZCRq8G84wBJkMWnMYiQoYsL9PF3DXFaK3NtQsdaZkzLKZNT4Ste6t57tvNrC+uZOHmfVS4fVx0yADuPHNco2P9AY0CbLaG17Rf4TuwchGMPzdOrY6h4M+1M8V86OjiJCATQnRatV6TfWiyqN9TDVltz5ANyknjjIl9ePzLTWzeW8U5k/tz/Og8bG2c9mJ9USW+gGZsn5D6sUDAZBKc7bDLEvA6gwFZn8Y7U7Nh8xfmfkr3Rrt7ZiRT7fFT6faZ7t9OOvXF9tIaHpyzntcWFmJTimF56Zwwthf+gOaF77ZyxLAcThhrunvLaryc9fBXbNpTxYhemfzv2sMbBGVJnn2mCzjgb39LabWWt9YEY0lpZvBHFycBmRCi03L7TIasyaWTvAdWm6WU4r7zJjIsL4PZ837g09XF/Pq44Vw3om1F/Susgv4xfUK6/oJTA7THDBngc1jXL6NX453BucggYpdlcJ61HaW1jOjlNCMzkzM7zWz9Wmue/3YLd/xvNWi46JAB/OKooeRZU354fAE27K7kt2+uYMbwXFKTHHyyqoiNu6s4akQun63dzfzNJRw6uEfdOZM8peZObVn91CIdVbAr3pliPhx1cVJDJoTotIIZsiaL+j2VBzydhFKKq48aysLfHctJ43rx0Gcb2FVlTRTbyhqy5dvLyEh2MCA7pE11UwO0w2kvAJ8jw9wJLegPCg0YInRZDu1p1rZcV1RhNihl1rRc9BxsnBvllsaPzx/gqa82cdYjX3P72ys5bEgPCm6ayZ9OH1sXjAEkOWz84dTR7K3y8Py3WwD4YPlO+mal8NBFk0hPdvDKgm0Nzp3ksRZqry2N19uJneA8gM5U6bJEAjIhRCe23xoyT3XU1oh02G387uTR2JRi9tfbzcZWZsgWbtnHxAFZDeuGgv+o2mmGzOu0FgzPiBCQ7SdDNrRnOnabYs2u8vqNpz8EuSPg5Ythz/roNjYOtNbc/vYK/vTuKtzeAH88dTRPXnYwfbIif/8mD8zmiGE5PPb5DxSX1/LF+j2cMLYXqTu/564+X/D+8h31o3j9Xpxe61rVlMbnDcWSt8YEY0lpEpAhAZkQohOr77KM8Kcu4DcZrKT0qL1en6wUzjioL99uteZUasXEsGU1XtYWVTBlYFg3VLArpz0uLk5ol2XrM2TJDjuDc9JYu6uifmNKFlz0qlnw/Z1rTQ1dB6G15q4P1/DS/G1cc9RQ3v/lEVw+fVCjwvxw1x87nL1VHk564As8/gAnjesF8x/jlJ0Pcr1+ga///VMq3roBqvaYxdzBLNje0QWnvZAuS0ACMiFEJ1bpNgFZhitCuWxwmH2UuwL7dU9hY00aWtmgdNv+n2BZtHUfWsPB+WHF73UZsvYakDWTIQvO1m9zNFmrN6JXBmtCAzIwa2LO+hts/QYWPhXF1sZOIKC56bVlPPb5D1x86ABuOH54i587eWB3Zl8yGYfNxoDsVA7q3x3KdwCKnzneY1blW7iWPMXqtavqn9QpuiytDJkzDQJe8Hv3/5xOTAIyIUSnVWktaZSW3ExAFuXMU8+MZNwk4cscCLvXtPh5CzaXYLcpJg7IarjD276L+r1Oq4asuaJ+V1bjKTEsI3tlULivhkp32FxuEy+EXuNheceYc+vzdbt5bWEh1xw1lDtOH9twHrkWOH5MLwpumsm7wVGV5Ttg3Dlw0j2UT74GJ37eevfNuuP3leyO9luIP2+NqSEL/g528W5LCciEEJ1WlfVPPj1SQFaXeYrudBLBou3KzCGwe22Ln7dg8z7G9MkkNSmsrTFqZ7Tszj0MjvszdM9vvDPYZRmhfixoRC8zonRteJZMKRgwDXYuNd3L7dw7S3fQLcXJdccMa3UwFuRy2s3cdgE/VOyErAEw9UoyJ54OwMmZm+qOffrTxdz6xnK+XL8Hnz/Aoq37+N+ynY0D2/YsOO1F8MNGF++2lGkvhBCdVmVzAVldhiw2AdnelEF03/656YaxO5t9jtcfYMm2Ui48ZECEne27qN+T3AOmnx15Z3DusQj1Y0Eje5kM29pdFUweGNZd22cizH/MFPf3HHngjY2RGo+fj1fu4tQJfUiKVK/YWpXFEPCZrluAHkMBGO9fCYC2OZiQDdcs2c5L87fictoazLn38EWTOHpk3oG3I9bqpr1Iq3/chUlAJoTotIIBWcQuS29siuXzMs0cZNudAxka8ELJJshtvp6ouMKN2xdgeF5GhHa27y7LZrmyQNmazZD1zUohLcnOyh1ljXf2Ocjc7ljcbgMyrTWfrC6iyuPn1AkRJsdti/Id5jazn7lNzTbBbc0+vI50nK40js5PYtHPj6NgbTGfr9vDuL7dGJybxu1vreCP76zi8KG50QkOY8XvBe03SydJlyUgXZZCiE6syu0j2WHDaY/wp85jjYSMcldgtxQnSQ4bPyjrn+me/Xdb7qvyANA9NanxzrrAsX12WTbLZjOBRDMZMptNMXNET95avJ3dFWHThOQMN0XfO5fEtJltta2kmsl/+ZTrXlpMbkZygwlcD0i5NW1KZkiA18MsJeVJsq5nTSkup50Txvbmb2eN48JDBnDo4B7cdvIotpZU89L8dr4eaGjmV7osAQnIRDtRUuXpWLUPokOodPsid1dCzKaTUEqRl5nMGq9V5N6Cwv591SYgy06LEJB52neX5X4dfycc8n/NHnLD8cOp9QV4YE7YvGM2uyns37E4hg1su5e/30pptYebZo3g8UunYN/P9BZ19m6ELd80vb8uQ9a3fpvVbelJ6m4yjk1MezFzeC6HDMrmX3PWN1y4HcDngbLClrUx1rxW25yukC7Lrr3AuARkIqHW7CrniLvnMumOT5h0xydc/cIi9la2bjJNIZpS6fZF7q6EmGae8jJcbKtUpig7WNi/9GV45VJTpB5mX7UZ7t89NUKtWTufqX+/Jl4A/ac2e8jg3HQunDqAF+dvZdOesH/KfQ6CXcvB374+sPn8AV5dUMjMET25+qihTOif1bInemvguTPhmVNg+yLzvoLf46DyQjP6MHQetx5DAPAkZZmsYxPTXiil+MsZY/F7qtn68JkEvnnEzOWmNfz3YvjXBFj2Sqvfb9SFTudS12VZ0/TxXYAEZCJh/F/cz9anfkJ27XZ+d/IoLpw6gE9XF/HzFxbh9VuTQe5ZD18/CN8/3uV/WUXrVTWbIQvOQxaDgCzTRVF5LeSMgJ3LoGovvH8zrHobHpsBPxQ0OL7UypBlNdVlaXPud2BAR3ftMUNx2hUPzg3LkvWdbK7B6ncS07AmFKzdTXGFm/MO7h/5gA1z4OPb4ZuHzKhJTzXs2wLz/gGlW8yana9cagKkR6ab7FVQ+Q7TXRk6WjMn2GWZbXVZRqi5swzLy+DxcWuZUvM1to9ugWdOhQ9uhvUfmfO+cSWsfi8KV+EABCdNDi6dBF2+y1KK+kVM+QOagNbsKqtlwZYSXl1QiC+gOW6AjSvm/4XjtZdj1Vxs/pvh5BuY2D+L6/+7hL++v5o/nDAEnjkNKqz0fdFKOOW+xL4h0aE032UZm3nIAHpmJjNvnRtmngLv/hL+cxR4KuCKD+Hpk2HzlzB4Zt3xJVXBgCxShqy642bHWqFnhouLDxnIk19t4tqjhzEoxwqUR50K/Q6Gt682QUmvcYltqOWtJdvJSU/i6JE9G+/c/CU8f5aZEDfgg5Vvmm7KmhKzf9y5MPkKePZ0yB5s6gyXvgSTLzP7y3c07K6EkC7LLEhxNT8xrN/LlO3PskwNZ23eqZy793nY8iUMPxHOfRoenGxeb9QpB3oZ2i408xv8+ZYuSyFiY8m2Ukbd/iHDfvsBR9z9Gb/671IK99VQUetj35eP49BeHsu/HzX2LCj4K9w7ijPW3syvD1I89dVmtnz8bxOMXfw6TLsGFjwJ6z5K9NsSHYjpsmxiHcsYzoCfl+miwu2jasxFMPX/TEZkwoUwcBp062dGXoYorfaS4XJEHnwQnBqgC7jqyMEkOWz8/u0Vdcte4XTBec+Dqxv874bENjDEssIyDhncI/L3bOHTpr2/2QKn3G+6XPsdbD5QHvN7OPFuyJ8ON/8AV39numW/uKd+pvry7Q0L+sFkWw/5GXtyDjEZMnc5LP2vCVRDeWug4G+osm3My7uUhyqOgF+thEvfgbMfN9dz+PEmSxualYu3uoDMJV2WFsmQiZj57/fbcNgV1x49nOz0JEb3zmRCvyxs2k/g/qvQOTP5v8uuAK6AMWfAqndg/Udcq78gNf1EMhd8gD//SOxDj4WBh5sugBfPg+EnwPF31KXwhWhKldvPoJwmuvo8VWbIva2JgO0ABKe+KK70MOiEv5kaqqHHmp3d82Hf5gbH76v2RB5hCeafVDtdxzLaema4+NNpY/jN68u55sXFPHrxZFMon9ELDrsOPrrVdAH3Hp/QdpbXetlaUh25u7Jmn/lbNulSSE6HKVfAQZeYtTnDucykuMy8FV78EXx0m1kyqnxn4wyZ3QEn/p2aggJwWd2VX/zTZNeOvt1cI081PDLN/HwNPxFHnxPZ/OFaSmo12YOPrD/X0OPMB9yt30Do9njyRciQeSRDJkTUeXwB3l++k+NH53HtMcO46JCBHDSgu1kSZOMcbBU7UIdcVf+EkSfDWY/BVQWozL781Pcy/oDmYcclZr/TBZf/D468GbZ+DY8ebj6FCtEM02XZTIYsRoFOXoaZHLaovNYEfOPOqZ+LK3sQ7GuYISup8tA90ghLMP9ku0CXZdB5Bw/g1hNH8smqIr7btLd+x8QLTAD9/X+gcEFCRwuu3lEOwOg+mY13LnvVLFo/6dL6bZGCsVDDjodDfwHzZ8MDE826jt36Nn18cBqR4JQqW74yt5vmmWDsjEfhwpeZZC1Uv3hr2IjMQTPAngQbPmm+XbEUzIY5XKYtyi7zkCW6AaJz+nzdbspqvJw+McIfldXvmILWocc13tc9H372FdxayBOHfsw/V6Ty4nfWfDppPeCo2+Dq+TDwMFObs/y1mL4P0bFV1vpIC1+KKMhTFbPliHpas/XvKI3QBdM9H6r3Qm153abSam/kEZbQpbosgy46dCAOm+KL9XvqN6Z0h/HnwqJn4fFj4N3rE9a+VTvN925M7wgB2Zp3oeeY1mXxlIJZf4WT7oG8MXD4r2HMWU0fHz7R7uYvze36j83P9Fjz3HF9u+GwKRZvLW14fHK6+Ru6PpEBWXDaixTz/pPSunyXpQRkIibeXrKd7LQkDh+W03CH3wdrPzCfCB1NZARsNkjO4IbjR3DEsBxue3M5t76xrH7kZUYvOP8ls87dWz+HT/8EFUWxfUOiw/EHNDVeP+muZgKyGGXIBvZIJTstiTlrihvv7D7I3IZ0W+63y7ILZcjALHU1aWB35q0LW0B7+vXmb0efSbB9gZnKIQFW7SgnJz2J3IzkhjsCfjOVxcBprT+pUjD1Srjwv3DsHxpOeREumCGzJ0P+ESYg09oEZEOOAodpV0qSnVG9M1kUniEDkyXbvQZqSlvf1mgIXxLMmSJdlolugOh8Kt0+Pl1dxMnjejcueN32rckOtGB0j8Nu44nLDuaqGYN5af423lmyo36n0wXnvwjDZ8FX98NL50f3TYgOr8rTzDqWENPRi067jVPH9+aTVUWU13ob7gwuwh0akFU1F5B1rS7LoBnDcli5o5w9ofMS9hgCF70KB11sarVKEzMb/aqd5Yzqndl4EfHda80KEP0Ojm0DgmuE9p8Kw46DPetMd2XZNvM4xEEDsli6rZRAICx4zbNGqxavim1bm1I37UUwIEuVLstEN0B0Pp+s2kWtN8DpE0NGCW38DJ47Cz68xXyqi9RdGUGSw8atJ46kTzcXH6zY2XBnarYZfXXUbbBjEVTtiXwS0SVV1jazjiVYGbLYLUd05qR+eHwBPlge9nObHcyQmToyjy9AlccvXZZhZgzPBeDL9RF+r3tPNLcJWFLJ4wuwvqgycv1Y4ffmNtYBWZrV8zDkKDPgCeD1n5jbsL+to3tnUuXxU7gvrDswb7S5LVoZw4Y2IzxDJl2WEpCJ6Htr8Q76ZqUwaYD1Ke6Le83M1MWrzMSIY88yNQwtpJTihLG9mbduDxXh2QaAQTPN7eYvDrjtovOocu8nQxbjgGxCv24Mzknj9YXbG+5wdTMZDmvqi7pJYZsq6u+CXZYAY/p0o3uqk/eW7Wy8M2+MmeMrwqoHsbauqAKPP8DoSPVj2xeY72324Ng2Ii3HTGNx6C+gz0SYfLlZYuqwaxsNBhhptXP1rvKG58jsa34WExaQhUwMC9JliQRkbaO1yfg0sZZYV7ZxdyVfbtjDaRP7mBGVq96GOX8yQdi1C+GWrXDmo60+70njeuHxB5gbqSanz0RISodNEpCJepX7C8hi3BWolOK8g/szf3MJywvDZlXvPqiuy7IkuI5lapL5J1W6rXE7u8i0F6HsNsUV0wfx6eoi5qwOqxF1uiB3FOxYEvd2zVldjFJw2JCcxjsLF0DfKQ1n2I+VwUeaIMZmh1P/BZe8Acf/pdFhw/PSUQrW7KxouEMpyBub2AyZw2VqhsHqspQMmWgNreGT38NzZ1Ay+zQufexzTn/oK37y9Pfc9OpSrn95MV9v2GOOW/AUFCWofz7WtIba+n8ylW4fN726lOPu/RynXXH2pH5mZuq3fmHS92c8arIRbfxDNWlAd3pmJPPB8l2Nd9qdpsB/07y2vhvRCQUDsqa7LGMf6Fx4yAAyXA4e/Xxjwx3d803dT8DPvqqQdSw/ug3uHwsPTzOTiQbb2QW7LAF+duQQRuRl8Ns3V1C4L6y+qM8E02UZ58L+j1ftYtKA7o0L+t0VULwa+k2Ja3v2JzXJwcDsVNaEZ8gAeo42bQ4E4t8wX219dgysgEwyZKIZWmvW7Crn3o/XcsqDX/DEPTfB1w+wMuVgsvct449F1/Jg6TVMKH6LLzfs4fN1u7nkyfm898G78N71ZpmU4OLCkezbUp+67Qi0ho9+C3cPhr/nw+r32LK3itMe/JLXFxXyk8MHUXDjUQztmW7qxVBmqY6mRlS2kM2mOGFsLwrWFVPtibDI8KAjYO96M6GiELS0y7LlXedtkeFycsmhA3l/xU5+2F1Zv2PUqWY29m8eYp+VIeue5Iflr5oMS8Uu+PSPZtSe390luyzB1JD+49zxVLp9nPzAl7y9ZDv+YHF674lmgFDZtmbPEU3bS2tYuaOc40fnNd656QtAQ/9D4taelhrZK5M1uyoa78gbY5b0KkvA4Ijwrvik1C6/lqUEZM3YWVbDMfd+zgn3f8G/P9tAqtPB8e5PWGEbyYU1N/HhwBsZlJPGgOxUrqv+N9/MXMO8G2cwY1gO7m8eo5oUKrxQPfsEM4npuo/h/ZvgrgEw+yhrYdnxUPC3RL/Vlpt3D3zzb7PsR95YAq//lL8+9gwl1R5evPJQfnvyaHp1c5mpLdZ/DDN/Y5aKiYITx/am1hugYO3uxjvzrcLWrd9E5bVEx1fpNkvvNN1lWRWXQOeK6YNIcdr547ur8PgCPPXVJh7bM56S/sfD3L/gKzYf2HrvKjDL4Rz9O1MbtOFTWPKiOUlyhHqlLmJ8vyzeu/Zw+men8MuXl3DC/fPYWVZjpm0AMyt+nHyy0mToj4sUkK35HyR3g4HT49aelhrZO4PNe6saf5jNG2tuW9uTo7XpAdm+EHzu/R8fibfGdD0HSZelLJ3UnLwMFyN7ZXDF9EGcMKYXubVb4KHN9D/xbpYeMguYBdxu1gN79XL46DYyvn+cJyb/GL3tO95zzOJpz9H8LvAIk9/9pTmpPcnMSr9rBaz90BRWrnkPjvtTAt9pBJW7YeNcszxR30nmF/C7R+Gzv8D48+HMR9lXXIjn0aN4zHcrlb2nkV54LGzxmq7Drd9AznCzjl+UTB2UTY+0JN5fvpOTxvVuuLPnGDPTc9GKukkRRddWVddlGWGmfp/HLPoch9qs3Ixkbp41gj++u4oT7p/HD3tMt8zjnMFXaV8yfO2jwCVkrHsdMnqbQKPXeLO24TvXQNZAGH9ezNvZnuXnpPH21YfzwYqd3PzaMq5/eQkvXnko9r6TYckLMPp0U0qyb5Pphjv6d43XgoyCj1cVMbRnOoNz02HuX0wPx1mzTSZz7ftmGp4D7A2IhZG9Ms00ZUWVTOifVb+j50hzW7SSmsGz2F5aQ056EllNTcES9MFvYP5j5n7fyXDRa83PmxaJr7bhByLpspSArDk2m+LhiybXb1j8trkddWrDAx1JcN5zsPpd+Opf2D75HQCnX/kHjskczLS/9uWq/ju49thRZqixq5sJcAI+U2f2wU2wZwPkDI1a2z2+ALvKaumfnVI/V86+LeQWf8WO975h4/pVVLj97HD04/ucM3AmuXD7AmwvqeJHVS9wifdV7AQIYGNt37Pp5tlJn91fEhhxMt6T7mXZln38+d0tFHv/yqsHr2XAtndg7h2gbCYNPvNWs3RIFP842W2K48f04u0l26n1+nE5Q/7ROl0mANy1ImqvJzq2uqL+SBPDBv/wx2im/nCXTMvnnaU7WFZYxj3nTuC40Xn89s3lPL9qBpcUfcxJzrHYN34K0642RdppPczIuSUvmYlC03rEpZ3tmd2mOGV8H2o8fm56bRn/+Ggtv5l4Eep/v4anToKaEhMcLH/NDCa64GVTytBau1bAxjlmpGTI3/qyai/fbSrhqhmDoboEvn7QBBXDZ5nJqmtKzIftdmhkrwwAbntzOWP6ZDIkN51d5bWs2F7GP3Ueyz/9hKs/GF13/OCcNH56xGDOmtSXZIeNBVv24fYGyMlIos+298mc/xj7RpyPt+d4cr/6I74nTqT25H+TPmhK47nZmhIs6g+SLksJyPZLa/j+cZP12bHE1AdE+uRls5sFskefbtYVq9oNucNJB86dMoB/fRPg3HMOopfL+gFUyhSjDz/eBGTrP2o+IAv4TRF98FNIIADfPQKVRdBjGGQPpnzzInas/JJit53qshJcgWo+dIzA32MIo2yFHLH7RcZo042TSjoOmyK9toKJtd/ze9fNJNsUd3rv5yDvNyzIPJaCrLMYs/1VTtz+KoU6h3t85/KfFWfiXloAmPqORy8+kgEjfwTcbkad2hyQnBGli9/YqeN789L8rZz9yNdcMX0QM4bl1C1TQ6+xsOXrmL226Fgq3T6cdkWyI0KGLDi8PobTXoSy2xRP/3gquyvcDMk1dWsPnH8QH371K+xzPuZh+z8go59ZQDto1t9MpieGv08d0TmT+7Fwyz4e/XwjnimjuN2ejCrbZgLX4bPMdCIvXWAmi770Heg3ueEJCu4ytzNvabg9EIC5f4Yv7zOPlR0ue9eUZwBz1xbhD2hTP7b0RROMdc83tbLd+lnzKx4b2zffRgOyU7lg6gBW7Sxn7ppiXllQiMtpY3TvTCqzRnCoZys3TR1B724udle4eX/FLm57czl/e381ORnJbLKyuqfZvubvztks0MM5f+lJ+HAw3XYD9+15hJxnjmNu8kySxp3BxJQiMnS1uS5Tfmz+P4bz1jYcrOJMM2t4+r3mf2MXJAFZc6r2wpv/ZxZgTc8zwc8Rv2r+OUrV1zNZLjtsIE99vYmTHviCY0b25PgxvZgxPMf8o+ieD7kjYd1H5tNxJNvmw/9uMIMDrvoMeo7G994NOBY9SUA5sGmTCcgEKnQPetp8BJLTsSWlMaPyNWx7zAiaNwMzeC/pJGZMn85Z00aR7nLComeZ8u4ved/3M1OnUrsdTrybKVOvYopSaH0hxSX7UPYUxmwr5dKt+8h0ORmWl860wTl0C53MMjh7dAwdNjSHe380gQfnbuDGV80cREeNyOW8gwdwRPeRpC1/1Xx6bW36XHQ8Pg8ULTfd/ul5jUbwVrl9kUdYBvxQ8oO5H6eADCDT5STTVf/7YrMpTjriUCg609Qfnf8CpOcScoAEYxEopfjrmePolurksc9/4PCxN3D02AEmGAMz8e6lb8Hjx8H7N8BVBfj8AXaW1VKyYwPjP78bdIDP9CRcAyYx1L6L3Pd+jHJXQMUOk5mcdi36pfPw//dS/GPOITl3CGtXpNMzPZcJfTPhrSfMh/MT7zYDt6pLYMaNrZpfMZ5sNsXfzhpX97i02kN6sgOH3QZzD4UvvuTqw/vWBUhXzRjMNz/s5fWF29mxr4IH+s0nf08BGXuWUJR1ENun3M+D3fLwBTS+wAS+qD6VIWse4bBtr5Ky8DMAvDhw4mPZ/Lks73cxI6vnM7zsK5KHH0PSUb8xGbL0nvWNDAZn3mqwd4vbtWlPlE7QWmDRMGXKFL1gwYLYvUBNKTxxHEy9Cg7+qVkSIym9TVM3fLF+N68uKOSzNcVUuH3kpCdz9uS+DM5JY9qmhxiw6lG2584gKzODtEClqYPSGla+AZvm4U/rRcBby97kfqzy9ubo2k94xHcq9/h+RF+1h8FqJyk9B3PTRaea+oag2nKo2GkyVz2GUFBQwMyZMxs2bss3sOBJMwz/+L+0Lc0fZ4GAZtXOcj5eVcSL321hT6WHGbalPJv0dxbNfJZJM083xaZ71ptJFFNzwB7/zx8Rr7c4MN5a+Pwu091fW2q2dR8EEy5gzc5KRua5YOs37N2+noDXQ27fQWY1h6HHmp+H/14Cu1eb5138Bgw9JmFvBTDvp3pvowk9O4pE/YxrrfnVf5fwztIdPHXFVI60ZvbfVlLN3DXFjN3yNJPX3sf5KY/xfVkm/oDm945nucT+CRWksF734zzP7cx23sthtlXMTzqEnd0msjn/R3gDsHn1An5TdQ8DVBFpyhSub0kdx8CcdFMje/YTMO4c83c6HvOOWaJ+vVe+Ba9eBlcVQJ+DGu7z++Ctn5nRv/2mmqD3sOuaLEXR1SVsXjmfgrI85m7xcFjh4/xcv1K3f3Mgj3xbEXOTjuJg5ybS+o/Hdv5zZufSl00C5PwX203Xbyx+tpVSC7XWEedGkQxZc1Ky4Odf16dPD+DT6hHDcjliWC4eX4CvNuzhmW82M3veD2gNKUzlZ45iziv+jL3FTmpTUuixyQwC2EUOT/ou5IW9x3CsbSH/8jxML1bwdb+fMuiQG3i1WwppSQ5Sk+z0zUoxk7GGcmWar+YMnNa2xXATyGZTjO3bjbF9u3H1UUNYXljGsjXZ8O3f+WDOp+SMOoIBb50RMpO3MgMUxp1rZrPuovM6dWiBgOnan3MHFK+kfPAprO4+k6SaPfTa+Qm9C/7KSCCw1kZx+khWMhJfkoNZtZvh+bNNofyedSYrdtI9JpMyeGZi3xOY+scOGowlklKKO88cx4od5Vz25HyOGJZDeY2XpdYkvP3VAL5IhjNTFjN54hUMTfdw2tzPKe5/KtV5kznku9tZnP8I3XctZG7f/+MF57ls2lvF9m+3kmS3MaLXMJYd/T8+Latl8cqV9C6exx/0/2DPDjj1ARh7drAhCbwKURA60rLPQVC4EBY/a7YvehZ2LYNj/gBH/Hq/p1Kp2Qw6+AQGAVcAcAisPh1/bQV7c6awoTyD7d/dz9FbHwEPvL2qP688/i2HDOrByaOOZUjeOHjnWrN4fGbv5l+sE2p3AZlS6gTgX4AdeFxrfVdCGxTlvuwkh42jRvbkqJE98fgCFJXXsqu8lmrPDErSk/nbB6v5Yv1ujuq2i5zsHFR2Pr26pXBbNxd9uh1B9bYMUvuO5bDRp0W1XR1ZssPOlPxspuRPw78sh8lV6/jh+esYULEUjvuzGb1TWWw+1X52p6nFm3VnopstIggENMu2l/HFut0s2rqPkmov5TVeampqeCBwJ1P1cnapXH7rvZk5qyZaz+oDjCdLVZJJNWUqg/K9KWhtpieYdcEYMyJu13Iz0GT6L6M2FYtIrLRkB2/84jAen/cDby3ZQZ8sF786djhnHtQXl9NG4IWnOM+5CGb93ZR9BNz0PukWyBkBqW66F/wNMnpz9GV/5OjmRtweO5xqz6kkOe4xjyPVRHVU2YPMAt9FK82HnnevM6PVATL7wTlPHdjI9VGnYAd6AscCjLkLPS8HNfcO+vTMoaTKy32fruO+T+GSIb/m9+6fo/9zLM7TH0h89jrO2lVAppSyAw8BxwGFwPdKqXe01p1yuvskh43+2an0z67/Q/Dsj6dS5fE3PXfSyNvi1LqOyd5nIids+BQqYF72uST3vpgMl5O0ZDspB99A9pwbcXz3KEy+otWjWt0+P/6ARqEafChWirptCupGGSlMt0pnprXGF9B4/YGw7aaofl+1B39Ao7U1sFhr68s8N6DNdS3cV8P8TSXMW7ebvVVmotQReRnkdXMxoHsKF+59mql7l/NGr+v4Kut0RmSlc0peOuP6dsPltJOa5CArxcm8eZ8zc+ZMAgFNWY3XjLC02yQA78QyXU5+ffwIfn38iMY7x5xmgvF598D3T5jyk56jzL4jbzJdY3Zni6Y/SU1qV/8uo8dmN9NfFK2AVW+a27P+Y7Jl3frFpDdBzbgRuvXn4N7j+aDnKPZUunnyy028sqCQFdW38A/vYwx5/iyezrqaZX1+RF6mi16ZLvpmpZCfk8rgnPTGvUGdQHv7CZsKbNBa/wCglHoZOB3olAFZJEqppoMxsX8n/QPfpq95dXUNd6zpTfXsbxvszuEwClyvUfXQLPYoM5WARkNI3BQaQgXjqWAg0VrdgEWfhW81f0hsChw21eJh4jrSo1Y0qaWH6iYfGApNJhVk6iqKdTeqcDU+aD+U9WXD/BEaAYyxKX7pcpLZ20mGy4HTbgO/hsJNpsbqsGs56/g7aMlndZtN0b2pxbpF13HQJbD8dTMlT1pPU0sYKm905Od1NXljzHQhu5aZedzGnlO/xmSsTKifWy8nPZmbTxjJTbNGsK3kMD5fdRKV3/6Ky0sfYnXZR9T6lfk7DZQDy5XC6bA1+ADcmG5yVa1Gm61/AfuyJ3D4Nf85sPd1ANpVUb9S6hzgBK31T63HlwCHaK2vCTnmKuAqgLy8vMkvv/xyQtraUVVWVpKe3j5HAkVbmVuztdyP2w9uv8bth2qfJr/0Ow6v/pjQX2MVfNTwpo5NmURL07/64XeMQCCAauIPW0CDL9D23z/VZGtouqEt273f51Xb0qixpZGlS0nGE/F89gjXrMH9kEyi0w7OJq6vJymbfd3HUZR3pJmKoBld6ee7vWj311wH6L5vGZ6kLKrS8xPdmgMWi+vdrXQVA7a+CsDWAedQljUmqudvCxXwMWjT86RXbkID/gB4AuZveY0XfNrKvDf1/Ka2N/PHb0/qUByTLqt7HItrfdRRRzVZ1N/eArJzgVlhAdlUrfW1kY6P+SjLTkhG/cWXXO/4kusdf3LN40uud/zEe5Rle1vLshDoH/K4H7AjQW0RQgghhIiL9haQfQ8MU0oNUkolAecD8Vs5VgghhBAiAdpV9bjW2qeUugb4CDPtxZNa65UJbpYQQgghREy1q4AMQGv9PvB+otshhBBCCBEv7a3LUgghhBCiy5GATAghhBAiwSQgE0IIIYRIMAnIhBBCCCESTAIyIYQQQogEk4BMCCGEECLBJCATQgghhEgwCciEEEIIIRJMAjIhhBBCiARTWutEt6HNlFK7gS2JbkcHkwPsSXQjuhC53vEl1zv+5JrHl1zv+InFtR6otc6NtKNDB2Si9ZRSC7TWUxLdjq5Crnd8yfWOP7nm8SXXO37ifa2ly1IIIYQQIsEkIBNCCCGESDAJyLqe2YluQBcj1zu+5HrHn1zz+JLrHT9xvdZSQyaEEEIIkWCSIRNCCCGESDAJyNo5pVR/pdRnSqnVSqmVSqlfWtuzlVKfKKXWW7fdre09rOMrlVL/DjvXeUqpZdZ57m7mNScrpZYrpTYopR5QSilr+8+s7UuUUl8qpUbH8r0nQju73pcrpXZb13uJUuqnsXzv8dbOrvV9Idd5nVKqNIZvPaHa2XUfqJSaY52jQCnVL5bvPd4SdK3vVEptU0pVhm2foZRapJTyKaXOicX7TbQ2XO/jlFILrZ/NhUqpo0POFfFnNsJrNvWz3frrrbWWr3b8BfQGJln3M4B1wGjgbuAWa/stwN+t+2nA4cDPgH+HnKcHsBXItR4/AxzTxGvOB6YBCvgAONHanhlyzGnAh4m+Pp38el8ees7O9tWernXYMdcCTyb6+nSF6w68Clxm3T8aeC7R16cTXOtDrdetDNueD4wHngXOSfS1aSfX+yCgj3V/LLB9fz+zEV6zqZ/tVl9vyZC1c1rrnVrrRdb9CmA10Bc4HfNLiXV7hnVMldb6S6A27FSDgXVa693W40+Bs8NfTynVGxN4faPNT9WzIecuDzk0Deh0BYjt6Xp3du34Wl8AvNT2d9a+tbPrPhqYY93/zGpDpxHva22d41ut9c4I2zdrrZcBgQN6U+1YG673Yq31Dmv7SsCllEpu6d+K/fy/bPX1loCsA1FK5WMi+u+AvOAvnXXbcz9P3wCMVErlK6UcmB+a/hGO6wsUhjwutLYF23C1Umoj5hPHdW17Jx1De7jewNlWN8VrSqlIz+8U2sm1Rik1EBgEzG39u+h42sF1X0p9YHEmkKGU6tH6d9L+xelaC0sbrvfZwGKttZsW/K2wtPS4FpGArINQSqUDrwPXh2WqWkRrvQ/4OfBf4AtgM+CL9FKRnh5ynoe01kOA3wC/a207Oop2cr3fBfK11uMxn4ifiXBsh9dOrnXQ+cBrWmt/a9vR0bST634jcKRSajFwJLC9iXN0aHG81oLWX2+l1Bjg78D/BTdFOCxSj1BLj2sRCcg6AKWUE/PD9YLW+g1rc5GVLg2mTYv3dx6t9bta60O01tOAtcB6pZRd1Rcz/xkT4YcW1vYDdkQ43ct00q619nK9tdZ7rU9rAP8BJkfj/bUn7eVahzifTtxdGdRerrvWeofW+iyt9UHAb61tZVF6m+1CnK91l9fa663MQJI3gUu11hutzRF/Zg/g/2WLSEDWzlkjNp4AVmut7w3Z9Q5wmXX/MuDtFpyrp3XbHfgF8LjW2q+1nmh9/d5K51YopQ61XvvS4LmVUsNCTncysP4A3167086ud++Q052GqYfoNNrTtbaeOwLoDnwThbfXbrWn666UylFKBf8P3Qo8GYW32G7E+1pHt/UdT2uvt1IqC/gfcKvW+qvgwU39zLb2b0qr6XYwMkK+mh01cjgmBboMWGJ9nYQZdTMHExTNAbJDnrMZKAEqMRH8aGv7S8Aq6+v8Zl5zCrAC2Aj8m/oJhP+FKXxcginAHZPo69PJr/ffrOu91LreIxN9fTrrtbb2/RG4K9HXpStdd+Ac6/XWAY8DyYm+Pp3gWt9tPS9g3f7R2n6w9bgK2AusTPT1SfT1xpTdVIUcuwTo2dzPbCt+tlt9vWWmfiGEEEKIBJMuSyGEEEKIBJOATAghhBAiwSQgE0IIIYRIMAnIhBBCCCESTAIyIYQQQogEk4BMiC5MKZWllPpFyOM+SqnXYvRaZyilIs6VpJSqbOM5c5VSHzazv7dS6j3r/nFKqYVKqeXW7dEhx92plNq2v3YopQqUUmtDJoeMuOSNUmqz9TrB4x5oy/trph37vV5KqZlKqbKQNvw+ZN8J1vvYoJS6JWR7tlLqE6XUeuu2u7V9nFLq6Wi+ByFEQxKQCdG1ZWEmmQTqZk4/J0avdTPwcDRPqM1iyzuVUtObOOTXmFUOAPYAp2qtx2Emh3wu5Lh3gaktfNmLdP3kkM3NsH5UyHGJWvf1i5A2/BlAKWUHHgJOxCzufYFSarR1/C3AHK31MMx8TbcAaK2XA/2UUgPi/g6E6CIkIBOia7sLGGJlUP6hzOLFKwCUUpcrpd5SSr2rlNqklLpGKfVrpdRipdS3Sqls67ghSqkPrazTF0qpkeEvopQaDri11nusx4OUUt8opb5XSt0Rcly6UmqOUmqRlWE63dp+h1LqlyHH3amUCgY5bwEXNfH+zgY+BNBaL9ZaB5c1WQm4lFLJ1r5vtbX4cCxZGbb7lVJfK6VWKKWmWtuzrWu9zLq2463t6Uqpp6xrsUwpdXbIue5USi21js9rRTOmAhu01j9orT2YZdBOt/adTv2aqc/QcHm0dzFLSwkhYkACMiG6tluAjVYG5aYI+8cCF2L+id8JVGuz7uA3mGVCAGYD12qtJ2MWi46UBZsOLAp5/C/gEa31wcCukO21wJla60nAUcA/Q5ZDuQzAWmrnfOAF6zkLgCPCX1ApNQjYp+vXAw11NrC4iX3785QVwN5uta0pn4V0F/4qZHua1vowTGYyuFTQn6z2jAduA561tt8OlGmtx1n75gbPAXyrtZ4AzAOubKIN06yg7QNlFlAG6AtsCzmm0NoGkBcMTK3b0C7ZiNdZCBEdjkQ3QAjRrn2mta7ArNdWhsmSACwHxiul0oHDgFdDYpPkCOfpDewOeTwdExSB6Tr8u3VfAX9VSs3ALP3SFxMkbFZK7VVKHQTkYYKXvdZzioE+LXhN8wImMPk7cHyz7zyyi7TW25VSGZgFjC+hPngKd1QwIxjmJQCt9TylVKYy6+kdjnU9tNZzlVI9lFLdgGMJyUpprfdZdz3Ae9b9hcBxEV5nETBQa12plDoJk0kchrnG4VqyZEtT11kIEQWSIRNCNCc0gxQIeRzAfKCzAaUhdUoTtdajIpynBnCFbYsUBFwE5AKTtdYTgaKQ5z0OXA5cQcNFqF3W+ff7mkqpfsCbwKVa640RnhN6rD0kw/VnAK31duu2Av6/vbt3jSKIwzj+fYJRCIgEFCx8K9RWBLFKYQrBQgiCQSFlSgM2FgoqKUSCgqCV/4AWacSIQkRQA7FJChMUxShaxEIRxKiNMfwsZo6Mx4bE4+IVeT7N3e3NTHbmmiczs7vcBg5WlVtGfb+DpUOSKsoDzMfic+8WqPjnOiLmIuJHfv8AaJe0mTQjtr0oug2oLeV+Un6ofX4t98gtNc5m1gQOZGZr23dgY6OVI2IOeC+pF0DJvoqir4DdxedxFmd+yv1fm4DPETEvqRvYWXx3BzhCemjvaHF8L+nhvvXeALtqH/JM1H3gXESMr6BvC0XIvChpXQ40SGoHjgIv6sst1y5wIrfRRVqO/EZaduzLxw8BX/LYPgQGij50rqD9WtmttSXVvFetjfSQ4wlgT97Ht570O4zkaiPkpeH8erdocqlxNrMmcCAzW8Pyst943mB+tcFm+oB+SVOkzfI9FWXGgP3FnqvTwClJE6QQVnMLOCBpMrf7ujjXX8BjYDgiFoo63aSgVd+3n8A7SbUgOEAKhRdUd9sKSVckzQIdkmYlDVb0YQMwKmkaeA58ZPEKzirlHrJyWfOrpGfATaA/HxvM/Z4mXWhRC0WXgM78+0zlvq7UcaBW7wZwMpLfeSxGSUF5OCJe5jpDwGFJM6Rl0KGivcpxNrPm0OKst5nZ6pF0HbgXEY8arN9G2hfVGxEzxfExoKfYX1XWOUZa/jzf4Gk3laQnwJmImGz1ufyLfDXqU6ArBzozazLPkJnZ/3IZ6GikotJ9st6S7pFVhrEtwLWqMAYQEXeAD438TfvLDuCsw5jZ6vEMmZmZmVmLeYbMzMzMrMUcyMzMzMxazIHMzMzMrMUcyMzMzMxazIHMzMzMrMUcyMzMzMxa7A/nXx+0dwoJXwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/MSI-1016TH/Documents/ผลการทดลอง/output model A 21-5-500-8V.csv 12385\n",
      "output model A 21-5-500-8V\n",
      "31.06184\n",
      "/Users/MSI-1016TH/Documents/ผลการทดลอง/output model CNN LSTM rmse run 1.csv 1\n"
     ]
    }
   ],
   "source": [
    "Export_folder_name = \"/Users/MSI-1016TH/Documents/ผลการทดลอง/\"\n",
    "# Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง/\"\n",
    "\n",
    "Epochs = [500]\n",
    "# n_in = [10,14,21]\n",
    "# n_out = [1,3,5,7]\n",
    "# Epochs = [5]\n",
    "n_in = [21]\n",
    "n_out = [5]\n",
    "list_name_result = []\n",
    "list_rmse_result = []\n",
    "list_rmse_all_result = []\n",
    "for i in range(len(Epochs)):\n",
    "    for j in range(len(n_in)):\n",
    "         for k in range(len(n_out)):\n",
    "            result_train = train_loop(Epochs[i],n_in[j],n_out[k],Export_folder_name)\n",
    "            print(result_train[0])\n",
    "            print(result_train[1])\n",
    "            list_name_result.append(result_train[0]) \n",
    "            list_rmse_result.append(result_train[1])\n",
    "            list_rmse_all_result.append(result_train[2]) \n",
    "\n",
    "d = {'name': list_name_result, 'rmse': list_rmse_result,'rmse_all': list_rmse_all_result}\n",
    "df_result = pd.DataFrame(data=d)\n",
    "\n",
    "file_name = 'output model CNN LSTM rmse run 1'\n",
    "file_name_save = file_name +'.csv'\n",
    "dataset_path_save = Export_folder_name + file_name_save\n",
    "df_result.to_csv(dataset_path_save, index=False, encoding=\"TIS-620\")\n",
    "print(\"{} {}\" .format(dataset_path_save,len(df_result)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf_2.4_ts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcdeb12b9765c5f0be135c78098b34d39651f762d518870df951bed52914d1c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
