{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "\n",
    "import datetime,os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name and Path\n",
    "cwd = os.getcwd()\n",
    "path_adress = \"/Import_Dataset/\"\n",
    "\n",
    "# ข้อมูล พิกัดสถานที่เเละรายชื้ออ้างอิงสถานที่ตรวจวัด\n",
    "file_name_st = 'Data_lat_long_Rice research Center'\n",
    "csv_file_st = cwd + path_adress + file_name_st + '.csv'\n",
    "\n",
    "df_st = pd.read_csv(csv_file_st)\n",
    "print(\"All low RiceCenter {} station\" .format(df_st.shape[0]))\n",
    "\n",
    "data_list_st_num = list(range(0, len(df_st)))\n",
    "data_list_st_name = []\n",
    "data_list_st_name = df_st['nameEng'].values.tolist()\n",
    "data_list_st_lat = df_st['Latitude'].values.tolist()\n",
    "data_list_st_long = df_st['Longitude'].values.tolist()\n",
    "\n",
    "#################-- Moving Averag data --#################\n",
    "def mavr_dataset(frames_sma,rolling_num,our_rate,mode):    \n",
    "    h_name = list(frames_sma)\n",
    "    if mode == 'sum':\n",
    "        frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "        frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "        frames_sma['precip'] = frames_sma['precip'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    else:\n",
    "        frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "        frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "        frames_sma['precip'] = frames_sma['precip'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "   \n",
    "    for i in range(7,12):\n",
    "        frames_sma[h_name[i]] = frames_sma[h_name[i]].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "\n",
    "    constant_subset = frames_sma[::our_rate] \n",
    "    return constant_subset\n",
    "\n",
    "#################-- creat_dataset  --#################\n",
    "def creat_dataset(st_BPH = 'ALL', y_1='2015', y_2='2019', m_avr='ALL'):\n",
    "    for i in range(len(data_list_st_num)):\n",
    "        st = i\n",
    "        file_name = df_st['nameEng'][data_list_st_num[st]]\n",
    "        name_input = file_name\n",
    "        name_locals = 'stN_' + file_name\n",
    "\n",
    "        # File name and Path\n",
    "        csv_file = cwd + path_adress + name_input + '.csv'\n",
    "        # index_col=0 , index_col=None\n",
    "        dataset = pd.read_csv(csv_file, header=0,\n",
    "                              index_col=0, encoding=\"TIS-620\")\n",
    "\n",
    "        if m_avr == '3-DAY-All-':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,1,'mean')\n",
    "        elif m_avr == '7-DAY-All':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,1,'mean')\n",
    "        elif m_avr == '14-DAY-All':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,14,1,'mean')\n",
    "        elif m_avr == '3-DAY-Sampling':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,3,'sum')\n",
    "        elif m_avr == '7-DAY-Sampling':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,7,'sum')\n",
    "        elif m_avr == '14-DAY-Sampling':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,14,14,'sum')\n",
    "        else :\n",
    "            locals()[name_locals] = dataset\n",
    "            # print(f'Dataframe name_station: {st+1 , name_input}')\n",
    "        print('wait......')\n",
    "        del dataset\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    date_start = y_1 + '-01' + '-01'\n",
    "    date_stop = y_2 + '-12' + '-31'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "    if st_BPH != 'ALL' :\n",
    "        # file_name = df_st['nameEng'][data_list_st_num[st_BPH]]\n",
    "        file_name = st_BPH\n",
    "        locals_input = 'stN_' + file_name\n",
    "        print(locals_input)\n",
    "        dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "        frames_st = dataset_st\n",
    "    else:\n",
    "        m = 0\n",
    "        for j in range(len(data_list_st_num)):\n",
    "            # for j in range(df_st.shape[0]):\n",
    "            # file_name = df_st['nameEng'][j]\n",
    "            file_name = df_st['nameEng'][data_list_st_num[j]]\n",
    "            locals_input = 'stN_' + file_name\n",
    "            print(locals_input)\n",
    "            dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "            clear_output(wait=True)\n",
    "            if m == 0:\n",
    "                frames_st = dataset_st\n",
    "                m = m+1\n",
    "                print(m)\n",
    "            else:\n",
    "                frames_st = [frames_st, dataset_st]\n",
    "                frames_st = pd.concat(frames_st)\n",
    "\n",
    "    # dataset    \n",
    "    frames = frames_st\n",
    "    return frames\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#################-- Drop Colum  --#################\n",
    "def drop_col(df_drop,drop = ['address']):\n",
    "    for j in range(len(drop)):\n",
    "        df_drop = df_drop.drop(drop[j], axis=1)\n",
    "    return df_drop\n",
    "\n",
    "#################--      Plot        --#################\n",
    "def plot_data(frames_train,plot_cols,df_name,start='2015',end='2017',st = 'ALL'):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    if st == 'ALL':\n",
    "        df_plot = frames_train[plot_cols]\n",
    "    else:\n",
    "        df_plot = frames_train[plot_cols].loc[start:end]\n",
    "    \n",
    "    plt.figure()    \n",
    "    # df_plot.plot(lw=1,grid=True,figsize=(13,30),subplots=True)\n",
    "    # df_plot.plot(lw=1,grid=True,subplots=True)\n",
    "    # df_plot.plot(marker='.',grid=True,linestyle = 'solid',subplots=True)\n",
    "    df_plot.plot(marker='.',grid=True,linestyle = 'solid')\n",
    "    plt.xlabel('Date time-'+ df_name)\n",
    "    plt.legend()\n",
    "    # plt.show()   \n",
    "\n",
    "#################--   get list of folders in directory   --#################\n",
    "dir_path = cwd + \"/Export_lstm/model/\"\n",
    "def get_list_folder():\n",
    "    folder_list = os.listdir(dir_path)\n",
    "    return folder_list\n",
    "\n",
    "def get_file_model(file_name):\n",
    "    txt = dir_path+file_name+\"/Training_model_data_discription.txt\"\n",
    "    string_data = open(txt,\"r\").read()\n",
    "    list_txt = list(string_data.split(\"\\n\"))\n",
    "    return list_txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################-- Dashboard Input Data--#########################################\n",
    "ALL = 'ALL'\n",
    "\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st = widgets.Output()\n",
    "def dropdown_station_eventhandler(change):\n",
    "    output_df_st.clear_output()\n",
    "    with output_df_st:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st_predict = widgets.Output()\n",
    "def dropdown_station_predict_eventhandler(change):\n",
    "    output_df_st_predict.clear_output()\n",
    "    with output_df_st_predict:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- load data  --#################\n",
    "\n",
    "\n",
    "output_df_train = widgets.Output()\n",
    "output_df_val = widgets.Output()\n",
    "output_df_test = widgets.Output()\n",
    "output_df_col = widgets.Output()\n",
    "def clicked_load(b):\n",
    "    global df_out_train\n",
    "    global df_out_val\n",
    "    global df_out_test\n",
    "    global selected_data \n",
    "    output_df_train.clear_output()\n",
    "    output_df_val.clear_output()\n",
    "    output_df_test.clear_output()\n",
    "    output_df_col.clear_output()\n",
    "    with output_df_train:\n",
    "        df_out_train = creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_train)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value))\n",
    "    with output_df_val:\n",
    "        df_out_val = creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_val)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value))\n",
    "    with output_df_test:\n",
    "        df_out_test = creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_test)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value))\n",
    "    with output_df_col:\n",
    "        checkbox_objects = []\n",
    "        # global selected_data\n",
    "        data = sorted(set(chek_list(df_out_train)),reverse=True)     \n",
    "        names = []\n",
    "        for key in data:\n",
    "                checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "                names.append(key)\n",
    " \n",
    "        arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "        ui = widgets.HBox(children=checkbox_objects)\n",
    "        display(ui)\n",
    "             \n",
    "        selected_data = []\n",
    "        def select_data(**kwargs):\n",
    "            selected_data.clear()\n",
    "            for key in kwargs:\n",
    "                if kwargs[key] is True:\n",
    "                    selected_data.append(key)\n",
    "            print(selected_data)\n",
    "\n",
    "        widgets.interactive_output(select_data, arg_dict)\n",
    "    \n",
    " \n",
    "#################-- Export data  --#################\n",
    "df_train = widgets.Output()\n",
    "df_val = widgets.Output()\n",
    "df_test = widgets.Output()\n",
    "def clicked_export(b):\n",
    "    df_train.clear_output()\n",
    "    df_val.clear_output()\n",
    "    df_test.clear_output()\n",
    "    global frames_train\n",
    "    global frames_val\n",
    "    global frames_test\n",
    "    with df_train:\n",
    "        frames_train = drop_col(df_out_train,selected_data) \n",
    "        display(frames_train)\n",
    "    with df_val:\n",
    "        frames_val = drop_col(df_out_val,selected_data) \n",
    "        display(frames_val)  \n",
    "    with df_test:\n",
    "        frames_test = drop_col(df_out_test,selected_data) \n",
    "        display(frames_test)  \n",
    "\n",
    "def chek_list(df_ch):\n",
    "        data_col = set(df_ch.columns)\n",
    "        return data_col      \n",
    "\n",
    "#################----------------------------- DashBoard display ----------------------------------#################\n",
    "dropdown_name_st = widgets.Dropdown(options = unique_sorted_values_plus_ALL(df_st.nameEng),description='station :')\n",
    "dropdown_sampling_data = widgets.Dropdown(options = ['All','3-DAY-All','7-DAY-All','14-DAY-All','3-DAY-Sampling','7-DAY-Sampling','14-DAY-Sampling'],valure = 'All-DAY',description='Sampling :')\n",
    "dropdown_year_train1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],description='Year-train :')\n",
    "dropdown_year_train2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2017')\n",
    "dropdown_year_val1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018',description='Year-val :')\n",
    "dropdown_year_val2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018')\n",
    "dropdown_year_test1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019',description='Year-test :')\n",
    "dropdown_year_test2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019')\n",
    "\n",
    "\n",
    "button_download = widgets.Button(description='load data',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_export = widgets.Button(description='export dataset',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "\n",
    "button_download.on_click(clicked_load)\n",
    "button_export.on_click(clicked_export)\n",
    "\n",
    "dropdown_name_st.observe(dropdown_station_eventhandler, names='value')\n",
    "\n",
    "\n",
    "item_layout = widgets.Layout(margin='0 0 15px 0')\n",
    "input_widgets_row1 = widgets.HBox([dropdown_name_st,dropdown_year_train1,dropdown_year_train2,dropdown_year_val1,dropdown_year_val2,dropdown_year_test1,dropdown_year_test2],layout = item_layout)\n",
    "input_widgets_row2 = widgets.HBox([dropdown_sampling_data,button_download,button_export],layout = item_layout)\n",
    "\n",
    "tab_dataset = widgets.Tab([output_df_st,output_df_train,output_df_val,output_df_test,output_df_col,df_train,df_val,df_test])\n",
    "tab_dataset.set_title(0, 'Dataset station')\n",
    "tab_dataset.set_title(1, 'train-data')\n",
    "tab_dataset.set_title(2, 'validation-data')\n",
    "tab_dataset.set_title(3, 'test-data')\n",
    "tab_dataset.set_title(4, 'Drop-data')\n",
    "tab_dataset.set_title(5, 'Dataset-train')\n",
    "tab_dataset.set_title(6, 'Dataset-validation')\n",
    "tab_dataset.set_title(7, 'Dataset-test')\n",
    "dashboard_dataset = widgets.VBox([input_widgets_row1,input_widgets_row2])\n",
    "display(dashboard_dataset)\n",
    "display(tab_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "def plot_data(frames_train,df_name):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    plt.figure()\n",
    "    df_plot = frames_train\n",
    "    df_plot.plot(lw=1,grid=True,figsize=(15,7),subplots=True)\n",
    "    plt.xlabel('time-(day)'+ df_name)\n",
    "    plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariate = [temp,precip,humidity,bph] 4\n",
    "#Multivariate = [temp,precip,humidity,day,month,bph] 6\n",
    "#Multivariate = [temp,precip,humidity,day,month,bph] + [rice] \n",
    "\n",
    "values_train = frames_train.values    \n",
    "n_features = frames_train.shape[1]\n",
    "\n",
    "values_validation = frames_val.values\n",
    "plot_data(frames_train,'  Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# In_day   Out_day\n",
    "#    7      1\n",
    "#    7      3\n",
    "#    7      5\n",
    "#    7      7\n",
    "#   14      1\n",
    "#   14      3\n",
    "#   14      5\n",
    "#   14      7\n",
    "#   21      1\n",
    "#   21      3\n",
    "#   21      5\n",
    "#   21      7\n",
    "\n",
    "n_day = 21\n",
    "n_out = 5\n",
    "\n",
    "#train data\n",
    "# ensure all data is float\n",
    "values = values_train.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_day, n_out)\n",
    "# print(reframed.shape)\n",
    "# print(reframed.head())\n",
    "\n",
    "# predict datasets\n",
    "values = reframed.values\n",
    "train = values\n",
    "\n",
    "#input \n",
    "n_obs = n_day * n_features\n",
    "# train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "train_X, train_y = train[:, :n_obs], train[:, -1]\n",
    "print(train_X.shape, len(train_X), train_y.shape)  #for train\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_day, n_features))\n",
    "print(train_X.shape, train_y.shape)\n",
    "\n",
    "#validation data\n",
    "# ensure all data is float\n",
    "values = values_validation.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_day, n_out)\n",
    "\n",
    "# predict datasets\n",
    "values = reframed.values\n",
    "test = values\n",
    "\n",
    "#output \n",
    "n_obs = n_day * n_features\n",
    "# test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "print(test_X.shape, len(test_X), test_y.shape)  #for train\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_day, n_features))\n",
    "print(test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "##------train-----## \n",
    "# Model A LSTM \n",
    "model = tf.keras.models.Sequential([\n",
    "                  # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "                  keras.layers.LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2]),activation='relu'),  #relu tanh\n",
    "                  keras.layers.Dense(units=1)\n",
    "    ])\n",
    "# Model B Bidirectional-LSTM\n",
    "# model = tf.keras.models.Sequential([\n",
    "#                   # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#                   keras.layers.Bidirectional(layers.LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2]),activation='relu')),  #relu tanh\n",
    "#                   keras.layers.Dense(units=1)\n",
    "#     ])\n",
    "# Model C Stacked_LSTM\n",
    "# model = tf.keras.models.Sequential([\n",
    "#                   # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#                   keras.layers.LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]),return_sequences=True,activation='relu'),\n",
    "#                   keras.layers.LSTM(50, activation='relu'),\n",
    "#                   keras.layers.Dense(units=1)\n",
    "#             ])\n",
    "            \n",
    "Optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "model.compile(Optimizer, loss='mae', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# fit network\n",
    "Epochs = 500\n",
    "batch_size = 128\n",
    "history = model.fit(train_X, train_y, \n",
    "                    epochs=Epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_data=(test_X, test_y), \n",
    "                    verbose=2, \n",
    "                    # callbacks=[cp_callback,es_callback], \n",
    "                    shuffle=False)\n",
    "\n",
    "# plot history\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    # plt.plot(history.history['val_loss'], label='val')\n",
    "    plt.xlabel('Epoch  '+'loss = %f'%history.history['loss'][-1])\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "plot_loss(history)\n",
    "\n",
    "# V ='6V'\n",
    "# Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 8V/\"\n",
    "# plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'-T'+'.png'\n",
    "# plt.savefig(Export_folder_name + plot_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "values_predict = frames_test.values\n",
    "n_features = frames_test.shape[1]\n",
    "df = frames_test.reset_index()\n",
    "date_time_predict = pd.to_datetime(df.pop('date'))\n",
    "\n",
    "# ensure all data is float\n",
    "values = values_predict.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "    \n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_day, n_out)\n",
    "# print(reframed.shape)\n",
    "# print(reframed.head())\n",
    "    \n",
    "# predict datasets\n",
    "values = reframed.values\n",
    "# n_train_day = int(values.shape[0]*0.9)\n",
    "# train = values[:n_train_day, :]\n",
    "test = values\n",
    "    \n",
    "# predict into input and outputs\n",
    "n_obs = n_day * n_features\n",
    "# test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "print(test_X.shape, len(test_X), test_y.shape)\n",
    "    \n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_day, n_features))\n",
    "print(test_X.shape, test_y.shape)\n",
    "    \n",
    "# # make a prediction\n",
    "yhat = model.predict(test_X,verbose=0)\n",
    "test_X_reshape = test_X.reshape((test_X.shape[0], n_day*n_features)) \n",
    "\n",
    "from cProfile import label\n",
    "from numpy import concatenate\n",
    "\n",
    "# invert scaling for forecast\n",
    "# inv_yhat = concatenate((yhat, test_X[:, -29:]), axis=1)\n",
    "inv_yhat = concatenate((test_X_reshape[:, :(n_features-1)], yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,-1]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y_reshape = test_y.reshape((len(test_y), 1))\n",
    "# inv_y = concatenate((test_y, test_X[:, -29:]), axis=1)\n",
    "inv_y = concatenate((test_X_reshape[:, :(n_features-1)], test_y_reshape), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,-1]\n",
    "\n",
    "d_range = 335\n",
    "pre_start = 0  \n",
    "# d_range = 60 #345\n",
    "# pre_start = 200 #0  200\n",
    "\n",
    "pre_stop = pre_start+d_range\n",
    "d_start = n_day+n_out-1+pre_start\n",
    "d_stop = n_day+n_out-1+pre_start+d_range\n",
    "\n",
    "\n",
    "# calculate RMSE\n",
    "m = tf.keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(inv_y[pre_start:pre_stop], inv_yhat[pre_start:pre_stop])\n",
    "rmse = m.result().numpy()\n",
    "print('RMSE: %.3f' % rmse)\n",
    "\n",
    "\n",
    "strings = list(frames_test.columns)\n",
    "textstr = '\\n'.join(strings[:12])\n",
    "\n",
    "from matplotlib import pyplot as plt1\n",
    "fig, ax = plt1.subplots()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_y[:],label='actual')\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_yhat[:],label='predict')\n",
    "\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_y[pre_start:pre_stop],label='actual')\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_yhat[pre_start:pre_stop],label='predict')\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('Multivariate-LSTM model-A' +'  RMSE: %.2f' % rmse)\n",
    "ax.set_xlabel('time (day) '+'(%d-'%n_day+'%d-'%n_out+'Epoch %d)'%Epochs)\n",
    "ax.set_ylabel('BPH Volume')\n",
    "ax.grid(True)\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', alpha=0.5)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt1.show()\n",
    "\n",
    "# V ='6V'\n",
    "# Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 6V/\"\n",
    "# plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'-Z'+'.png'\n",
    "# plt1.savefig(Export_folder_name + plot_name)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "# d_range = 345\n",
    "# pre_start = 0  \n",
    "d_range = 60 #345\n",
    "pre_start = 200 #0  200\n",
    "\n",
    "pre_stop = pre_start+d_range\n",
    "d_start = n_day+n_out-1+pre_start\n",
    "d_stop = n_day+n_out-1+pre_start+d_range\n",
    "\n",
    "\n",
    "# calculate RMSE\n",
    "m = tf.keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(inv_y[pre_start:pre_stop], inv_yhat[pre_start:pre_stop])\n",
    "rmse = m.result().numpy()\n",
    "print('RMSE: %.3f' % rmse)\n",
    "\n",
    "\n",
    "strings = list(frames_test.columns)\n",
    "textstr = '\\n'.join(strings[:12])\n",
    "from matplotlib import pyplot as plt2\n",
    "fig, ax = plt2.subplots()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_y[:],label='actual')\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_yhat[:],label='predict')\n",
    "\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_y[pre_start:pre_stop],label='actual')\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_yhat[pre_start:pre_stop],label='predict')\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('Multivariate-LSTM model-A' +'  RMSE: %.2f' % rmse)\n",
    "ax.set_xlabel('time (day) '+'(%d-'%n_day+'%d-'%n_out+'Epoch %d)'%Epochs)\n",
    "ax.set_ylabel('BPH Volume')\n",
    "ax.grid(True)\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', alpha=0.5)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt2.show()\n",
    "\n",
    "# V ='6V'\n",
    "# Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 6V/\"\n",
    "# plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'.png'\n",
    "# plt2.savefig(Export_folder_name + plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_predict = frames_test.values\n",
    "n_features = frames_test.shape[1]\n",
    "df = frames_test.reset_index()\n",
    "date_time_predict = pd.to_datetime(df.pop('date'))\n",
    "\n",
    "# ensure all data is float\n",
    "values = values_predict.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "    \n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_day, n_out)\n",
    "# print(reframed.shape)\n",
    "# print(reframed.head())\n",
    "    \n",
    "# predict datasets\n",
    "values = reframed.values\n",
    "# n_train_day = int(values.shape[0]*0.9)\n",
    "# train = values[:n_train_day, :]\n",
    "test = values\n",
    "    \n",
    "# predict into input and outputs\n",
    "n_obs = n_day * n_features\n",
    "# test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "print(test_X.shape, len(test_X), test_y.shape)\n",
    "    \n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_day, n_features))\n",
    "print(test_X.shape, test_y.shape)\n",
    "    \n",
    "# # make a prediction\n",
    "yhat = model.predict(test_X,verbose=0)\n",
    "test_X_reshape = test_X.reshape((test_X.shape[0], n_day*n_features)) \n",
    "\n",
    "from cProfile import label\n",
    "from numpy import concatenate\n",
    "\n",
    "# invert scaling for forecast\n",
    "# inv_yhat = concatenate((yhat, test_X[:, -29:]), axis=1)\n",
    "inv_yhat = concatenate((test_X_reshape[:, :(n_features-1)], yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,-1]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y_reshape = test_y.reshape((len(test_y), 1))\n",
    "# inv_y = concatenate((test_y, test_X[:, -29:]), axis=1)\n",
    "inv_y = concatenate((test_X_reshape[:, :(n_features-1)], test_y_reshape), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,-1]\n",
    "\n",
    "d_range = 335\n",
    "pre_start = 0  \n",
    "# d_range = 60 #345\n",
    "# pre_start = 200 #0  200\n",
    "\n",
    "pre_stop = pre_start+d_range\n",
    "d_start = n_day+n_out-1+pre_start\n",
    "d_stop = n_day+n_out-1+pre_start+d_range\n",
    "\n",
    "\n",
    "# calculate RMSE\n",
    "m = tf.keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(inv_y[pre_start:pre_stop], inv_yhat[pre_start:pre_stop])\n",
    "rmse = m.result().numpy()\n",
    "print('RMSE: %.3f' % rmse)\n",
    "\n",
    "\n",
    "strings = list(frames_test.columns)\n",
    "textstr = '\\n'.join(strings[:12])\n",
    "\n",
    "from matplotlib import pyplot as plt1\n",
    "fig, ax = plt1.subplots()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_y[:],label='actual')\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_yhat[:],label='predict')\n",
    "\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_y[pre_start:pre_stop],label='actual')\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_yhat[pre_start:pre_stop],label='predict')\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('Multivariate-LSTM model-A' +'  RMSE: %.2f' % rmse)\n",
    "ax.set_xlabel('time (day) '+'(%d-'%n_day+'%d-'%n_out+'Epoch %d)'%Epochs)\n",
    "ax.set_ylabel('BPH Volume')\n",
    "ax.grid(True)\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', alpha=0.5)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt1.show()\n",
    "\n",
    "V ='6V'\n",
    "Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 6V/\"\n",
    "plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'-Z'+'.png'\n",
    "plt1.savefig(Export_folder_name + plot_name)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "# d_range = 345\n",
    "# pre_start = 0  \n",
    "d_range = 60 #345\n",
    "pre_start = 200 #0  200\n",
    "\n",
    "pre_stop = pre_start+d_range\n",
    "d_start = n_day+n_out-1+pre_start\n",
    "d_stop = n_day+n_out-1+pre_start+d_range\n",
    "\n",
    "\n",
    "# calculate RMSE\n",
    "m = tf.keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(inv_y[pre_start:pre_stop], inv_yhat[pre_start:pre_stop])\n",
    "rmse = m.result().numpy()\n",
    "print('RMSE: %.3f' % rmse)\n",
    "\n",
    "\n",
    "strings = list(frames_test.columns)\n",
    "textstr = '\\n'.join(strings[:12])\n",
    "from matplotlib import pyplot as plt2\n",
    "fig, ax = plt2.subplots()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_y[:],label='actual')\n",
    "# ax.plot(date_time_predict[n_day+n_out-1:],inv_yhat[:],label='predict')\n",
    "\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_y[pre_start:pre_stop],label='actual')\n",
    "ax.plot(date_time_predict[d_start:d_stop],inv_yhat[pre_start:pre_stop],label='predict')\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('Multivariate-LSTM model-A' +'  RMSE: %.2f' % rmse)\n",
    "ax.set_xlabel('time (day) '+'(%d-'%n_day+'%d-'%n_out+'Epoch %d)'%Epochs)\n",
    "ax.set_ylabel('BPH Volume')\n",
    "ax.grid(True)\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', alpha=0.5)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt2.show()\n",
    "\n",
    "V ='6V'\n",
    "Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 6V/\"\n",
    "plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'.png'\n",
    "plt2.savefig(Export_folder_name + plot_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V ='6V'\n",
    "Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 6V/\"\n",
    "plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'-Z'+'.png'\n",
    "plt.savefig(Export_folder_name + plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V ='6V'\n",
    "Export_folder_name = \"/home/np13-sut-pc/Documents/ผลการทดลอง 6V/\"\n",
    "plot_name = 'output model A '+str(n_day)+'-'+str(n_out)+'-'+str(Epochs)+'-'+V+'.png'\n",
    "plt.savefig(Export_folder_name + plot_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb01e479798b652ff2decc92044ac783e2e74b0a89b91ea27564b1f393a8174f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
