{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import datetime,os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "# import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "# import platform\n",
    "# print(platform.python_version())\n",
    "# print(np.__version__)\n",
    "# print(tf.__version__)\n",
    "\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All low RiceCenter 34 station\n"
     ]
    }
   ],
   "source": [
    "# File name and Path\n",
    "cwd = os.getcwd()\n",
    "path_adress = \"/Import_Dataset/\"\n",
    "\n",
    "# ข้อมูล พิกัดสถานที่เเละรายชื้ออ้างอิงสถานที่ตรวจวัด\n",
    "file_name_st = 'Data_lat_long_Rice research Center'\n",
    "csv_file_st = cwd + path_adress + file_name_st + '.csv'\n",
    "\n",
    "df_st = pd.read_csv(csv_file_st)\n",
    "print(\"All low RiceCenter {} station\" .format(df_st.shape[0]))\n",
    "\n",
    "data_list_st_num = list(range(0, len(df_st)))\n",
    "data_list_st_name = []\n",
    "data_list_st_name = df_st['nameEng'].values.tolist()\n",
    "data_list_st_lat = df_st['Latitude'].values.tolist()\n",
    "data_list_st_long = df_st['Longitude'].values.tolist()\n",
    "\n",
    "#################-- Moving Averag data --#################\n",
    "def mavr_dataset(frames_sma,rolling_num,our_rate):    \n",
    "    h_name = list(frames_sma)\n",
    "    frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    # frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "    # frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "    for i in range(7,14):\n",
    "        frames_sma[h_name[i]] = frames_sma[h_name[i]].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "\n",
    "    constant_subset = frames_sma[::our_rate] \n",
    "    return constant_subset\n",
    "\n",
    "#################-- creat_dataset  --#################\n",
    "def creat_dataset(st_BPH = 'ALL', y_1='2015', y_2='2019', m_avr='ALL-DAY'):\n",
    "    for i in range(len(data_list_st_num)):\n",
    "        st = i\n",
    "        file_name = df_st['nameEng'][data_list_st_num[st]]\n",
    "        name_input = file_name\n",
    "        name_locals = 'stN_' + file_name\n",
    "\n",
    "        # File name and Path\n",
    "        csv_file = cwd + path_adress + name_input + '.csv'\n",
    "        # index_col=0 , index_col=None\n",
    "        dataset = pd.read_csv(csv_file, header=0,\n",
    "                              index_col=0, encoding=\"TIS-620\")\n",
    "\n",
    "        if m_avr == '3-DAY':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,3)\n",
    "        elif m_avr == '7-DAY':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,7)\n",
    "        else :\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,1)\n",
    "            # print(f'Dataframe name_station: {st+1 , name_input}')\n",
    "        print('wait......')\n",
    "        del dataset\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    date_start = y_1 + '-01' + '-01'\n",
    "    date_stop = y_2 + '-12' + '-31'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "    if st_BPH != 'ALL' :\n",
    "        # file_name = df_st['nameEng'][data_list_st_num[st_BPH]]\n",
    "        file_name = st_BPH\n",
    "        locals_input = 'stN_' + file_name\n",
    "        print(locals_input)\n",
    "        dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "        frames_st = dataset_st\n",
    "    else:\n",
    "        m = 0\n",
    "        for j in range(len(data_list_st_num)):\n",
    "            # for j in range(df_st.shape[0]):\n",
    "            # file_name = df_st['nameEng'][j]\n",
    "            file_name = df_st['nameEng'][data_list_st_num[j]]\n",
    "            locals_input = 'stN_' + file_name\n",
    "            print(locals_input)\n",
    "            dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "            clear_output(wait=True)\n",
    "            if m == 0:\n",
    "                frames_st = dataset_st\n",
    "                m = m+1\n",
    "                print(m)\n",
    "            else:\n",
    "                frames_st = [frames_st, dataset_st]\n",
    "                frames_st = pd.concat(frames_st)\n",
    "\n",
    "    # dataset    \n",
    "    frames = frames_st\n",
    "    return frames\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#################-- Drop Colum  --#################\n",
    "def drop_col(df_drop,drop = ['address']):\n",
    "    for j in range(len(drop)):\n",
    "        df_drop = df_drop.drop(drop[j], axis=1)\n",
    "    return df_drop\n",
    "\n",
    "#################--      Plot        --#################\n",
    "def plot_data(frames_train,plot_cols,df_name,start='2015',end='2017',st = 'ALL'):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    if st == 'ALL':\n",
    "        df_plot = frames_train[plot_cols]\n",
    "    else:\n",
    "        df_plot = frames_train[plot_cols].loc[start:end]\n",
    "    \n",
    "    plt.figure()    \n",
    "    # df_plot.plot(lw=1,grid=True,figsize=(13,30),subplots=True)\n",
    "    # df_plot.plot(lw=1,grid=True,subplots=True)\n",
    "    # df_plot.plot(marker='.',grid=True,linestyle = 'solid',subplots=True)\n",
    "    df_plot.plot(marker='.',grid=True,linestyle = 'solid')\n",
    "    plt.xlabel('Date time-'+ df_name)\n",
    "    plt.legend()\n",
    "    # plt.show()   \n",
    "\n",
    "#################--   get list of folders in directory   --#################\n",
    "dir_path = cwd + \"/Export_lstm/model/\"\n",
    "def get_list_folder():\n",
    "    folder_list = os.listdir(dir_path)\n",
    "    return folder_list\n",
    "\n",
    "def get_file_model(file_name):\n",
    "    txt = dir_path+file_name+\"/Training_model_data_discription.txt\"\n",
    "    string_data = open(txt,\"r\").read()\n",
    "    list_txt = list(string_data.split(\"\\n\"))\n",
    "    return list_txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcea0f70d0474d9b9e853ebd8521fb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='station :', options=('ALL', 'Chachoengsao Rice research Ce…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585ed2dcd4584305a04100f56ee601c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################-- Dashboard Input Data--#########################################\n",
    "ALL = 'ALL'\n",
    "\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st = widgets.Output()\n",
    "def dropdown_station_eventhandler(change):\n",
    "    output_df_st.clear_output()\n",
    "    with output_df_st:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st_predict = widgets.Output()\n",
    "def dropdown_station_predict_eventhandler(change):\n",
    "    output_df_st_predict.clear_output()\n",
    "    with output_df_st_predict:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- load data  --#################\n",
    "\n",
    "\n",
    "output_df_train = widgets.Output()\n",
    "output_df_val = widgets.Output()\n",
    "output_df_test = widgets.Output()\n",
    "output_df_col = widgets.Output()\n",
    "def clicked_load(b):\n",
    "    global df_out_train\n",
    "    global df_out_val\n",
    "    global df_out_test\n",
    "    global selected_data \n",
    "    output_df_train.clear_output()\n",
    "    output_df_val.clear_output()\n",
    "    output_df_test.clear_output()\n",
    "    output_df_col.clear_output()\n",
    "    with output_df_train:\n",
    "        df_out_train = creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_train)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value))\n",
    "    with output_df_val:\n",
    "        df_out_val = creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_val)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value))\n",
    "    with output_df_test:\n",
    "        df_out_test = creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_test)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value))\n",
    "    with output_df_col:\n",
    "        checkbox_objects = []\n",
    "        # global selected_data\n",
    "        data = sorted(set(chek_list(df_out_train)),reverse=True)     \n",
    "        names = []\n",
    "        for key in data:\n",
    "                checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "                names.append(key)\n",
    " \n",
    "        arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "        ui = widgets.HBox(children=checkbox_objects)\n",
    "        display(ui)\n",
    "             \n",
    "        selected_data = []\n",
    "        def select_data(**kwargs):\n",
    "            selected_data.clear()\n",
    "            for key in kwargs:\n",
    "                if kwargs[key] is True:\n",
    "                    selected_data.append(key)\n",
    "            print(selected_data)\n",
    "\n",
    "        widgets.interactive_output(select_data, arg_dict)\n",
    "    \n",
    " \n",
    "#################-- Export data  --#################\n",
    "df_train = widgets.Output()\n",
    "df_val = widgets.Output()\n",
    "df_test = widgets.Output()\n",
    "def clicked_export(b):\n",
    "    df_train.clear_output()\n",
    "    df_val.clear_output()\n",
    "    df_test.clear_output()\n",
    "    global frames_train\n",
    "    global frames_val\n",
    "    global frames_test\n",
    "    with df_train:\n",
    "        frames_train = drop_col(df_out_train,selected_data) \n",
    "        display(frames_train)\n",
    "    with df_val:\n",
    "        frames_val = drop_col(df_out_val,selected_data) \n",
    "        display(frames_val)  \n",
    "    with df_test:\n",
    "        frames_test = drop_col(df_out_test,selected_data) \n",
    "        display(frames_test)  \n",
    "\n",
    "def chek_list(df_ch):\n",
    "        data_col = set(df_ch.columns)\n",
    "        return data_col      \n",
    "\n",
    "#################----------------------------- DashBoard display ----------------------------------#################\n",
    "dropdown_name_st = widgets.Dropdown(options = unique_sorted_values_plus_ALL(df_st.nameEng),description='station :')\n",
    "dropdown_sampling_data = widgets.Dropdown(options = ['All-DAY','3-DAY','7-DAY'],valure = 'All-DAY',description='Sampling :')\n",
    "dropdown_year_train1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],description='Year-train :')\n",
    "dropdown_year_train2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2017')\n",
    "dropdown_year_val1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018',description='Year-val :')\n",
    "dropdown_year_val2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018')\n",
    "dropdown_year_test1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019',description='Year-test :')\n",
    "dropdown_year_test2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019')\n",
    "\n",
    "\n",
    "button_download = widgets.Button(description='load data',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_export = widgets.Button(description='export dataset',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "\n",
    "button_download.on_click(clicked_load)\n",
    "button_export.on_click(clicked_export)\n",
    "\n",
    "dropdown_name_st.observe(dropdown_station_eventhandler, names='value')\n",
    "\n",
    "\n",
    "item_layout = widgets.Layout(margin='0 0 15px 0')\n",
    "input_widgets_row1 = widgets.HBox([dropdown_name_st,dropdown_year_train1,dropdown_year_train2,dropdown_year_val1,dropdown_year_val2,dropdown_year_test1,dropdown_year_test2],layout = item_layout)\n",
    "input_widgets_row2 = widgets.HBox([dropdown_sampling_data,button_download,button_export],layout = item_layout)\n",
    "\n",
    "tab_dataset = widgets.Tab([output_df_st,output_df_train,output_df_val,output_df_test,output_df_col,df_train,df_val,df_test])\n",
    "tab_dataset.set_title(0, 'Dataset station')\n",
    "tab_dataset.set_title(1, 'train-data')\n",
    "tab_dataset.set_title(2, 'validation-data')\n",
    "tab_dataset.set_title(3, 'test-data')\n",
    "tab_dataset.set_title(4, 'Drop-data')\n",
    "tab_dataset.set_title(5, 'Dataset-train')\n",
    "tab_dataset.set_title(6, 'Dataset-validation')\n",
    "tab_dataset.set_title(7, 'Dataset-test')\n",
    "dashboard_dataset = widgets.VBox([input_widgets_row1,input_widgets_row2])\n",
    "display(dashboard_dataset)\n",
    "display(tab_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "from numpy import array\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data,n_in,n_out):\t\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\t\tcols.append(df.shift(i))\n",
    "\t\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\tfor i in range(0, n_out):\n",
    "\t\t\tcols.append(df.shift(-i))\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\t\telse:\n",
    "\t\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\tagg.dropna(inplace=True)\n",
    "\t\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3\n",
    "n_out = 1\n",
    "data_train = frames_train.iloc[:10]\n",
    "reframed = series_to_supervised(data_train,n_steps,n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-10</th>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            var1(t-3)  var2(t-3)  var1(t-2)  var2(t-2)  var1(t-1)  var2(t-1)  \\\n",
       "date                                                                           \n",
       "2015-01-04       25.7        0.0       24.7        0.0       23.7        0.0   \n",
       "2015-01-05       24.7        0.0       23.7        0.0       24.7        0.0   \n",
       "2015-01-06       23.7        0.0       24.7        0.0       25.1        0.0   \n",
       "2015-01-07       24.7        0.0       25.1        0.0       26.0        0.0   \n",
       "2015-01-08       25.1        0.0       26.0        0.0       26.5        0.0   \n",
       "2015-01-09       26.0        0.0       26.5        0.0       26.5        0.0   \n",
       "2015-01-10       26.5        0.0       26.5        0.0       27.2        0.0   \n",
       "\n",
       "            var1(t)  var2(t)  \n",
       "date                          \n",
       "2015-01-04     24.7      0.0  \n",
       "2015-01-05     25.1      0.0  \n",
       "2015-01-06     26.0      0.0  \n",
       "2015-01-07     26.5      0.0  \n",
       "2015-01-08     26.5      0.0  \n",
       "2015-01-09     27.2      0.0  \n",
       "2015-01-10     28.1      0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "values = reframed.values\n",
    "n_features = 1\n",
    "#input \n",
    "n_obs = n_steps \n",
    "dataset_X, dataset_y = values[:, :n_obs], values[:, -1]\n",
    "print('sample:',dataset_X.shape,'n_input:', len(dataset_X),'n_output:', dataset_y.shape) \n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "dataset_X = dataset_X.reshape((dataset_X.shape[0], n_steps, n_features))\n",
    "print(dataset_X.shape, dataset_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate lstm example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = dataset_X\n",
    "y = dataset_y\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction\n",
    "# x_input = array([29.8 ,30.6, 31. , 30.8, 31.5, 31.9 ,32.4])\n",
    "# x_input = x_input.reshape((1, n_steps, n_features))\n",
    "# x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict = frames_val.iloc[:]\n",
    "reframed_predict = series_to_supervised(data_predict,n_steps,n_out)\n",
    "# datasets\n",
    "values_predict = reframed_predict.values\n",
    "n_features = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "n_obs = n_steps \n",
    "dataset_Xp, dataset_yp = values_predict[:, :n_obs], values_predict[:, -1]\n",
    "print('sample:',dataset_Xp.shape,'n_input:', len(dataset_Xp),'n_output:', dataset_yp.shape) \n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "dataset_Xp = dataset_Xp.reshape((dataset_Xp.shape[0], n_steps, n_features))\n",
    "print(dataset_Xp.shape, dataset_yp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = dataset_Xp\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "# print(yhat)\n",
    "out = yhat.tolist()\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(dataset_yp, columns = ['Column_A'])\n",
    "df_2 = pd.DataFrame(out, columns = ['Column_B'])\n",
    "df_1['Column_B']=df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_1.plot(lw=1,grid=True,figsize=(35,10),subplots=False,marker='.')\n",
    "plt.xlabel('Date time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 25, 35, 45, 55, 65, 75, 85, 95])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  45,  65,  85, 105, 125, 145, 165, 185])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
