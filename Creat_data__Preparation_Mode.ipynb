{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import datetime,os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "# import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "import platform\n",
    "print(platform.python_version())\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name and Path\n",
    "cwd = os.getcwd()\n",
    "path_adress = \"/Import_Dataset/\"\n",
    "\n",
    "# ข้อมูล พิกัดสถานที่เเละรายชื้ออ้างอิงสถานที่ตรวจวัด\n",
    "file_name_st = 'Data_lat_long_Rice research Center'\n",
    "csv_file_st = cwd + path_adress + file_name_st + '.csv'\n",
    "\n",
    "df_st = pd.read_csv(csv_file_st)\n",
    "print(\"All low RiceCenter {} station\" .format(df_st.shape[0]))\n",
    "\n",
    "data_list_st_num = list(range(0, len(df_st)))\n",
    "data_list_st_name = []\n",
    "data_list_st_name = df_st['nameEng'].values.tolist()\n",
    "data_list_st_lat = df_st['Latitude'].values.tolist()\n",
    "data_list_st_long = df_st['Longitude'].values.tolist()\n",
    "\n",
    "#################-- Moving Averag data --#################\n",
    "def mavr_dataset(frames_sma,rolling_num,our_rate):    \n",
    "    h_name = list(frames_sma)\n",
    "    frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    # frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "    # frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "    for i in range(7,14):\n",
    "        frames_sma[h_name[i]] = frames_sma[h_name[i]].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "\n",
    "    constant_subset = frames_sma[::our_rate] \n",
    "    return constant_subset\n",
    "\n",
    "#################-- creat_dataset  --#################\n",
    "def creat_dataset(st_BPH = 'ALL', y_1='2015', y_2='2019', m_avr='ALL-DAY'):\n",
    "    for i in range(len(data_list_st_num)):\n",
    "        st = i\n",
    "        file_name = df_st['nameEng'][data_list_st_num[st]]\n",
    "        name_input = file_name\n",
    "        name_locals = 'stN_' + file_name\n",
    "\n",
    "        # File name and Path\n",
    "        csv_file = cwd + path_adress + name_input + '.csv'\n",
    "        # index_col=0 , index_col=None\n",
    "        dataset = pd.read_csv(csv_file, header=0,\n",
    "                              index_col=0, encoding=\"TIS-620\")\n",
    "\n",
    "        if m_avr == '3-DAY':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,3)\n",
    "        elif m_avr == '7-DAY':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,7)\n",
    "        else :\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,1)\n",
    "            # print(f'Dataframe name_station: {st+1 , name_input}')\n",
    "        print('wait......')\n",
    "        del dataset\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    date_start = y_1 + '-01' + '-01'\n",
    "    date_stop = y_2 + '-12' + '-31'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "    if st_BPH != 'ALL' :\n",
    "        # file_name = df_st['nameEng'][data_list_st_num[st_BPH]]\n",
    "        file_name = st_BPH\n",
    "        locals_input = 'stN_' + file_name\n",
    "        print(locals_input)\n",
    "        dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "        frames_st = dataset_st\n",
    "    else:\n",
    "        m = 0\n",
    "        for j in range(len(data_list_st_num)):\n",
    "            # for j in range(df_st.shape[0]):\n",
    "            # file_name = df_st['nameEng'][j]\n",
    "            file_name = df_st['nameEng'][data_list_st_num[j]]\n",
    "            locals_input = 'stN_' + file_name\n",
    "            print(locals_input)\n",
    "            dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "            clear_output(wait=True)\n",
    "            if m == 0:\n",
    "                frames_st = dataset_st\n",
    "                m = m+1\n",
    "                print(m)\n",
    "            else:\n",
    "                frames_st = [frames_st, dataset_st]\n",
    "                frames_st = pd.concat(frames_st)\n",
    "\n",
    "    # dataset    \n",
    "    frames = frames_st\n",
    "    return frames\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#################-- Drop Colum  --#################\n",
    "def drop_col(df_drop,drop = ['address']):\n",
    "    for j in range(len(drop)):\n",
    "        df_drop = df_drop.drop(drop[j], axis=1)\n",
    "    return df_drop\n",
    "\n",
    "#################--      Plot        --#################\n",
    "def plot_data(frames_train,plot_cols,df_name,start='2015',end='2017'):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    \n",
    "    df_plot = frames_train[plot_cols].loc[start:end]\n",
    "    plt.figure()    \n",
    "    # df_plot.plot(lw=1,grid=True,figsize=(13,30),subplots=True)\n",
    "    # df_plot.plot(lw=1,grid=True,subplots=True)\n",
    "    # df_plot.plot(marker='.',grid=True,linestyle = 'solid',subplots=True)\n",
    "    df_plot.plot(marker='.',grid=True,linestyle = 'solid')\n",
    "    plt.xlabel('Date time-'+ df_name)\n",
    "    plt.legend()\n",
    "    # plt.show()   \n",
    "\n",
    "#################--                  --#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################-- convert series to supervised learning --#################\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "#################--          data_preprocess        --#################\n",
    "def data_preprocess(data_frames,n_day,n_out):\n",
    "      values_df = data_frames.values    #ตัด header กับ idx ออก เป็น array matrix\n",
    "      n_features = data_frames.shape[1]\n",
    "      # print(n_features)\n",
    "      \n",
    "      # ensure all data is float\n",
    "      values = values_df.astype('float32')\n",
    "      # normalize features\n",
    "      scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "      scaled = scaler.fit_transform(values)\n",
    "\n",
    "      # frame as supervised learning\n",
    "      reframed = series_to_supervised(scaled, n_day, n_out)\n",
    "      # print(reframed.shape)\n",
    "      # print(reframed.head())\n",
    "\n",
    "      # datasets\n",
    "      values = reframed.values\n",
    "\n",
    "      #input \n",
    "      n_obs = n_day * n_features\n",
    "      dataset_X, dataset_y = values[:, :n_obs], values[:, -1]\n",
    "      # print(dataset_X.shape, len(dataset_X), dataset_y.shape) \n",
    "\n",
    "      # reshape input to be 3D [samples, timesteps, features]\n",
    "      dataset_X = dataset_X.reshape((dataset_X.shape[0], n_day, n_features))\n",
    "      # print(dataset_X.shape, dataset_y.shape)\n",
    "\n",
    "      return dataset_X,dataset_y\n",
    "       \n",
    "#################--           create_model           --#################\n",
    "def create_model(units,shape_1,shape_2,activation = 'relu'):\n",
    "      return tf.keras.models.Sequential([\n",
    "                  # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "                  keras.layers.LSTM(units=units, input_shape=(shape_1, shape_2),activation=activation),\n",
    "                  # keras.BatchNormalization(),\n",
    "                  keras.layers.Dense(units=1)\n",
    "            ])            \n",
    " \n",
    "#################--           train_model           --#################   \n",
    "def train_model(model,train_x, train_y,val_x, val_y,Epochs,batch_size,optimizer = 0.0001,loss_input = 'mae',metrics_input = 'accuracy'):\n",
    "      Optimizer = tf.keras.optimizers.Adam(optimizer)\n",
    "      model.compile(Optimizer, loss=loss_input, metrics= metrics_input)\n",
    "\n",
    "      logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "      tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "      training_history =  model.fit(train_x, train_y, \n",
    "                  epochs=Epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  validation_data=(val_x, val_y), \n",
    "                  # verbose=2, \n",
    "                  # callbacks=[cp_callback,es_callback], \n",
    "                  # callbacks=[cp_callback],\n",
    "                  callbacks=[tensorboard_callback])\n",
    "                  # shuffle=False)\n",
    "      return training_history,model\n",
    "\n",
    "#################--           open TensorBoard          --#################   \n",
    "def displaytensor():\n",
    "      from tensorboard import notebook\n",
    "      notebook.list() # View open TensorBoard instances\n",
    "      notebook.display(port=6006, height=1000) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea89aab5279a46318fd4894ce32d39f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='station :', options=('ALL', 'Chachoengsao Rice research Ce…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8249c81d944da490fa79cfb0db7c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a94b52c92440e4bf13fc21d6aed57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=10, continuous_update=False, description='Epochs :', max=5000, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6eb4e45a9146dfbf1499ef4fdd0fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), _titles={'0': 'model.summary', '1': 'model_fit', '2': 'tensorboar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################-- Dashboard --#################\n",
    "\n",
    "ALL = 'ALL'\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st = widgets.Output()\n",
    "def dropdown_station_eventhandler(change):\n",
    "    output_df_st.clear_output()\n",
    "    with output_df_st:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- select sampling --#################\n",
    "def dropdown_sampling_eventhandler(change):\n",
    "    return dropdown_sampling_data\n",
    "\n",
    "#################-- select year train --#################\n",
    "def dropdown_year_t1_eventhandler(change):\n",
    "    return dropdown_year_train1\n",
    "def dropdown_year_t2_eventhandler(change):\n",
    "    return dropdown_year_train2\n",
    "def dropdown_year_v1_eventhandler(change):\n",
    "    return dropdown_year_val1\n",
    "def dropdown_year_v2_eventhandler(change):\n",
    "    return dropdown_year_val2\n",
    "def dropdown_year_ts1_eventhandler(change):\n",
    "    return dropdown_year_test1\n",
    "def dropdown_year_ts2_eventhandler(change):\n",
    "    return dropdown_year_test2\n",
    "\n",
    "#################-- select model --#################\n",
    "def Slider_Epochs_eventhandler(change):\n",
    "    return Slider_Epochs\n",
    "def Slider_batch_size_eventhandler(change):\n",
    "    return Slider_batch_size\n",
    "def Box_Units_eventhandler(change):\n",
    "    return Box_Units\n",
    "def Box_Optimizer_eventhandler(change):\n",
    "    return Box_Optimizer\n",
    "def dropdown_activation_eventhandler(change):\n",
    "    return dropdown_activation\n",
    "def dropdown_loss_eventhandler(change):\n",
    "    return dropdown_loss\n",
    "def Box_nday_eventhandler(change):\n",
    "    return Box_nday\n",
    "def Box_nout_eventhandler(change):\n",
    "    return Box_nout\n",
    "\n",
    "\n",
    "\n",
    "#################-- load data  --#################\n",
    "output_df_train = widgets.Output()\n",
    "output_df_val = widgets.Output()\n",
    "output_df_test = widgets.Output()\n",
    "output_df_col = widgets.Output()\n",
    "def clicked_load(b):\n",
    "   \n",
    "    global df_out_train\n",
    "    global df_out_val\n",
    "    global df_out_test\n",
    "    global selected_data\n",
    "    output_df_train.clear_output()\n",
    "    output_df_val.clear_output()\n",
    "    output_df_test.clear_output()\n",
    "    output_df_col.clear_output()\n",
    "    with output_df_train:\n",
    "        df_out_train = creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_train)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value))\n",
    "    with output_df_val:\n",
    "        df_out_val = creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_val)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value))\n",
    "    with output_df_test:\n",
    "        df_out_test = creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_test)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value))\n",
    "    with output_df_col:\n",
    "        checkbox_objects = []\n",
    "        # global selected_data\n",
    "        data = set(chek_list(df_out_train))    \n",
    "        names = []\n",
    "        for key in data:\n",
    "                checkbox_objects.append(widgets.Checkbox(value=False, description=key))\n",
    "                names.append(key)\n",
    " \n",
    "        arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "        ui = widgets.HBox(children=checkbox_objects)\n",
    "        display(ui)\n",
    "             \n",
    "        selected_data = []\n",
    "        def select_data(**kwargs):\n",
    "            selected_data.clear()\n",
    "            for key in kwargs:\n",
    "                if kwargs[key] is True:\n",
    "                    selected_data.append(key)\n",
    "            print(selected_data)\n",
    "\n",
    "        widgets.interactive_output(select_data, arg_dict)\n",
    "    \n",
    "    return df_out_train,df_out_val,df_out_test\n",
    "\n",
    "def chek_list(df_ch):\n",
    "        data_col = set(df_ch.columns)    \n",
    "        return data_col\n",
    "\n",
    "#################-- Export data  --#################\n",
    "df_train = widgets.Output()\n",
    "df_val = widgets.Output()\n",
    "df_test = widgets.Output()\n",
    "def clicked_export(b):\n",
    "    df_train.clear_output()\n",
    "    df_val.clear_output()\n",
    "    df_test.clear_output()\n",
    "    global frames_train\n",
    "    global frames_val\n",
    "    global frames_test\n",
    "    with df_train:\n",
    "        frames_train = drop_col(df_out_train,selected_data) \n",
    "        display(frames_train)\n",
    "    with df_val:\n",
    "        frames_val = drop_col(df_out_val,selected_data) \n",
    "        display(frames_val)  \n",
    "    with df_test:\n",
    "        frames_test = drop_col(df_out_test,selected_data) \n",
    "        display(frames_test)     \n",
    "\n",
    "\n",
    "#################-- create_model  --#################\n",
    "output_create_model = widgets.Output()\n",
    "def clicked_model(b):\n",
    "    output_create_model.clear_output()\n",
    "    global model_in\n",
    "    global train_X\n",
    "    global train_Y\n",
    "    global val_X\n",
    "    global val_Y\n",
    "    \n",
    "    \n",
    "    with output_create_model:\n",
    "        train_X, train_Y = data_preprocess(frames_train,Box_nday.value,Box_nout.value)\n",
    "        val_X,val_Y = data_preprocess(frames_val,Box_nday.value,Box_nout.value)              \n",
    "        model_in = create_model(Box_Units.value,train_X.shape[1],train_X.shape[2],dropdown_activation.value)\n",
    "        clear_output(wait=True) \n",
    "        print(model_in.summary())\n",
    "        print(train_X.shape)  \n",
    "        print(train_Y.shape) \n",
    "        \n",
    "#################-- fit_model  --#################\n",
    "output_fit_model = widgets.Output()   \n",
    "def clicked_train(b):\n",
    "    output_fit_model.clear_output()\n",
    "    global history_out\n",
    "    global model_out\n",
    "    \n",
    "    with output_fit_model:\n",
    "        # fit network\n",
    "        # (train_x, train_y,val_x, val_y,Epochs,batch_size,optimi = 0.0001,loss_input = 'mae',metrics_input = 'accuracy'):\n",
    "        history_out,model_out = train_model(model_in,train_X, train_Y,val_X, val_Y,Slider_Epochs.value,Slider_batch_size.value,\n",
    "                                Box_Optimizer.value,dropdown_loss.value)\n",
    "        print(\"Average test loss: \", np.average(history_out.history['loss']))\n",
    "        \n",
    "      \n",
    " #################-- tensorboard display  --#################\n",
    "output_tensorboard = widgets.Output()      \n",
    "def clicked_tensor(b):\n",
    "    output_tensorboard.clear_output()\n",
    "    with output_tensorboard:\n",
    "         displaytensor()\n",
    "\n",
    "\n",
    "#################-- Plot data  --#################\n",
    "output_df_plot = widgets.Output()\n",
    "\n",
    "\n",
    "#################----------------------------- DashBoard  ----------------------------------#################\n",
    "dropdown_name_st = widgets.Dropdown(options = unique_sorted_values_plus_ALL(df_st.nameEng),description='station :')\n",
    "dropdown_sampling_data = widgets.Dropdown(options = ['All-DAY','3-DAY','7-DAY'],valure = 'All-DAY',description='Sampling :')\n",
    "dropdown_year_train1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],description='Year-train :')\n",
    "dropdown_year_train2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2017')\n",
    "dropdown_year_val1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018',description='Year-val :')\n",
    "dropdown_year_val2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018')\n",
    "dropdown_year_test1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019',description='Year-test :')\n",
    "dropdown_year_test2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019')\n",
    "\n",
    "button_download = widgets.Button(description='load data',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_export = widgets.Button(description='export dataset',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_model = widgets.Button(description='create_model',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_train = widgets.Button(description='train_model',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "button_tensorboard = widgets.Button(description='tensorboard',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "\n",
    "Slider_Epochs = widgets.IntSlider(value=10,min=10,max=5000,step=10,description='Epochs :',disabled=False,continuous_update=False,orientation='horizontal', readout=True,readout_format='d')\n",
    "Slider_batch_size = widgets.IntSlider(value=128,min=16,max=256,step=8,description='Batch_size :',disabled=False,continuous_update=False,orientation='horizontal', readout=True,readout_format='d')\n",
    "Box_Units = widgets.IntText(value=50,description='units :',disabled=False)\n",
    "Box_Optimizer = widgets.FloatText(value=0.0001,step=0.0001,description='Optimizer :',disabled=False)\n",
    "dropdown_activation = widgets.Dropdown(options = ['relu','elu','sigmoid','tanh'],valure = 'elu',description='activation :')\n",
    "dropdown_loss = widgets.Dropdown(options = ['mae','mae'],valure = 'mae',description='loss :')\n",
    "Box_nday = widgets.IntText(value=7,description='n-day :',disabled=False)\n",
    "Box_nout = widgets.IntText(value=1,description='n-out :',disabled=False)\n",
    "\n",
    "button_download.on_click(clicked_load)\n",
    "button_export.on_click(clicked_export)\n",
    "button_model.on_click(clicked_model)\n",
    "button_train.on_click(clicked_train)\n",
    "button_tensorboard.on_click(clicked_tensor)\n",
    "\n",
    "dropdown_name_st.observe(dropdown_station_eventhandler, names='value')\n",
    "dropdown_sampling_data.observe(dropdown_sampling_eventhandler, names='value')\n",
    "dropdown_year_train1.observe(dropdown_year_t1_eventhandler, names='value')\n",
    "dropdown_year_train2.observe(dropdown_year_t2_eventhandler, names='value')\n",
    "dropdown_year_val1.observe(dropdown_year_v1_eventhandler, names='value')\n",
    "dropdown_year_val2.observe(dropdown_year_v2_eventhandler, names='value')\n",
    "dropdown_year_test1.observe(dropdown_year_ts1_eventhandler, names='value')\n",
    "dropdown_year_test2.observe(dropdown_year_ts2_eventhandler, names='value')\n",
    "Slider_Epochs.observe(Slider_Epochs_eventhandler, names='value')\n",
    "Slider_batch_size.observe(Slider_batch_size_eventhandler, names='value')\n",
    "Box_Units.observe(Box_Units_eventhandler, names='value')\n",
    "Box_Optimizer.observe(Box_Optimizer_eventhandler, names='value')\n",
    "dropdown_activation.observe(dropdown_activation_eventhandler, names='value')\n",
    "dropdown_loss.observe(dropdown_loss_eventhandler, names='value')\n",
    "Box_nday.observe(Box_nday_eventhandler, names='value')\n",
    "Box_nout.observe(Box_nout_eventhandler, names='value')\n",
    "\n",
    "\n",
    "item_layout = widgets.Layout(margin='0 0 15px 0')\n",
    "\n",
    "input_widgets_row1 = widgets.HBox([dropdown_name_st,dropdown_year_train1,dropdown_year_train2,dropdown_year_val1,dropdown_year_val2,dropdown_year_test1,dropdown_year_test2],layout = item_layout)\n",
    "input_widgets_row2 = widgets.HBox([dropdown_sampling_data,button_download,button_export],layout = item_layout)\n",
    "input_widgets_row3 = widgets.HBox([Slider_Epochs,Slider_batch_size,Box_Units,Box_Optimizer],layout = item_layout)\n",
    "input_widgets_row4 = widgets.HBox([dropdown_activation,dropdown_loss,Box_nday,Box_nout],layout = item_layout)\n",
    "input_widgets_row5 = widgets.HBox([button_model,button_train,button_tensorboard])\n",
    "\n",
    "tab_dataset = widgets.Tab([output_df_st,output_df_train,output_df_val,output_df_test,output_df_col,df_train,df_val,df_test])\n",
    "tab_dataset.set_title(0, 'Dataset station')\n",
    "tab_dataset.set_title(1, 'train-data')\n",
    "tab_dataset.set_title(2, 'validation-data')\n",
    "tab_dataset.set_title(3, 'test-data')\n",
    "tab_dataset.set_title(4, 'Drop-data')\n",
    "tab_dataset.set_title(5, 'Dataset-train')\n",
    "tab_dataset.set_title(6, 'Dataset-validation')\n",
    "tab_dataset.set_title(7, 'Dataset-test')\n",
    "dashboard_dataset = widgets.VBox([input_widgets_row1,input_widgets_row2])\n",
    "display(dashboard_dataset)\n",
    "display(tab_dataset)\n",
    "\n",
    "dashboard_model = widgets.VBox([input_widgets_row3,input_widgets_row4,input_widgets_row5])\n",
    "tab_model = widgets.Tab([output_create_model,output_fit_model,output_tensorboard])\n",
    "tab_model.set_title(0,'model.summary')\n",
    "tab_model.set_title(1,'model_fit')\n",
    "tab_model.set_title(2,'tensorboard')\n",
    "display(dashboard_model)\n",
    "display(tab_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter creat model : Epochs : 10,  batch_size : 128, n-day : 7, n-out : 1\n",
      "parameter Model Fit : Units : 50,  activation : relu,\n"
     ]
    }
   ],
   "source": [
    "print(\"parameter creat model : Epochs : %d,  batch_size : %d, n-day : %d, n-out : %d\" % (Slider_Epochs.value, Slider_batch_size.value, Box_nday.value, Box_nout.value))\n",
    "print(\"parameter Model Fit : Units : %d,  activation : %s,\" % (Box_Units.value, dropdown_activation.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance loss\n",
    "perf_loss  = round(history_out['loss'][-1], 5)\n",
    "print('loss is : ', perf_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 0:02:30 ago; pid 10019)\n",
      "Selecting TensorBoard with logdir logs (started 0:02:30 ago; port 6006, pid 10019).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-675eb5cb8d906cd6\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-675eb5cb8d906cd6\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %reload_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "# !lsof -i:6006\n",
    "# !kill 5080   #pid\n",
    "displaytensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = data_preprocess(frames_test,Box_nday.value,Box_nout.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = '2019-01-01'\n",
    "date_stop = '2019-01-31'\n",
    "\n",
    "# frames_test.loc[date_start:date_stop]\n",
    "# test_X, test_Y = data_preprocess(frames_test,Box_nday.value,Box_nout.value)\n",
    "n_day = Box_nday.value\n",
    "n_out = Box_nout.value\n",
    "values_df = frames_test.loc[date_start:date_stop].values    #ตัด header กับ idx ออก เป็น array matrix\n",
    "n_features = frames_test.loc[date_start:date_stop].shape[1]\n",
    "# print(n_features)\n",
    "\n",
    "# ensure all data is float\n",
    "values = values_df.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_day, n_out)\n",
    "# print(reframed.shape)\n",
    "# print(reframed.head())\n",
    "\n",
    "# datasets\n",
    "values = reframed.values\n",
    "\n",
    "#input \n",
    "n_obs = n_day * n_features\n",
    "dataset_X, dataset_y = values[:, :n_obs], values[:, -1]\n",
    "# print(dataset_X.shape, len(dataset_X), dataset_y.shape) \n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "dataset_X = dataset_X.reshape((dataset_X.shape[0], n_day, n_features))\n",
    "# print(dataset_X.shape, dataset_y.shape)\n",
    "\n",
    "# # make a prediction\n",
    "yhat = model_out.predict(dataset_X)\n",
    "test_X_reshape = dataset_X.reshape((dataset_X.shape[0], n_day*n_features))\n",
    "    \n",
    "# invert scaling for forecast\n",
    "# inv_yhat = concatenate((yhat, test_X[:, -29:]), axis=1)\n",
    "inv_yhat = concatenate((test_X_reshape[:, :(n_features-1)], yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,-1]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y_reshape = dataset_y.reshape((len(dataset_y), 1))\n",
    "# inv_y = concatenate((test_y, test_X[:, -29:]), axis=1)\n",
    "inv_y = concatenate((test_X_reshape[:, :(n_features-1)], test_y_reshape), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,-1]\n",
    "# # calculate RMSE\n",
    "# rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "# print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "forecast_data = (abs(inv_yhat[:])) \n",
    "label_data =  inv_y[:]\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(label_data,forecast_data))\n",
    "\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "df = frames_test.loc[date_start:date_stop].reset_index()\n",
    "date_time_predict = pd.to_datetime(df.pop('date'))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_Perfor():\n",
    "      plt.figure()\n",
    "      plt.plot(date_time_predict[n_day+n_out-1:],label_data,label='label',marker='.')\n",
    "      plt.plot(date_time_predict[n_day+n_out-1:],forecast_data,label='forecast',marker='.')\n",
    "\n",
    "      plt.ylabel('BPH volume')\n",
    "      plt.xlabel('Date time')\n",
    "      # plt.title(file_name +'  RMSE: %.3f' % rmse)\n",
    "      plt.legend()\n",
    "      plt.grid(True)\n",
    "      # plt.show()\n",
    "\n",
    "plot_Perfor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = frames_test['bph'].loc[date_start:date_stop]\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_plot = 'data test'\n",
    "cols = ['mirid bug', 'bph']\n",
    "date_start = '2015-01-01'\n",
    "date_stop = '2017-12-31'\n",
    "plot_data(frames_train,cols,name_plot,date_start,date_stop)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = data_preprocess(frames_train,7,3)\n",
    "val_X,val_y = data_preprocess(frames_val,7,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# loss, acc = model.evaluate(val_X, val_y, verbose=2)\n",
    "# var_loss = round(loss,5)\n",
    "# print('Accuracy : ', acc)\n",
    "# print('var_loss is : ', var_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_bph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e4ccb82a3f882ff33793e2fd72a967c991b1009db10b47a306b585d520f8880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
