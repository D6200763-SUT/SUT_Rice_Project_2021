{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n",
      "1.22.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "# import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import tensorflow \n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "import platform\n",
    "print(platform.python_version())\n",
    "# print(tf.version.VERSION)\n",
    "print(np.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All low RiceCenter 34 station\n"
     ]
    }
   ],
   "source": [
    "# File name and Path\n",
    "cwd = os.getcwd()\n",
    "path_adress = \"/Import_Dataset/\"\n",
    "\n",
    "# ข้อมูล พิกัดสถานที่เเละรายชื้ออ้างอิงสถานที่ตรวจวัด\n",
    "file_name_st = 'Data_lat_long_Rice research Center'\n",
    "csv_file_st = cwd + path_adress + file_name_st + '.csv'\n",
    "\n",
    "df_st = pd.read_csv(csv_file_st)\n",
    "print(\"All low RiceCenter {} station\" .format(df_st.shape[0]))\n",
    "\n",
    "data_list_st_num = list(range(0, len(df_st)))\n",
    "data_list_st_name = []\n",
    "data_list_st_name = df_st['nameEng'].values.tolist()\n",
    "data_list_st_lat = df_st['Latitude'].values.tolist()\n",
    "data_list_st_long = df_st['Longitude'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mavr_dataset(frames_sma,rolling_num,our_rate):    \n",
    "    h_name = list(frames_sma)\n",
    "    # frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    # frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).sum().round(1)\n",
    "    frames_sma['mirid bug'] = frames_sma['mirid bug'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "    frames_sma['bph'] = frames_sma['bph'].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "    for i in range(7,14):\n",
    "        frames_sma[h_name[i]] = frames_sma[h_name[i]].rolling(rolling_num, min_periods=1).mean().round(1)\n",
    "\n",
    "    #defining rate\n",
    "    # our_rate = rolling_num\n",
    "    #apply the rate\n",
    "    constant_subset = frames_sma[::our_rate] \n",
    "        \n",
    "    # frames = constant_subset\n",
    "    return constant_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_dataset(st_BPH = 'ALL', y_1='2015', y_2='2019', m_avr='ALL-DAY'):\n",
    "    for i in range(len(data_list_st_num)):\n",
    "        st = i\n",
    "        file_name = df_st['nameEng'][data_list_st_num[st]]\n",
    "        name_input = file_name\n",
    "        name_locals = 'stN_' + file_name\n",
    "\n",
    "        # File name and Path\n",
    "        csv_file = cwd + path_adress + name_input + '.csv'\n",
    "        # index_col=0 , index_col=None\n",
    "        dataset = pd.read_csv(csv_file, header=0,\n",
    "                              index_col=0, encoding=\"TIS-620\")\n",
    "        # dataset = dataset.drop(['address'], axis=1)\n",
    "        # dataset = dataset.drop(['year'], axis=1)\n",
    "        # dataset = dataset.drop(['dew'], axis=1)\n",
    "        # dataset = dataset.drop(['latitude'], axis=1)\n",
    "        # dataset = dataset.drop(['longitude'], axis=1)\n",
    "        # dataset.columns\n",
    "        # locals()[name_locals] =dataset\n",
    "\n",
    "        if m_avr == '3-DAY':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,3,3)\n",
    "        elif m_avr == '7-DAY':\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,7)\n",
    "        else :\n",
    "            locals()[name_locals] = mavr_dataset(dataset,7,1)\n",
    "            # print(f'Dataframe name_station: {st+1 , name_input}')\n",
    "        print('wait......')\n",
    "        del dataset\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    date_start = y_1 + '-01' + '-01'\n",
    "    date_stop = y_2 + '-12' + '-31'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "    if st_BPH != 'ALL' :\n",
    "        # file_name = df_st['nameEng'][data_list_st_num[st_BPH]]\n",
    "        file_name = st_BPH\n",
    "        locals_input = 'stN_' + file_name\n",
    "        print(locals_input)\n",
    "        dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "        frames_st = dataset_st\n",
    "    else:\n",
    "        m = 0\n",
    "        for j in range(len(data_list_st_num)):\n",
    "            # for j in range(df_st.shape[0]):\n",
    "            # file_name = df_st['nameEng'][j]\n",
    "            file_name = df_st['nameEng'][data_list_st_num[j]]\n",
    "            locals_input = 'stN_' + file_name\n",
    "            print(locals_input)\n",
    "            dataset_st = locals()[locals_input].loc[date_start:date_stop]\n",
    "            clear_output(wait=True)\n",
    "            if m == 0:\n",
    "                frames_st = dataset_st\n",
    "                m = m+1\n",
    "                print(m)\n",
    "            else:\n",
    "                frames_st = [frames_st, dataset_st]\n",
    "                frames_st = pd.concat(frames_st)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "    # dataset    \n",
    "    frames = frames_st\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(frames_train,df_name):\n",
    "    #ตรวจสอบข้อมูล dataset \n",
    "    plt.figure()\n",
    "    df_plot = frames_train\n",
    "    df_plot.plot(lw=1,grid=True,figsize=(13,30),subplots=True)\n",
    "    plt.xlabel('Date time-'+ df_name)\n",
    "    plt.legend()\n",
    "    # plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a2280d0215449e9c06e011259005ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='station :', options=('ALL', 'Chachoengsao Rice research Ce…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67af0c2abc834a24b1649361cefcee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output()), _titles={'0': 'Dataset station', '1': 'Dataset train', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ALL = 'ALL'\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "\n",
    "#################-- DataFrame station --#################\n",
    "output_df_st= widgets.Output()\n",
    "def dropdown_station_eventhandler(change):\n",
    "    output_df_st.clear_output()\n",
    "    with output_df_st:  \n",
    "        if (change.new == ALL):\n",
    "            display(df_st)\n",
    "        else:\n",
    "            display(df_st[df_st.nameEng == change.new])\n",
    "\n",
    "#################-- select sampling --#################\n",
    "def dropdown_sampling_eventhandler(change):\n",
    "    return dropdown_sampling_data\n",
    "\n",
    "#################-- select year train --#################\n",
    "def dropdown_year_t1_eventhandler(change):\n",
    "    return dropdown_year_train1\n",
    "def dropdown_year_t2_eventhandler(change):\n",
    "    return dropdown_year_train2\n",
    "def dropdown_year_v1_eventhandler(change):\n",
    "    return dropdown_year_val1\n",
    "def dropdown_year_v2_eventhandler(change):\n",
    "    return dropdown_year_val2\n",
    "def dropdown_year_ts1_eventhandler(change):\n",
    "    return dropdown_year_test1\n",
    "def dropdown_year_ts2_eventhandler(change):\n",
    "    return dropdown_year_test2\n",
    "\n",
    "#################-- load data  --#################\n",
    "output_df_train = widgets.Output()\n",
    "output_df_val = widgets.Output()\n",
    "output_df_test = widgets.Output()\n",
    "\n",
    "def clicked(b):\n",
    "   \n",
    "    global df_out_train\n",
    "    global df_out_val\n",
    "    global df_out_test\n",
    "    output_df_train.clear_output()\n",
    "    output_df_val.clear_output()\n",
    "    output_df_test.clear_output()\n",
    "    with output_df_train:\n",
    "        df_out_train = creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_train)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_train1.value,dropdown_year_train2.value,dropdown_sampling_data.value))\n",
    "    with output_df_val:\n",
    "        df_out_val = creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_val)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_val1.value,dropdown_year_val2.value,dropdown_sampling_data.value))\n",
    "    with output_df_test:\n",
    "        df_out_test = creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value)\n",
    "        display(df_out_test)\n",
    "        # display(creat_dataset(dropdown_name_st.value,dropdown_year_test1.value,dropdown_year_test2.value,dropdown_sampling_data.value))\n",
    "    data  = set(df_out_train.columns)\n",
    "    return df_out_train,df_out_val,df_out_test\n",
    "\n",
    "\n",
    "def chek_list(df_ch):\n",
    "    data = set(df_ch.columns)\n",
    "    global checkbox_objects\n",
    "    names = []\n",
    "    for key in data:\n",
    "        checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "        names.append(key)\n",
    "    return names\n",
    "    \n",
    "    \n",
    "\n",
    "dropdown_name_st = widgets.Dropdown(options = unique_sorted_values_plus_ALL(df_st.nameEng),description='station :')\n",
    "dropdown_sampling_data = widgets.Dropdown(options = ['All-DAY','3-DAY','7-DAY'],valure = 'All-DAY',description='Sampling :')\n",
    "dropdown_year_train1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],description='Year-train :')\n",
    "dropdown_year_train2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2017')\n",
    "dropdown_year_val1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018',description='Year-val :')\n",
    "dropdown_year_val2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2018')\n",
    "dropdown_year_test1 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019',description='Year-test :')\n",
    "dropdown_year_test2 = widgets.Dropdown(options = ['2015','2016','2017','2018','2019','2020'],value = '2019')\n",
    "button_download = widgets.Button(description='load data',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "\n",
    "\n",
    "button_download.on_click(clicked)\n",
    "\n",
    "dropdown_name_st.observe(dropdown_station_eventhandler, names='value')\n",
    "dropdown_sampling_data.observe(dropdown_sampling_eventhandler, names='value')\n",
    "dropdown_year_train1.observe(dropdown_year_t1_eventhandler, names='value')\n",
    "dropdown_year_train2.observe(dropdown_year_t2_eventhandler, names='value')\n",
    "dropdown_year_val1.observe(dropdown_year_v1_eventhandler, names='value')\n",
    "dropdown_year_val2.observe(dropdown_year_v2_eventhandler, names='value')\n",
    "dropdown_year_test1.observe(dropdown_year_ts1_eventhandler, names='value')\n",
    "dropdown_year_test2.observe(dropdown_year_ts2_eventhandler, names='value')\n",
    "\n",
    "item_layout = widgets.Layout(margin='0 0 15px 0')\n",
    "\n",
    "input_widgets_row1 = widgets.HBox([dropdown_name_st,dropdown_year_train1,dropdown_year_train2,dropdown_year_val1,dropdown_year_val2,dropdown_year_test1,dropdown_year_test2],layout = item_layout)\n",
    "input_widgets_row2 = widgets.HBox([dropdown_sampling_data,button_download],layout = item_layout)\n",
    "\n",
    "\n",
    "tab = widgets.Tab([output_df_st,output_df_train,output_df_val,output_df_test])\n",
    "tab.set_title(0, 'Dataset station')\n",
    "tab.set_title(1, 'Dataset train')\n",
    "tab.set_title(2, 'Dataset validation')\n",
    "tab.set_title(3, 'Dataset test')\n",
    "tab.set_title(4, 'Dataset Drop')\n",
    "\n",
    "dashboard = widgets.VBox([input_widgets_row1,input_widgets_row2])\n",
    "display(dashboard)\n",
    "display(tab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R-4', 'R-3', 'R-7', 'R-14', 'mint', 'mirid bug', 'R-11', 'humidity', 'wdir', 'temp', 'latitude', 'precip', 'R-10', 'R-9', 'dew', 'maxt', 'R-15', 'R-20', 'longitude', 'wspd', 'R-1', 'R-16', 'R-19', 'R-13', 'R-18', 'R-2', 'address', 'R-12', 'R-6', 'year', 'day', 'month', 'bph', 'R-17', 'R-5', 'R-8']\n"
     ]
    }
   ],
   "source": [
    "tt = chek_list(df_out_train)\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_out_train))\n",
    "# df_out = pd.DataFrame(output_df_test)  \n",
    "df_out_train.head()\n",
    "\n",
    "plot_data(df_out_train['bph'],dropdown_name_st.value)\n",
    "\n",
    "# plot_data(df_out_val[['bph','mirid bug']],dropdown_name_st.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Checkbox\n",
    "\n",
    "box = Checkbox(False, description='checker')\n",
    "display(box)\n",
    "\n",
    "def changed(b):\n",
    "    print(b)\n",
    "    print('tttt')\n",
    "\n",
    "box.observe(changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "source = df_out_train\n",
    "\n",
    "# alt.Chart(source).mark_line().encode(\n",
    "#     x='x',\n",
    "#     y='f(x)'\n",
    "# )\n",
    "\n",
    "# alt.Chart(source).mark_line().encode(\n",
    "#     x='date',\n",
    "#     y='bph'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "words = ['correct', 'horse', 'battery', 'staple']\n",
    "items = [Button(description=w) for w in words]\n",
    "left_box = VBox([items[0], items[1]])\n",
    "right_box = VBox([items[2], items[3]])\n",
    "HBox([left_box, right_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipywidgets as widgets\n",
    "\n",
    "# # data = {\"label_1\":\"data_1\", \"label_2\":\"data_2\", \"label_3\":\"data_3\"}\n",
    "# # data =  {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n",
    "\n",
    "data  = set(df_out_train.columns)\n",
    "\n",
    "\n",
    "# names = []\n",
    "# checkbox_objects = []\n",
    "# for key in data:\n",
    "#     checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "#     names.append(key)\n",
    "\n",
    "# arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "\n",
    "# ui = widgets.HBox(children=checkbox_objects)\n",
    "\n",
    "# display(ui)\n",
    "\n",
    "# selected_data = []\n",
    "# def select_data(**kwargs):\n",
    "#     selected_data.clear()\n",
    "\n",
    "#     for key in kwargs:\n",
    "#         if kwargs[key] is True:\n",
    "#             selected_data.append(key)\n",
    "\n",
    "#     print(selected_data)\n",
    "\n",
    "# out = widgets.interactive_output(select_data, arg_dict)\n",
    "# display(ui, out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = ['Alia', 'Bobby', 'Bobby', 1, 1, 2, 3]\n",
    "list1 = df_out_train.columns\n",
    "x = list(dict.fromkeys(list1))\n",
    "se = set(x)\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = df_out_train.columns\n",
    "s = set()\n",
    "for item in iterable:\n",
    "    s.add(item)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n",
    "print(basket)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 1\n",
    "# st_num = 1\n",
    "file_name = df_st['nameEng'][data_list_st_num[st]]\n",
    "name_input = file_name\n",
    "name_locals = 'stN_' + file_name\n",
    "print(name_locals)\n",
    "\n",
    "# File name and Path\n",
    "csv_file = cwd + path_adress + name_input + '.csv'\n",
    "# index_col=0 , index_col=None\n",
    "dataset = pd.read_csv(csv_file, header=0,\n",
    "                      index_col=0, encoding=\"TIS-620\")\n",
    "\n",
    "header_name = list(dataset)\n",
    "# print(header_name)\n",
    "\n",
    "data_list_header_num = list(range(0, len(header_name)))\n",
    "# print(data_list_header_num)\n",
    "\n",
    "data_list_drop = [0,4,5]\n",
    "\n",
    "for i in range(len(data_list_drop)):\n",
    "        dataset = dataset.drop([header_name[data_list_drop[i]]], axis=1)\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "frames_train = creat_avrdata(dataset,7)\n",
    "frames_train.head()\n",
    "# len(frames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_train.head()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temperature = dataset['temp']\n",
    "df_temperature = pd.DataFrame(dataset['bph'].loc['2015-01-01':'2015-01-31']) \n",
    "\n",
    "# df_temperature = \n",
    "# the simple moving average over a period of 10 years\n",
    "# df_temperature['7D-SMA'] = df_temperature.bph.rolling(7, min_periods=1).mean()\n",
    "# df_temperature['3D-SMA'] = df_temperature.bph.rolling(3, min_periods=1).mean()\n",
    "df_temperature['7D-SMA'] = df_temperature.bph.rolling(7, min_periods=1).sum()\n",
    "df_temperature['3D-SMA'] = df_temperature.bph.rolling(3, min_periods=1).sum()\n",
    "# df_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors for the line plot\n",
    "colors = ['green', 'red', 'purple']\n",
    "\n",
    "# line plot - the yearly average air temperature in Barcelona\n",
    "df_temperature.plot(color=colors, linewidth=3, figsize=(12,6))\n",
    "\n",
    "# modify ticks size\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(labels =['Data Input', '10-years SMA', '20-years SMA'], fontsize=14)\n",
    "\n",
    "# title and labels\n",
    "plt.title('Data average ', fontsize=18)\n",
    "plt.xlabel('date-time', fontsize=16)\n",
    "plt.ylabel('Temperature [°C]', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining rate\n",
    "our_rate = 6 \n",
    "#apply the rate\n",
    "constant_subset = df_temperature[::our_rate] \n",
    "#data\n",
    "constant_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_train\n",
    "our_rate = 6 \n",
    "\n",
    "#conditonal sampling\n",
    "our_condition = df['latitude'] == 15.198\n",
    "\n",
    "#Retirive the index\n",
    "index = our_condition[our_condition == True].index\n",
    " \n",
    "#sample based on condition \n",
    "conditional_subset = df[our_condition][::our_rate] \n",
    " \n",
    "#output \n",
    "df2 = conditional_subset.set_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining rate\n",
    "our_rate = 6 \n",
    "#apply the rate\n",
    "constant_subset = df_temperature[::our_rate] \n",
    "#data\n",
    "constant_subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_bph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e4ccb82a3f882ff33793e2fd72a967c991b1009db10b47a306b585d520f8880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
